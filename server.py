import os
import json
import io
import glob
import pandas as pd
from flask import Flask, request, jsonify, render_template, send_file
from flask_cors import CORS
from dotenv import load_dotenv
import google.generativeai as genai
import PIL.Image
import PIL.ImageEnhance
import re
from html import unescape

# --- ì„¤ì • ë° ì´ˆê¸°í™” ---
load_dotenv()
app = Flask(__name__)
CORS(app)

# API í‚¤ ì„¤ì •
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
if not GOOGLE_API_KEY:
    print("ğŸš¨ ê²½ê³ : .env íŒŒì¼ì— GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤!")
else:
    genai.configure(api_key=GOOGLE_API_KEY)

# Gemini ëª¨ë¸ ì„¤ì • (ê¸°ë³¸ê°’, ìë™ ê°ì§€ë¡œ ë®ì–´ì”Œì›Œì§ˆ ìˆ˜ ìˆìŒ)
MODEL_NAME = 'gemini-1.5-flash'

# ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ í•¨ìˆ˜
def check_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ í™•ì¸í•˜ê³  ì ì ˆí•œ ëª¨ë¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global MODEL_NAME
    try:
        models = genai.list_models()
        available_models = []
        print("\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡:")
        for m in models:
            if 'generateContent' in m.supported_generation_methods:
                # ëª¨ë¸ ì´ë¦„ì—ì„œ 'models/' ì ‘ë‘ì‚¬ ì œê±°
                model_name = m.name.replace('models/', '')
                available_models.append(model_name)
                print(f"   - {model_name}")
        
        # Flash ëª¨ë¸ ìš°ì„  ì„ íƒ
        for model in available_models:
            if 'flash' in model.lower():
                MODEL_NAME = model
                print(f"\nâœ… ì¶”ì²œ ëª¨ë¸ ì„ íƒ: {MODEL_NAME}\n")
                return MODEL_NAME
        
        # Flashê°€ ì—†ìœ¼ë©´ Pro ëª¨ë¸ ì„ íƒ
        for model in available_models:
            if 'pro' in model.lower():
                MODEL_NAME = model
                print(f"\nâœ… Pro ëª¨ë¸ ì„ íƒ: {MODEL_NAME}\n")
                return MODEL_NAME
        
        # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ëª¨ë¸ ì‚¬ìš©
        if available_models:
            MODEL_NAME = available_models[0]
            print(f"\nâœ… ì²« ë²ˆì§¸ ëª¨ë¸ ì„ íƒ: {MODEL_NAME}\n")
            return MODEL_NAME
        
        print(f"\nâš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ ì‚¬ìš©: {MODEL_NAME}\n")
        return None
    except Exception as e:
        print(f"âš ï¸ ëª¨ë¸ ëª©ë¡ í™•ì¸ ì‹¤íŒ¨: {e}")
        print(f"âš ï¸ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©: {MODEL_NAME}\n")
        return None

# ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ í™•ì¸ ë° ìë™ ì„¤ì •
if GOOGLE_API_KEY:
    check_available_models()
else:
    print(f"âš ï¸ API í‚¤ê°€ ì—†ì–´ ëª¨ë¸ í™•ì¸ì„ ê±´ë„ˆëœë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©: {MODEL_NAME}\n")

# --- ë²•ë ¹ í…ìŠ¤íŠ¸ ë¡œë“œ ---
def load_law_texts() -> str:
    """ë²•ë ¹ .txt íŒŒì¼ë“¤ì„ ëª¨ë‘ ì½ì–´ í•˜ë‚˜ì˜ í° í…ìŠ¤íŠ¸ë¡œ í•©ì¹©ë‹ˆë‹¤."""
    print("ğŸ“š ë²•ë ¹ íŒŒì¼ë“¤ì„ ì½ì–´ì˜¤ëŠ” ì¤‘...")
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì™€ í˜„ì¬ ë””ë ‰í† ë¦¬ ëª¨ë‘ í™•ì¸
    law_files = glob.glob("law_text_*.txt") + glob.glob("../law_text_*.txt")
    
    if not law_files:
        print("âš ï¸ ë²•ë ¹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë²•ë¥  ê²€í†  ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return ""
    
    all_law_text = ""
    for file_path in law_files:
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                all_law_text += f"--- ë²•ë ¹ [{file_path}] ì‹œì‘ ---\n\n"
                all_law_text += f.read()
                all_law_text += f"\n\n--- ë²•ë ¹ [{file_path}] ë ---\n\n"
            print(f"âœ… ë²•ë ¹ íŒŒì¼ '{file_path}' ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ë²•ë ¹ íŒŒì¼ '{file_path}' ì½ê¸° ì‹¤íŒ¨: {e}")
    
    print(f"âœ… ëª¨ë“  ë²•ë ¹ íŒŒì¼ ë¡œë“œ ì™„ë£Œ (ì´ {len(all_law_text)}ì)")
    return all_law_text

ALL_LAW_TEXT = load_law_texts()

# --- í”„ë¡¬í”„íŠ¸ (ì§€ì‹œì‚¬í•­) ---

# ì›ì¬ë£Œ í‘œì‹œì‚¬í•­ ì´ë¯¸ì§€ì—ì„œ í•„ìš”í•œ ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ëŠ” í”„ë¡¬í”„íŠ¸
PROMPT_EXTRACT_INGREDIENT_INFO = """
ì´ ì´ë¯¸ì§€ëŠ” ì›ë¶€ì¬ë£Œ í‘œì‹œì‚¬í•­ ì‚¬ì§„ì…ë‹ˆë‹¤. 
**í•„ìˆ˜ì ìœ¼ë¡œ ì¶”ì¶œí•´ì•¼ í•  ì •ë³´ë§Œ** ì¶”ì¶œí•˜ì„¸ìš”.

[ì¶”ì¶œí•´ì•¼ í•  ì •ë³´]
1. **ì›ì¬ë£Œëª…**: ì›ì¬ë£Œì˜ ì •í™•í•œ ëª…ì¹­
2. **ë³µí•©ì›ì¬ë£Œ ë‚´ì—­**: ê´„í˜¸ ì•ˆì˜ í•˜ìœ„ ì›ì¬ë£Œ ì •ë³´ (ì˜ˆ: (íƒˆì§€ëŒ€ë‘, ì†Œë§¥))
3. **ì›ì‚°ì§€ ì •ë³´**: ì›ì‚°ì§€ í‘œê¸° (ì˜ˆ: ì™¸êµ­ì‚°, êµ­ë‚´ì‚°, ì¸ë„ì‚° ë“±)
4. **ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ**: ì•Œë ˆë¥´ê¸° í‘œì‹œ ì •ë³´
5. **ì‹í’ˆì²¨ê°€ë¬¼**: ì²¨ê°€ë¬¼ëª…ê³¼ ìš©ë„ ë³‘ê¸° ì—¬ë¶€

[ì¶”ì¶œí•˜ì§€ ë§ì•„ì•¼ í•  ì •ë³´]
- ë³´ê´€ë°©ë²• (ì˜ˆ: ëƒ‰ì¥ë³´ê´€, ì‹¤ì˜¨ë³´ê´€ ë“±)
- í¬ì¥ì¬ì§ˆ ì •ë³´
- ë¶„ë¦¬ë°°ì¶œ ë§ˆí¬
- ë°”ì½”ë“œ ë²ˆí˜¸
- ì œì¡°ì¼ì/ìœ í†µê¸°í•œ
- ë‹¨ìˆœ í™ë³´ ë¬¸êµ¬
- ê¸°íƒ€ í‘œì‹œì‚¬í•­ê³¼ ë¬´ê´€í•œ ì •ë³´

[ì¶œë ¥ í˜•ì‹]
JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{
    "ingredient_name": "ì›ì¬ë£Œëª…",
    "sub_ingredients": "í•˜ìœ„ì›ì¬ë£Œ ë‚´ì—­ (ë³µí•©ì›ì¬ë£Œì¸ ê²½ìš°)",
    "origin": "ì›ì‚°ì§€ ì •ë³´",
    "allergens": ["ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ ëª©ë¡"],
    "additives": ["ì‹í’ˆì²¨ê°€ë¬¼ ëª©ë¡"]
}

ì›ì¬ë£Œëª…ì´ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ "ingredient_name"ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë‘ì„¸ìš”.
"""

# 1. ê¸°ì¤€ ë°ì´í„° ìƒì„±ìš© (ì—‘ì…€ + ì›ì¬ë£Œ ì‚¬ì§„ë“¤ -> ì •ë‹µì§€ ìƒì„±)
PROMPT_CREATE_STANDARD = """
ë‹¹ì‹ ì€ ì‹í’ˆ ê·œì • ë° í‘œì‹œì‚¬í•­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ [ë°°í•©ë¹„ ë°ì´í„°(Excel)]ì™€ [ì›ì¬ë£Œ í‘œì‹œì‚¬í•­ ì‚¬ì§„ë“¤ì—ì„œ ì¶”ì¶œí•œ ì •ë³´]ë¥¼ ì¢…í•©í•˜ì—¬,
ë²•ì ìœ¼ë¡œ ì™„ë²½í•œ **'ì‹í’ˆí‘œì‹œì‚¬í•­ ê¸°ì¤€ ë°ì´í„°(Standard)'**ë¥¼ ì‹¤ì œ ë¼ë²¨ í˜•ì‹ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.

[ë¶„ì„ ë‹¨ê³„]
1. **Excel ë°ì´í„° ë¶„ì„**: ë°°í•©ë¹„ìœ¨(%)ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì›ì¬ë£Œ ë‚˜ì—´ ìˆœì„œë¥¼ ê²°ì •í•˜ì„¸ìš”. (ê°€ì¥ ì¤‘ìš”)
2. **ì´ë¯¸ì§€ ë°ì´í„° ë§¤í•‘**: Excelì— ì íŒ ì›ì¬ë£Œëª…(ì˜ˆ: 'ê°„ì¥')ì— í•´ë‹¹í•˜ëŠ” ì‚¬ì§„(ì›ì¬ë£Œ ë¼ë²¨)ì„ ì°¾ì•„ì„œ ìƒì„¸ ì •ë³´(ë³µí•©ì›ì¬ë£Œ ë‚´ì—­, ì•Œë ˆë¥´ê¸°, ì›ì‚°ì§€)ë¥¼ ë³´ê°•í•˜ì„¸ìš”.
    - ì˜ˆ: Excelì—” 'ê°„ì¥'ë§Œ ìˆì§€ë§Œ, ì‚¬ì§„ì— 'íƒˆì§€ëŒ€ë‘(ì¸ë„ì‚°), ì†Œë§¥(ë°€)'ì´ ìˆë‹¤ë©´ ì´ë¥¼ ë°˜ì˜í•´ì•¼ í•¨.
    - **ì¤‘ìš”**: ë³´ê´€ë°©ë²•, í¬ì¥ì¬ì§ˆ ë“±ì€ ë¬´ì‹œí•˜ê³  ì›ì¬ë£Œ ê´€ë ¨ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.
3. **ë²•ë¥  ê²€í† **: ì œê³µëœ ë²•ë ¹ì„ ì°¸ê³ í•˜ì—¬ í‘œì‹œì‚¬í•­ì´ ë²•ì ìœ¼ë¡œ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.
4. **ìµœì¢… ì¡°í•©**: í’ˆëª©ì œì¡°ë³´ê³ ì„œ ê¸°ë°˜ì˜ ë¹„ìœ¨ê³¼ ì›ì¬ë£Œ ë¼ë²¨ì˜ ìƒì„¸ ë‚´ìš©ì„ í•©ì³ ìµœì¢… í‘œì‹œ í…ìŠ¤íŠ¸ë¥¼ ë§Œë“œì„¸ìš”.

[ì¶œë ¥ ì–‘ì‹ - JSON]
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì‹¤ì œ ì‹í’ˆ ë¼ë²¨ í˜•ì‹ì²˜ëŸ¼ êµ¬ì¡°í™”í•˜ì„¸ìš”.
{
    "product_info": {
        "product_name": "ì œí’ˆëª…",
        "food_type": "ì‹í’ˆì˜ ìœ í˜• (ì˜ˆ: ì–´ë¬µ(ìœ íƒ•ì²˜ë¦¬ì œí’ˆ/ë¹„ì‚´ê· ))",
        "net_weight": "ë‚´ìš©ëŸ‰ (ì˜ˆ: 1kg)",
        "expiration_date": "ì†Œë¹„ê¸°í•œ (ì˜ˆ: ì „ë©´ ë³„ë„í‘œì‹œì¼ê¹Œì§€)",
        "storage_method": "ë³´ê´€ë°©ë²• (ì˜ˆ: 0~10â„ƒì´í•˜ ëƒ‰ì¥ë³´ê´€)",
        "packaging_material": "í¬ì¥ì¬ì§ˆ (ì˜ˆ: í´ë¦¬ì—í‹¸ë Œ(ë‚´ë©´))",
        "item_report_number": "í’ˆëª©ë³´ê³ ë²ˆí˜¸",
        "front_calories": "ì „ë©´ë¶€ ì´ì—´ëŸ‰/ë¬¸êµ¬ (ì˜ˆ: 1,291kcal / ì—°ìœ¡70.6%, ë‹¹ê·¼4.41%)"
    },
    "ingredients": {
        "structured_list": [
            "ëƒ‰ë™ì—°ìœ¡70.6%(ì™¸êµ­ì‚°/ì–´ìœ¡ì‚´, ì„¤íƒ•, D-ì†Œë¹„í†¨, ì‚°ë„ì¡°ì ˆì œ)",
            "ì „ë¶„ê°€ê³µí’ˆ1 [ì¹´ì‚¬ë°”ì „ë¶„(íƒœêµ­, ë² íŠ¸ë‚¨ì‚°), ê°ìì „ë¶„]",
            "í˜¼í•©ì œì œ[ì¸ì‚°ì´ì „ë¶„(íƒ€í”¼ì˜¤ì¹´), ë±ìŠ¤íŠ¸ë¦°]",
            "ë‹¹ê·¼(êµ­ë‚´ì‚°)",
            "..."
        ],
        "continuous_text": "ëƒ‰ë™ì—°ìœ¡70.6%(ì™¸êµ­ì‚°/ì–´ìœ¡ì‚´, ì„¤íƒ•, D-ì†Œë¹„í†¨, ì‚°ë„ì¡°ì ˆì œ), ì „ë¶„ê°€ê³µí’ˆ1 [ì¹´ì‚¬ë°”ì „ë¶„(íƒœêµ­, ë² íŠ¸ë‚¨ì‚°), ê°ìì „ë¶„], í˜¼í•©ì œì œ[ì¸ì‚°ì´ì „ë¶„(íƒ€í”¼ì˜¤ì¹´), ë±ìŠ¤íŠ¸ë¦°], ë‹¹ê·¼(êµ­ë‚´ì‚°), ..."
    },
    "allergens": {
        "contains": ["ëŒ€ë‘", "ê²Œ"],
        "manufacturing_facility": "ë³¸ ì œí’ˆì€ ë°€, ê³„ë€, ìƒˆìš°, ì˜¤ì§•ì–´, ê³ ë“±ì–´, ìš°ìœ , ì‡ ê³ ê¸°, í† ë§ˆí† , ì¡°ê°œë¥˜(êµ´â€¤ì „ë³µ,í™í•© í¬í•¨)ë¥¼ ì‚¬ìš©í•œ ì œí’ˆê³¼ ê°™ì€ ì œì¡°ì‹œì„¤ì—ì„œ ì œì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤."
    },
    "nutrition_info": {
        "total_content": "1000 g",
        "per_100g": {
            "calories": "130 Kcal",
            "sodium": {"amount": "530 mg", "daily_value": "27%"},
            "fat": {"amount": "1.5 g", "daily_value": "3%"},
            "cholesterol": {"amount": "17 mg", "daily_value": "6%"},
            "carbohydrates": {"amount": "19 g", "daily_value": "6%"},
            "sugars": {"amount": "5 g", "daily_value": "5%"},
            "trans_fat": {"amount": "0 g", "daily_value": "0%"},
            "saturated_fat": {"amount": "0.3 g", "daily_value": "2%"},
            "protein": {"amount": "10 g", "daily_value": "18%"}
        },
        "disclaimer": "1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)ì€ 2,000kcal ê¸°ì¤€ì´ë¯€ë¡œ ê°œì¸ì˜ í•„ìš” ì—´ëŸ‰ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    },
    "manufacturer": {
        "name": "ì‚¼ì§„ì‹í’ˆ(ì£¼)",
        "address": "ë¶€ì‚°ê´‘ì—­ì‹œ ì‚¬í•˜êµ¬ ë‹¤ëŒ€ë¡œ 1066ë²ˆê¸¸ 51(ì¥ë¦¼ë™)"
    },
    "precautions": [
        "ë°˜ë“œì‹œ ëƒ‰ì¥ë³´ê´€í•˜ì‹œê³  ê°œë´‰ í›„ì—ëŠ” ë¹ ë¥¸ì‹œì¼ ë‚´ ì„­ì·¨í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤.",
        "ê°„í˜¹ í‘ë§‰ì´ ë°œê²¬ë  ìˆ˜ ìˆìœ¼ë‚˜ ìƒì„  ë‚´ë¶€ë³µë§‰ì´ì˜¤ë‹ˆ ì•ˆì‹¬í•˜ê³  ë“œì‹œê¸° ë°”ëë‹ˆë‹¤.",
        "ë°˜í’ˆ ë° êµí™˜: ìœ í†µ ì¤‘ ë³€ì§ˆ íŒŒì†ëœ ì œí’ˆì€ ë³¸ì‚¬ ë° êµ¬ì…ì²˜ì—ì„œ êµí™˜í•´ë“œë¦½ë‹ˆë‹¤.",
        "ë³¸ ì œí’ˆì€ ê³µì •ê±°ë˜ìœ„ì›íšŒê³ ì‹œ ì†Œë¹„ì ë¶„ìŸí•´ê²°ê¸°ì¤€ì— ì˜ê±° êµí™˜ ë˜ëŠ” ë³´ìƒë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "ë¶€ì •, ë¶ˆëŸ‰ì‹í’ˆ ì‹ ê³ ëŠ” êµ­ë²ˆì—†ì´ 1399"
    ],
    "law_compliance": {
        "status": "compliant" | "needs_review",
        "issues": ["ë²•ë¥  ìœ„ë°˜ ì‚¬í•­ ëª©ë¡ (ìˆëŠ” ê²½ìš°)"]
    },
    "details": [
        {"name": "ì›ì¬ë£Œëª…", "ratio": "ë°°í•©ë¹„ìœ¨", "origin": "ì›ì‚°ì§€", "sub_ingredients": "í•˜ìœ„ì›ë£Œ"}
    ]
}

**ì¤‘ìš”**: 
- Excel ë°ì´í„°ì—ì„œ ì¶”ì¶œ ê°€ëŠ¥í•œ ëª¨ë“  ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”.
- ì˜ì–‘ì •ë³´ëŠ” Excelì— ìˆëŠ” ê²½ìš°ì—ë§Œ í¬í•¨í•˜ê³ , ì—†ìœ¼ë©´ ë¹ˆ ê°ì²´ë¡œ ë‘ì„¸ìš”.
- ì›ì¬ë£Œëª…ì€ ë°°í•©ë¹„ìœ¨ ìˆœì„œëŒ€ë¡œ ì •í™•íˆ ë‚˜ì—´í•˜ì„¸ìš”.
- ì‹¤ì œ ë¼ë²¨ì— í‘œì‹œë˜ëŠ” í˜•ì‹ ê·¸ëŒ€ë¡œ êµ¬ì¡°í™”í•˜ì„¸ìš”.
"""

# 2. ë””ìì¸ ê²€ì¦ìš© (ì •ë‹µì§€ vs ë””ìì¸PDF)
# server.py ìˆ˜ì •ë³¸

PROMPT_VERIFY_DESIGN = """
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ [ì‹í’ˆí‘œì‹œì‚¬í•­ ì •ë°€ ê°ì‚¬ AI]ì´ì ê°ì • ì—†ëŠ” [ìë™ ì±„ì ê¸°]ì…ë‹ˆë‹¤.
ì œê³µëœ [Standard(ê¸°ì¤€ì„œ)]ì™€ [Design(ë””ìì¸ ì´ë¯¸ì§€ - ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ë§Œ í¬ë¡­ë¨)]ì„ 1:1 ì •ë°€ ëŒ€ì¡°í•˜ì—¬, ì•„ë˜ ê·œì¹™ì— ë”°ë¼ ëƒ‰ì² í•˜ê²Œ ì±„ì í•˜ì„¸ìš”.

**ì¤‘ìš”**: Design ì´ë¯¸ì§€ëŠ” ì´ë¯¸ ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ë§Œ í¬ë¡­ë˜ì–´ ì œê³µë©ë‹ˆë‹¤. 
ë¸Œëœë“œ ë¡œê³ , ì œí’ˆ ì‚¬ì§„, ì¡°ë¦¬ë²• ë“±ì€ ì´ë¯¸ ì œê±°ë˜ì—ˆìœ¼ë¯€ë¡œ, ì‹í’ˆí‘œì‹œì‚¬í•­ í…ìŠ¤íŠ¸ì—ë§Œ ì§‘ì¤‘í•˜ì„¸ìš”.

[ê°ì  ê¸°ì¤€í‘œ (ì´ì  100ì ì—ì„œ ì‹œì‘)]
ê¸°ë³¸ 100ì ì—ì„œ ì•„ë˜ ì˜¤ë¥˜ê°€ ë°œê²¬ë  ë•Œë§ˆë‹¤ ì ìˆ˜ë¥¼ ì°¨ê°í•˜ì„¸ìš”. (ìµœí•˜ 0ì )

1. **ì›ì¬ë£Œëª… ì˜¤ë¥˜ (-5ì /ê±´)**:
   - Standard(ì—‘ì…€)ì— ìˆëŠ” ì›ì¬ë£Œê°€ Design(ì´ë¯¸ì§€)ì— ì—†ê±°ë‚˜ ìˆœì„œê°€ ë‹¤ë¦„.
   - í•¨ëŸ‰(%) ìˆ«ìê°€ 0.1%ë¼ë„ ë‹¤ë¦„. (ì˜ˆ: 70.6% vs 70.5%)
2. **ì˜ì–‘ì„±ë¶„ ì˜¤ë¥˜ (-5ì /ê±´)**:
   - ë‚˜íŠ¸ë¥¨, íƒ„ìˆ˜í™”ë¬¼, ë‹¹ë¥˜ ë“±ì˜ ìˆ˜ì¹˜ ë˜ëŠ” ë‹¨ìœ„(g, mg) ë¶ˆì¼ì¹˜.
   - ë¹„ìœ¨(%) ìˆ«ìê°€ ë‹¤ë¦„.
3. **ë²•ì  ì˜ë¬´ ë¬¸êµ¬ ëˆ„ë½ (-10ì /ê±´)**:
   - "ì†Œë¹„ê¸°í•œ" (ìœ í†µê¸°í•œ ì•„ë‹˜) í‘œê¸° ì—¬ë¶€.
   - "ë¶€ì • ë¶ˆëŸ‰ì‹í’ˆ ì‹ ê³ ëŠ” êµ­ë²ˆì—†ì´ 1399" í‘œê¸° ì—¬ë¶€.
   - ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ ë³„ë„ í‘œì‹œë€ ìœ ë¬´.
   - í¬ì¥ì¬ì§ˆ ë° ë¶„ë¦¬ë°°ì¶œ ë§ˆí¬ ìœ ë¬´.
4. **ë¹„í˜„ì‹¤ì  ìˆ˜ì¹˜ ì˜¤ë¥˜ (-5ì /ê±´)**:
   - í•¨ëŸ‰ì´ 100%ë¥¼ ì´ˆê³¼í•˜ëŠ” ê²½ìš° (ì˜ˆ: "221%", "150%")
   - ë¹„í˜„ì‹¤ì ìœ¼ë¡œ í° ìˆ˜ì¹˜ (ì˜ˆ: "ë‚˜íŠ¸ë¥¨ 50000mg")
   - ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜ (ì˜ˆ: "13ì›”", "32ì¼")
5. **ë””ìì¸/í‘œê¸° ì˜¤íƒˆì (-3ì /ê±´)**:
   - ëª…ë°±í•œ ì² ì ì˜¤ë¥˜ (ì˜ˆ: "ì œì¡°ë²™ë²•" â†’ "ì œì¡°ë°©ë²•")
   - ë‹¨ìœ„ í‘œê¸° ì˜¤ë¥˜ (ì˜ˆ: "10Kg" â†’ "10 kg", ë‹¨ìœ„ ëˆ„ë½)
   - ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ê³µë°± (ì˜ˆ: "ë³´ê´€ë°© ë²•" â†’ "ë³´ê´€ë°©ë²•")
6. **ë‹¨ìˆœ ì˜¤íƒ€ (-2ì /ê±´)**:
   - ê´„í˜¸ ìœ„ì¹˜ ë“± ê²½ë¯¸í•œ ì°¨ì´.

[ë¶„ì„ í”„ë¡œì„¸ìŠ¤ - ë‹¨ê³„ë³„ ìˆ˜í–‰]

1. **êµ¬ì¡°í™” (Structuring)**:
   - Standard ë°ì´í„°(ì—‘ì…€)ë¥¼ [ì œí’ˆëª…, ì‹í’ˆìœ í˜•, ë‚´ìš©ëŸ‰, ì›ì¬ë£Œëª…, ì˜ì–‘ì •ë³´, ë³´ê´€ë°©ë²•, í¬ì¥ì¬ì§ˆ, í’ˆëª©ë³´ê³ ë²ˆí˜¸] í•­ëª©ë³„ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
   - Design ì´ë¯¸ì§€ëŠ” ì´ë¯¸ ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ë§Œ í¬ë¡­ë˜ì–´ ì œê³µë˜ë¯€ë¡œ, ì´ ì˜ì—­ì˜ í…ìŠ¤íŠ¸ë§Œ OCRí•˜ì—¬ ë™ì¼í•œ í•­ëª©ë“¤ì„ ì°¾ì•„ë‚´ì–´ 1:1 ë§¤ì¹­ ì¤€ë¹„ë¥¼ í•˜ì„¸ìš”.
   - **ë¬´ì‹œí•  ê²ƒ**: ë¸Œëœë“œ ë¡œê³ , ì œí’ˆ ì‚¬ì§„, ì¡°ë¦¬ë²•, í™ë³´ ë¬¸êµ¬ëŠ” ì´ë¯¸ ì œê±°ë˜ì—ˆìœ¼ë¯€ë¡œ ì‹ ê²½ì“°ì§€ ë§ˆì„¸ìš”.

2. **ì •ë°€ ëŒ€ì¡° (Cross-Checking) - ì„¸ë°€í•œ ê²€ì¦ í•„ìˆ˜**:
   
   **(1) ì›ì¬ë£Œëª… ê²€ì¦ (ê°€ì¥ ì¤‘ìš”) - ë‹¤ê°ë„ ê²€ì¦**:
   
   a. **í•¨ëŸ‰(%) ê²€ì¦**:
      - Standardì— í•¨ëŸ‰ì´ ì—†ìœ¼ë©´ Designì—ë„ í•¨ëŸ‰ì´ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤.
      - Standardì— í•¨ëŸ‰ì´ ìˆìœ¼ë©´ Designì˜ í•¨ëŸ‰ì´ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
      - í•¨ëŸ‰ì´ ì¶”ê°€ë˜ì—ˆê±°ë‚˜ ëˆ„ë½ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
      - ì˜ˆ: Standard "ë‹¹ê·¼(êµ­ë‚´ì‚°)" vs Design "ë‹¹ê·¼ 4.41%" â†’ í•¨ëŸ‰ì´ ê¸°ì¤€ì„œì— ì—†ëŠ”ë° ë””ìì¸ì— ì¶”ê°€ë¨ (ì˜¤ë¥˜)
      - ì˜ˆ: Standard "ì–‘íŒŒ" vs Design "ì–‘íŒŒ 2.21%" â†’ í•¨ëŸ‰ì´ ê¸°ì¤€ì„œì— ì—†ëŠ”ë° ë””ìì¸ì— ì¶”ê°€ë¨ (ì˜¤ë¥˜)
   
   b. **ìœ ì‚¬ë„ ë¹„êµ (ë¯¸ì„¸í•œ ì˜¤íƒ€ ê°ì§€)**:
      - ë‹¨ìˆœ ë¬¸ìì—´ ì¼ì¹˜ê°€ ì•„ë‹Œ, ë¬¸ì ë‹¨ìœ„ ìœ ì‚¬ë„ë¥¼ í™•ì¸í•˜ì„¸ìš”.
      - ì˜ˆ: "ì „ë°˜ê°€ê³µí’ˆ" vs "ì „ë¶„ê°€ê³µí’ˆ" â†’ 'ë°˜'ê³¼ 'ë¶„' í•œ ê¸€ì ì°¨ì´ (ì˜¤íƒ€ ê°ì§€)
      - ì˜ˆ: "ì–‘íŒŒ221%" vs "ì–‘íŒŒ2.21%" â†’ ì†Œìˆ˜ì (.) ëˆ„ë½ (ì˜¤íƒ€ ê°ì§€)
      - í•œ ê¸€ì ì°¨ì´ë‚˜ ë¹„ìŠ·í•œ ë¬¸ì(ì˜ˆ: ã…‚/ã…, ã„±/ã…‹) êµì²´ë„ ê°ì§€í•˜ì„¸ìš”.
   
   c. **ì›ì‚°ì§€ í‘œê¸° ê²€ì¦**:
      - ì›ì‚°ì§€ê°€ ê´„í˜¸ ì•ˆì— í‘œê¸°ë˜ì–´ì•¼ í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
      - ì˜ˆ: "ë‹¹ê·¼(êµ­ë‚´ì‚°)" â†’ ì›ì‚°ì§€ê°€ ê´„í˜¸ ì•ˆì— ìˆì–´ì•¼ í•¨
      - ì›ì‚°ì§€ê°€ êµµê²Œ í‘œì‹œë˜ì–´ì•¼ í•˜ëŠ” ê²½ìš°, OCR ê²°ê³¼ì—ì„œ í°íŠ¸ ì •ë³´ë¥¼ í™•ì¸í•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ ê°•ì¡° í‘œì‹œ(**êµµê²Œ**)ë¥¼ í™•ì¸í•˜ì„¸ìš”.
      - ì˜ˆ: Standard "ë‹¹ê·¼(êµ­ë‚´ì‚°)" â†’ Designì—ì„œ "êµ­ë‚´ì‚°" ë¶€ë¶„ì´ êµµê²Œ í‘œì‹œë˜ì–´ì•¼ í•¨
   
   d. **ë„ì–´ì“°ê¸° ë° êµ¬ë‘ì  ê²€ì¦**:
      - ë„ì–´ì“°ê¸° ìœ„ì¹˜ê°€ ì •í™•í•œì§€ í™•ì¸í•˜ì„¸ìš”.
      - ì˜ˆ: "ì œì¡°ì› / ì†Œì¬ì§€" vs "ì œì¡°ì›/ì†Œì¬ì§€" â†’ '/' ì•ë’¤ ê³µë°± ì°¨ì´ (ì˜¤ë¥˜)
      - ì˜ˆ: "ìš°ìœ , ì‡ ê³ ê¸°, í† ë§ˆí† " vs "ìš°ìœ  ì‡ ê³ ê¸° í† ë§ˆí† " â†’ ì‰¼í‘œ(,) ëˆ„ë½ (ì˜¤ë¥˜)
   
   e. **íŠ¹ìˆ˜ë¬¸ì ë° ê¸°í˜¸ ê²€ì¦**:
      - Standardì— ì—†ëŠ” ê¸°í˜¸ê°€ Designì— ì¶”ê°€ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
      - ì˜ˆ: Standard "ì£¼ì˜ì‚¬í•­ ë°˜ë“œì‹œ ëƒ‰ì¥ë³´ê´€í•˜ì‹œê³ ..." vs Design "â— ì£¼ì˜ì‚¬í•­ ë°˜ë“œì‹œ ëƒ‰ì¥ë³´ê´€í•˜ì‹œê³ ..." â†’ 'â— ' ê¸°í˜¸ ì¶”ê°€ (ì˜¤ë¥˜)
   
   **(2) ì˜ì–‘ì •ë³´ ê²€ì¦ - ìˆ˜ì¹˜ ë° ë‹¨ìœ„ ì •ë°€ ê²€ì¦**:
   
   a. **ìˆ˜ì¹˜ ê²€ì¦**:
      - ëª¨ë“  ìˆ«ìê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
      - ì˜ˆ: "127kcal" vs "130kcal" â†’ ìˆ«ì ì˜¤íƒˆì (ì˜¤ë¥˜)
      - ì†Œìˆ˜ì  ìœ„ì¹˜ë„ ì •í™•íˆ í™•ì¸í•˜ì„¸ìš”.
   
   b. **ë‹¨ìœ„ ê²€ì¦ (ì¤‘ìš”)**:
      - ë‹¨ìœ„(g, mg, %, kcal ë“±)ê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
      - ì˜ˆ: "ë‹¨ë°±ì§ˆ 10mg" vs "ë‹¨ë°±ì§ˆ 10g" â†’ ë‹¨ìœ„ ì˜¤íƒˆì (mg â†’ g) (ì˜¤ë¥˜)
      - ë‹¨ìœ„ê°€ ëˆ„ë½ë˜ì—ˆëŠ”ì§€ë„ í™•ì¸í•˜ì„¸ìš”.
      - ì˜ˆ: "ë‚˜íŠ¸ë¥¨ 530" vs "ë‚˜íŠ¸ë¥¨ 530 mg" â†’ ë‹¨ìœ„ ëˆ„ë½ (ì˜¤ë¥˜)
   
   c. **ë‹¨ìœ„ í‘œê¸° í˜•ì‹ ê²€ì¦**:
      - ë„ì–´ì“°ê¸° ë° ëŒ€ì†Œë¬¸ì í™•ì¸
      - ì˜ˆ: "10Kg" vs "10 kg" â†’ ë„ì–´ì“°ê¸° ë° ì†Œë¬¸ì ê¶Œì¥ (ì˜¤ë¥˜)
   
   **(3) ì²¨ê°€ë¬¼ ë° ìš©ë„ í‘œê¸° ê²€ì¦**:
   
   a. **ì²¨ê°€ë¬¼ ìš©ë„ ëª…ê¸° í•„ìˆ˜ í™•ì¸**:
      - ì²¨ê°€ë¬¼ì€ ëª…ì¹­ê³¼ ìš©ë„ë¥¼ í•¨ê»˜ í‘œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.
      - ì˜ˆ: "ì†Œë¸Œì‚°ì¹¼ë¥¨" vs "ì†Œë¸Œì‚°ì¹¼ë¥¨(ë³´ì¡´ë£Œ)" â†’ ìš©ë„ í‘œê¸° ëˆ„ë½ (ë²•ë ¹ ìœ„ë°˜)
      - ë²•ë ¹: ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ì— ì˜ê±° ëª…ì¹­ê³¼ ìš©ë„ë¥¼ í•¨ê»˜ í‘œì‹œí•´ì•¼ í•˜ëŠ” ì²¨ê°€ë¬¼
   
   **(4) í’ˆëª©ë³´ê³ ë²ˆí˜¸ ê²€ì¦**:
   
   a. **ìˆ«ì ì •í™•ì„±**:
      - ëª¨ë“  ìˆ«ìê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
      - ì˜ˆ: "2011014370370" vs "20110144370370" â†’ ìˆ«ì(0) ëˆ„ë½ (ì˜¤íƒ€)
   
   **(5) ë²•ì  ì˜ë¬´ì‚¬í•­ ê²€ì¦**: 
      - ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ í‘œì‹œ, "ì†Œë¹„ê¸°í•œ" ë¬¸êµ¬, ë¶„ë¦¬ë°°ì¶œ ë§ˆí¬ ë“±ì´ ë²•ê·œëŒ€ë¡œ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
      **ì¤‘ìš”**: ë²•ë¥  ìœ„ë°˜ ì‚¬í•­ì„ ë°œê²¬í•˜ë©´ ë°˜ë“œì‹œ ê´€ë ¨ ë²•ë ¹ ì¡°í•­ì„ ëª…ì‹œí•˜ì„¸ìš”.
      ì˜ˆ: "ì‹í’ˆë“±ì˜ í‘œì‹œÂ·ê´‘ê³ ì— ê´€í•œ ë²•ë¥  ì œ5ì¡° ì œ1í•­", "ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ ì œ3ì¡° ì œ2í•­" ë“±

3. **Step 3: Verdict (íŒë‹¨) - 3ê°€ì§€ ì˜¤ë¥˜ ìœ í˜• ëª¨ë‘ ì ê·¹ ê°ì§€**:
   
   **3-1. ë²•ë ¹ ìœ„ë°˜ ê°ì§€ (Legal Compliance)**
   - ë²•ë ¹ì— ëª…ì‹œëœ í•„ìˆ˜ í‘œê¸°ì‚¬í•­ ëˆ„ë½ ë° ìœ„ë°˜ ì—¬ë¶€ë¥¼ ì² ì €íˆ ê²€ì¦í•˜ì„¸ìš”.
   - ê´€ë ¨ ë²•ë ¹ ì¡°í•­ì„ ë°˜ë“œì‹œ ëª…ì‹œí•˜ì„¸ìš”.
   - **ë²•ë ¹ ìœ„ë°˜ ë³´ê³  í˜•ì‹**: "ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ [ë³„ì§€1] 1.ë°”.1)ê°€) ì›ì¬ë£Œëª…ì€ ë§ì´ ì‚¬ìš©í•œ ìˆœì„œì— ë”°ë¼ í‘œì‹œí•´ì•¼ í•˜ë©°, ì¤‘ë³µ í‘œê¸°ëŠ” ì •í™•ì„±ì„ ì €í•´í•©ë‹ˆë‹¤." í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
   - ë²•ë ¹ ì¡°í•­ ë²ˆí˜¸ì™€ ìœ„ë°˜ ë‚´ìš©ì„ í•¨ê»˜ í¬í•¨í•œ ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
   
   **3-2. ë¹„í˜„ì‹¤ì  ìˆ˜ì¹˜ ë° ë…¼ë¦¬ ì˜¤ë¥˜ ê°ì§€ (Logical Error) - ì ê·¹ ë³´ê³ **
   - **í•¨ëŸ‰ ì˜¤ë¥˜**: ì›ì¬ë£Œ í•¨ëŸ‰ì´ 100%ë¥¼ ì´ˆê³¼í•˜ê±°ë‚˜ ë¹„í˜„ì‹¤ì ì¸ ìˆ˜ì¹˜ì¸ ê²½ìš°ë¥¼ **ë°˜ë“œì‹œ** ì°¾ìœ¼ì„¸ìš”.
     * ì˜ˆ: "ì–´ë¬µ 221%" â†’ "2.21%" ë˜ëŠ” "22.1%"ì˜ ì˜¤íƒ€ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ â†’ 'violation' ë˜ëŠ” 'typo'ë¡œ ë³´ê³ 
     * ì˜ˆ: "ë‚˜íŠ¸ë¥¨ 50000mg" â†’ ë‹¨ìœ„ ì˜¤íƒ€ ë˜ëŠ” ì†Œìˆ˜ì  ëˆ„ë½ ê°€ëŠ¥ì„± â†’ 'typo'ë¡œ ë³´ê³ 
   - **ë‚ ì§œ ì˜¤ë¥˜**: ìœ í†µê¸°í•œì´ë‚˜ ì œì¡°ì¼ìê°€ ì¡´ì¬í•  ìˆ˜ ì—†ëŠ” ë‚ ì§œ(ì˜ˆ: 13ì›”, 32ì¼)ì´ê±°ë‚˜ í˜•ì‹ì´ ì˜ëª»ëœ ê²½ìš°ë¥¼ ì°¾ìœ¼ì„¸ìš”.
   - **ë…¼ë¦¬ì  ëª¨ìˆœ**: ì˜ì–‘ì •ë³´ ê³„ì‚°ì´ ë§ì§€ ì•Šê±°ë‚˜, í•¨ëŸ‰ í•©ê³„ê°€ ë¹„ì •ìƒì ì¸ ê²½ìš°ë¥¼ ì°¾ìœ¼ì„¸ìš”.
   
   **3-3. ë””ìì¸/í‘œê¸° ì˜¤íƒˆì ê°ì§€ (Design & Spelling Error) - ì ê·¹ ë³´ê³ **
   - **ëª…ë°±í•œ ì² ì ì˜¤ë¥˜**: ë¬¸ë§¥ìƒ ëª…í™•í•œ ë‹¨ì–´ì˜ ì˜¤íƒ€ë¥¼ **ë°˜ë“œì‹œ** ìˆ˜ì • ì œì•ˆí•˜ì„¸ìš”.
     * ì˜ˆ: "ì œì¡°ë²™ë²•" â†’ "ì œì¡°ë°©ë²•" (ëª…ë°±í•œ ì˜¤íƒ€)
     * ì˜ˆ: "ë³´ê´€ë°© ë²•" â†’ "ë³´ê´€ë°©ë²•" (ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ê³µë°±)
     * ì˜ˆ: "ìœ í†µê¸°í•œã„´" â†’ "ìœ í†µê¸°í•œ" (ì¤‘ë³µ ë¬¸ì)
     * ì˜ˆ: "ì„­ì·¨í•˜ì‹­ì‹œìš”" â†’ "ì„­ì·¨í•˜ì‹­ì‹œì˜¤" (í‘œì¤€ì–´ ê·œì • ìœ„ë°˜)
   - **ë‹¨ìœ„ í‘œê¸° ì˜¤ë¥˜**: ë²•ì • ê³„ëŸ‰ ë‹¨ìœ„ë‚˜ í‘œì¤€ í‘œê¸°ë²•ê³¼ ë‹¤ë¥¸ ê²½ìš°ë¥¼ ì°¾ìœ¼ì„¸ìš”.
     * ì˜ˆ: "10Kg" â†’ "10 kg" (ë„ì–´ì“°ê¸° ë° ì†Œë¬¸ì ê¶Œì¥)
     * ì˜ˆ: "ë‚˜íŠ¸ë¥¨ 530" â†’ "ë‚˜íŠ¸ë¥¨ 530 mg" (ë‹¨ìœ„ ëˆ„ë½)
   - **ì¼ê´€ì„± ê²€ì¦**: ê°™ì€ ì´ë¯¸ì§€ ë‚´ì—ì„œ ë™ì¼í•œ ë‹¨ì–´ê°€ ë‹¤ë¥´ê²Œ í‘œê¸°ëœ ê²½ìš°ë¥¼ ì°¾ìœ¼ì„¸ìš”.
     * ì˜ˆ: í•œ ê³³ì—ì„œëŠ” "ëƒ‰ì¥ë³´ê´€", ë‹¤ë¥¸ ê³³ì—ì„œëŠ” "ëƒ‰ì¥ ë³´ê´€"ìœ¼ë¡œ í‘œê¸°ëœ ê²½ìš°

4. **í•€ì…‹ ì˜¤ë¥˜ ì§€ì  (Pinpoint Reporting) - êµ¬ì²´ì  ì˜¤ë¥˜ ìœ í˜• ë¶„ë¥˜**:
   - "ì›ì¬ë£Œëª…ì´ ë‹¤ë¦…ë‹ˆë‹¤" ê°™ì´ ë­‰ëš±ê·¸ë¦¬ì§€ ë§ˆì„¸ìš”.
   - **ì˜¤ë¥˜ê°€ ìˆëŠ” 'ë‹¨ì–´' ë˜ëŠ” 'ìˆ«ì'ë§Œ ì •í™•íˆ ì˜ë¼ë‚´ì–´ `actual` í•„ë“œì— ë„£ìœ¼ì„¸ìš”.**
   - ì˜ˆ: "L-ê¸€ë£¨íƒì‚°ë‚˜íŠ¸ë¥¨"ì´ ë¹ ì¡Œë‹¤ë©´, ê·¸ ìœ„ì¹˜ ì£¼ë³€ í…ìŠ¤íŠ¸ë¥¼ `actual`ë¡œ ì¡ì•„ í•˜ì´ë¼ì´íŠ¸ í•˜ì„¸ìš”.
   
   **ì˜¤ë¥˜ ìœ í˜•ë³„ ë³´ê³  í˜•ì‹ (ë¹„ê³ ë€ í˜•ì‹)**:
   
   a. **ì˜¤íƒˆì (Typo)**:
      - "ì˜¤íƒˆì (. í‘œì‹œë¹ ì§)" â†’ ì†Œìˆ˜ì  ëˆ„ë½ (ì˜ˆ: "ì–‘íŒŒ221%" â†’ "ì–‘íŒŒ2.21%")
      - "ì˜¤íƒˆì (,í‘œì‹œë¹ ì§)" â†’ ì‰¼í‘œ ëˆ„ë½ (ì˜ˆ: "ìš°ìœ  ì‡ ê³ ê¸° í† ë§ˆí† " â†’ "ìš°ìœ , ì‡ ê³ ê¸°, í† ë§ˆí† ")
      - "ì˜¤íƒˆì (0 ë¹ ì§)" â†’ ìˆ«ì ëˆ„ë½ (ì˜ˆ: "2011014370370" â†’ "20110144370370")
      - "ê¸€ì ì˜¤íƒˆì" â†’ ë¬¸ì ì˜¤íƒ€ (ì˜ˆ: "ì „ë°˜ê°€ê³µí’ˆ" â†’ "ì „ë¶„ê°€ê³µí’ˆ")
      - "ìˆ«ì ì˜¤íƒˆì" â†’ ìˆ«ì ì˜¤íƒ€ (ì˜ˆ: "127kcal" â†’ "130kcal")
      - "ë‹¨ìœ„ ì˜¤íƒˆì" â†’ ë‹¨ìœ„ ì˜¤íƒ€ (ì˜ˆ: "ë‹¨ë°±ì§ˆ 10mg" â†’ "ë‹¨ë°±ì§ˆ 10g")
   
   b. **í¬ë§·íŒ… ì˜¤ë¥˜**:
      - "ì›ì‚°ì§€ êµµê²Œë¯¸í‘œì‹œ" â†’ ì›ì‚°ì§€ê°€ êµµê²Œ í‘œì‹œë˜ì§€ ì•ŠìŒ (ì˜ˆ: "ë‹¹ê·¼(êµ­ë‚´ì‚°)" â†’ "ë‹¹ê·¼(**êµ­ë‚´ì‚°**)")
      - "ë„ì–´ì“°ê¸° ì˜¤ë¥˜" â†’ ë„ì–´ì“°ê¸° ìœ„ì¹˜ ì°¨ì´ (ì˜ˆ: "ì œì¡°ì›/ì†Œì¬ì§€" â†’ "ì œì¡°ì› / ì†Œì¬ì§€")
   
   c. **í•„ìˆ˜ í‘œê¸° ëˆ„ë½**:
      - "ì²¨ê°€ë¬¼ ìœ í˜•ì´ ë¹ ì§" â†’ ì²¨ê°€ë¬¼ ìš©ë„ í‘œê¸° ëˆ„ë½ (ì˜ˆ: "ì†Œë¸Œì‚°ì¹¼ë¥¨" â†’ "ì†Œë¸Œì‚°ì¹¼ë¥¨(ë³´ì¡´ë£Œ)")
      - ë²•ë ¹ ì°¸ì¡°: "ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ì— ì˜ê±° ëª…ì¹­ê³¼ ìš©ë„ë¥¼ í•¨ê»˜ í‘œì‹œí•´ì•¼ í•˜ëŠ” ì²¨ê°€ë¬¼"
   
   d. **í•¨ëŸ‰ ì¶”ê°€/ëˆ„ë½**:
      - "ê¸°ì¤€ì„œì— ëª…ì‹œë˜ì§€ ì•Šì€ í•¨ëŸ‰(%)ì´ ë””ìì¸ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤" â†’ Standardì— í•¨ëŸ‰ì´ ì—†ëŠ”ë° Designì— í•¨ëŸ‰ì´ ì¶”ê°€ë¨
      - "ê¸°ì¤€ì„œì— ëª…ì‹œëœ í•¨ëŸ‰(%)ì´ ë””ìì¸ì— ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤" â†’ Standardì— í•¨ëŸ‰ì´ ìˆëŠ”ë° Designì— í•¨ëŸ‰ì´ ì—†ìŒ

[ë²•ë ¹ ìœ„ë°˜ ë³´ê³  í˜•ì‹]

**ë²•ë ¹ ìœ„ë°˜ ì‚¬í•­ì„ ë³´ê³ í•  ë•ŒëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¥´ì„¸ìš”:**
- ê´€ë ¨ ë²•ë ¹ ì¡°í•­ì„ ë¨¼ì € ëª…ì‹œí•˜ì„¸ìš”.
- ì˜ˆ: "ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ [ë³„ì§€1] 1.ë°”.1)ê°€) ì›ì¬ë£Œëª…ì€ ë§ì´ ì‚¬ìš©í•œ ìˆœì„œì— ë”°ë¼ í‘œì‹œí•´ì•¼ í•˜ë©°, ì¤‘ë³µ í‘œê¸°ëŠ” ì •í™•ì„±ì„ ì €í•´í•©ë‹ˆë‹¤."
- ì˜ˆ: "ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ [ë³„ì§€1] 1.ì•„.1)ê°€) ë° 1.ì•„.2)ê°€)(5)(ê°€) ì˜ì–‘ì„±ë¶„ í•¨ëŸ‰ì€ ì´ë‚´ìš©ëŸ‰ ë˜ëŠ” 100g(ml)ë‹¹ìœ¼ë¡œ ì •í™•íˆ í‘œì‹œë˜ì–´ì•¼ í•˜ë©°, ë‹¨ìœ„ ë° ìˆ˜ì¹˜ ì˜¤ë¥˜ëŠ” í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
- ì˜ˆ: "ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ [ë„2] í‘œì‹œì‚¬í•­í‘œì‹œì„œì‹ë„ì•ˆì— ë”°ë¼ ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆì€ ë³„ë„ì˜ í‘œì‹œë€ìœ¼ë¡œ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ í‘œê¸°í•´ì•¼ í•©ë‹ˆë‹¤."

**violations ë°°ì—´ í˜•ì‹:**
ê° ìœ„ë°˜ ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì¡°í™”í•˜ì„¸ìš”:
{
  "violation": "ìœ„ë°˜ ë‚´ìš© ì„¤ëª… (ë²•ë ¹ ì¡°í•­ í¬í•¨)",
  "law_reference": "ê´€ë ¨ ë²•ë ¹ ì¡°í•­ (ì˜ˆ: ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ [ë³„ì§€1] 1.ë°”.1)ê°€))"
}

[ì˜¤íƒˆì(Typo) ë³´ê³  ê·œì¹™ - ì ê·¹ì  ê°ì§€]

**ë³´ê³  ëŒ€ìƒ (ì ê·¹ì  ë³´ê³  - ë°˜ë“œì‹œ ì¡ì•„ë‚´ì„¸ìš”):**
- "ì œì¡°ë²™ë²•", "ë‚´ìš©ëƒ¥", "ìœ í†µê¸°í•œã„´" ê°™ì€ ëª…ë°±í•œ ì² ì ì˜¤ë¥˜
- "ì–´ë¬µ 221%", "ë‚˜íŠ¸ë¥¨ 50000mg" ê°™ì€ ë¹„í˜„ì‹¤ì ì¸ ìˆ˜ì¹˜ ì˜¤ë¥˜ (ë‹¨ìœ„ ë˜ëŠ” ì†Œìˆ˜ì  ì˜¤íƒ€ ìœ ë ¥)
- "ë³´ê´€ë°© ë²•"ê³¼ ê°™ì´ ë‹¨ì–´ ì¤‘ê°„ì˜ ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ê³µë°±
- ë¬¸ë§¥ìƒ ì˜¤íƒ€ê°€ í™•ì‹¤í•œ ê²½ìš° (ì˜ˆ: "ì„­ì·¨í•˜ì‹­ì‹œì˜¤" â†’ "ì„­ì·¨í•˜ì‹­ì‹œìš”" ë“± í‘œì¤€ì–´ ê·œì • ìœ„ë°˜ í¬í•¨)
- í•¨ëŸ‰ì´ 100%ë¥¼ ì´ˆê³¼í•˜ëŠ” ê²½ìš° (ì˜ˆ: "221%", "150%")
- ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜ (ì˜ˆ: "13ì›”", "32ì¼", "2024-13-01")

**ë³´ê³  ì œì™¸ ëŒ€ìƒ (ì‹ ì¤‘í•˜ê²Œ íŒë‹¨):**
- "ì¹´ ìì „ë¶„" ê°™ì´ ì „ë¬¸ì ì¸ ì›ì¬ë£Œëª…ì˜ ë„ì–´ì“°ê¸°ëŠ” ì‹ ì¤‘í•˜ê²Œ íŒë‹¨ (í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ ì œì™¸)
- ë””ìì¸ì  ìš”ì†Œë¡œ ì¸í•´ ì˜ë„ì ìœ¼ë¡œ ì¤„ë°”ê¿ˆëœ ê²½ìš°

[ì¶œë ¥ ì–‘ì‹ - JSON Only]
- Markdown í¬ë§· ì—†ì´ ì˜¤ì§ JSON ë°ì´í„°ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
{
  "design_ocr_text": "ë””ìì¸ ì „ì²´ í…ìŠ¤íŠ¸...",
  "score": (100ì ì—ì„œ ì°¨ê°ëœ ìµœì¢… ì ìˆ˜),
  "law_compliance": {
    "status": "compliant" | "violation",
    "violations": [
      {
        "violation": "ìœ„ë°˜ ë‚´ìš© ìƒì„¸ ì„¤ëª… (ë²•ë ¹ ì¡°í•­ ë²ˆí˜¸ì™€ ìœ„ë°˜ ë‚´ìš©ì„ í•¨ê»˜ í¬í•¨í•œ ì „ì²´ ë¬¸ì¥, ì˜ˆ: 'ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ [ë³„ì§€1] 1.ë°”.1)ê°€) ì›ì¬ë£Œëª…ì€ ë§ì´ ì‚¬ìš©í•œ ìˆœì„œì— ë”°ë¼ í‘œì‹œí•´ì•¼ í•˜ë©°, ì¤‘ë³µ í‘œê¸°ëŠ” ì •í™•ì„±ì„ ì €í•´í•©ë‹ˆë‹¤.')",
        "law_reference": "ê´€ë ¨ ë²•ë ¹ ì¡°í•­ ë²ˆí˜¸ë§Œ (ì˜ˆ: 'ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ [ë³„ì§€1] 1.ë°”.1)ê°€)', 'ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ [ë³„ì§€1] 1.ì•„.1)ê°€) ë° 1.ì•„.2)ê°€)(5)(ê°€)' ë“±)"
      }
    ]
  },
  
  **ì¤‘ìš”**: 
  - violations ë°°ì—´ì´ ë¹„ì–´ìˆê±°ë‚˜ statusê°€ "compliant"ì´ë©´ ë²•ë ¹ ìœ„ë°˜ì´ ì—†ëŠ” ê²ƒì…ë‹ˆë‹¤.
  - violation í•„ë“œì—ëŠ” ë²•ë ¹ ì¡°í•­ê³¼ ìœ„ë°˜ ë‚´ìš©ì„ í•¨ê»˜ í¬í•¨í•œ ì „ì²´ ë¬¸ì¥ì„ ì‘ì„±í•˜ì„¸ìš”.
  - ì˜ˆ: "ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ [ë³„ì§€1] 1.ë°”.1)ê°€) ì›ì¬ë£Œëª…ì€ ë§ì´ ì‚¬ìš©í•œ ìˆœì„œì— ë”°ë¼ í‘œì‹œí•´ì•¼ í•˜ë©°, ì¤‘ë³µ í‘œê¸°ëŠ” ì •í™•ì„±ì„ ì €í•´í•©ë‹ˆë‹¤."
  "issues": [
    {
      "type": "Critical" (ë‚´ìš© ë¶ˆì¼ì¹˜) | "Minor" (ë‹¨ìˆœ ì˜¤íƒ€) | "Law_Violation" (ë²•ë¥  ìœ„ë°˜) | "Logical_Error" (ë¹„í˜„ì‹¤ì  ìˆ˜ì¹˜/ë…¼ë¦¬ ì˜¤ë¥˜) | "Spelling_Error" (ëª…ë°±í•œ ì² ì ì˜¤ë¥˜) | "Formatting_Error" (í¬ë§·íŒ… ì˜¤ë¥˜) | "Missing_Info" (í•„ìˆ˜ ì •ë³´ ëˆ„ë½) | "Extra_Info" (ê¸°ì¤€ì„œì— ì—†ëŠ” ì •ë³´ ì¶”ê°€),
      "location": "í•­ëª©ëª… ë° ìœ„ì¹˜ (ì˜ˆ: ì›ì¬ë£Œëª…, í›„ë©´ë¶€ ì›ì¬ë£Œëª…, í›„ë©´ë¶€ ì˜ì–‘ì •ë³´, í›„ë©´ë¶€ ì•Œë ˆë¥´ê¸°ì£¼ì˜ì‚¬í•­ë¬¸êµ¬, ì „ë©´ë¶€ í•˜ë‹¨, í›„ë©´ë¶€ í’ˆëª©ë³´ê³ ë²ˆí˜¸)",
      "issue": "ì˜¤ë¥˜ ìƒì„¸ ì„¤ëª… (ë¹„ê³ ë€ í˜•ì‹ìœ¼ë¡œ ì‘ì„±, ì˜ˆ: 'ì˜¤íƒˆì (. í‘œì‹œë¹ ì§)', 'ë‹¨ìœ„ ì˜¤íƒˆì', 'ì›ì‚°ì§€ êµµê²Œë¯¸í‘œì‹œ', 'ì²¨ê°€ë¬¼ ìœ í˜•ì´ ë¹ ì§', 'ê¸°ì¤€ì„œì— ëª…ì‹œë˜ì§€ ì•Šì€ í•¨ëŸ‰(%)ì´ ë””ìì¸ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤')",
      "expected": "ê¸°ì¤€ì„œ ë°ì´í„° (ì •ë‹µ)",
      "actual": "ë””ìì¸ì—ì„œ ë°œê²¬ëœ í‹€ë¦° í…ìŠ¤íŠ¸ (í•˜ì´ë¼ì´íŠ¸ìš©)",
      "suggestion": "ìˆ˜ì • ì œì•ˆ (êµ¬ì²´ì ì¸ ìˆ˜ì • ë°©ë²•)",
      "law_reference": "ê´€ë ¨ ë²•ë ¹ ì¡°í•­ (ì˜ˆ: ì‹í’ˆë“±ì˜ í‘œì‹œÂ·ê´‘ê³ ì— ê´€í•œ ë²•ë¥  ì œ5ì¡°, ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ ì œ3ì¡° ì œ1í•­ ë“±) - ë²•ë¥  ìœ„ë°˜ì¸ ê²½ìš° í•„ìˆ˜. ì²¨ê°€ë¬¼ ìš©ë„ í‘œê¸° ëˆ„ë½ì˜ ê²½ìš° 'ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ì— ì˜ê±° ëª…ì¹­ê³¼ ìš©ë„ë¥¼ í•¨ê»˜ í‘œì‹œí•´ì•¼ í•˜ëŠ” ì²¨ê°€ë¬¼' í¬í•¨"
    }
  ]
  
  **ì¤‘ìš” - ì˜¤ë¥˜ ìœ í˜•ë³„ ì˜ˆì‹œ**:
  
  **ì˜ˆì‹œ 1: í•¨ëŸ‰ ì¶”ê°€ ì˜¤ë¥˜**
  {
    "type": "Extra_Info",
    "location": "ì›ì¬ë£Œëª…",
    "issue": "ê¸°ì¤€ì„œì— ëª…ì‹œë˜ì§€ ì•Šì€ í•¨ëŸ‰(%)ì´ ë””ìì¸ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. (ë‹¹ê·¼)",
    "expected": "ë‹¹ê·¼(êµ­ë‚´ì‚°)",
    "actual": "ë‹¹ê·¼ 4.41%",
    "suggestion": "ê¸°ì¤€ì„œì— ë‹¹ê·¼ì˜ í•¨ëŸ‰ ì •ë³´ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ë””ìì¸ì—ì„œ í•¨ëŸ‰ ì •ë³´ë¥¼ ì œê±°í•´ì•¼ í•©ë‹ˆë‹¤.",
    "law_reference": ""
  }
  
  **ì˜ˆì‹œ 2: ì†Œìˆ˜ì  ëˆ„ë½ ì˜¤íƒ€**
  {
    "type": "Spelling_Error",
    "location": "ì›ì¬ë£Œëª…",
    "issue": "ì˜¤íƒˆì (. í‘œì‹œë¹ ì§)",
    "expected": "ì–‘íŒŒ2.21%",
    "actual": "ì–‘íŒŒ221%",
    "suggestion": "ì†Œìˆ˜ì (.)ì„ ì¶”ê°€í•˜ì—¬ 'ì–‘íŒŒ2.21%'ë¡œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.",
    "law_reference": ""
  }
  
  **ì˜ˆì‹œ 3: ë‹¨ìœ„ ì˜¤ë¥˜**
  {
    "type": "Spelling_Error",
    "location": "í›„ë©´ë¶€ ì˜ì–‘ì •ë³´",
    "issue": "ë‹¨ìœ„ ì˜¤íƒˆì",
    "expected": "ë‹¨ë°±ì§ˆ 10g",
    "actual": "ë‹¨ë°±ì§ˆ 10mg",
    "suggestion": "ë‹¨ìœ„ë¥¼ 'mg'ì—ì„œ 'g'ë¡œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.",
    "law_reference": ""
  }
  
  **ì˜ˆì‹œ 4: ì²¨ê°€ë¬¼ ìš©ë„ ëˆ„ë½**
  {
    "type": "Missing_Info",
    "location": "ì›ì¬ë£Œëª…",
    "issue": "ì²¨ê°€ë¬¼ ìœ í˜•ì´ ë¹ ì§",
    "expected": "ì†Œë¸Œì‚°ì¹¼ë¥¨(ë³´ì¡´ë£Œ)",
    "actual": "ì†Œë¸Œì‚°ì¹¼ë¥¨",
    "suggestion": "ì²¨ê°€ë¬¼ ìš©ë„ë¥¼ ì¶”ê°€í•˜ì—¬ 'ì†Œë¸Œì‚°ì¹¼ë¥¨(ë³´ì¡´ë£Œ)'ë¡œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.",
    "law_reference": "ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ì— ì˜ê±° ëª…ì¹­ê³¼ ìš©ë„ë¥¼ í•¨ê»˜ í‘œì‹œí•´ì•¼ í•˜ëŠ” ì²¨ê°€ë¬¼"
  }
  
  **ì˜ˆì‹œ 5: ì›ì‚°ì§€ êµµê²Œ í‘œì‹œ ëˆ„ë½**
  {
    "type": "Formatting_Error",
    "location": "ì›ì¬ë£Œëª…",
    "issue": "ì›ì‚°ì§€ êµµê²Œë¯¸í‘œì‹œ",
    "expected": "ë‹¹ê·¼(**êµ­ë‚´ì‚°**)",
    "actual": "ë‹¹ê·¼(êµ­ë‚´ì‚°)",
    "suggestion": "ì›ì‚°ì§€ 'êµ­ë‚´ì‚°' ë¶€ë¶„ì„ êµµê²Œ í‘œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.",
    "law_reference": ""
  }
  
  **ì˜ˆì‹œ 6: ë„ì–´ì“°ê¸° ì˜¤ë¥˜**
  {
    "type": "Formatting_Error",
    "location": "ì œì¡°ì› / ì†Œì¬ì§€",
    "issue": "ë„ì–´ì“°ê¸° ì˜¤ë¥˜: '/' ì•ë’¤ ê³µë°±ì´ ê¸°ì¤€ì„œì™€ ë‹¤ë¦…ë‹ˆë‹¤.",
    "expected": "ì œì¡°ì› / ì†Œì¬ì§€",
    "actual": "ì œì¡°ì›/ì†Œì¬ì§€",
    "suggestion": "ì œì¡°ì›ê³¼ ì†Œì¬ì§€ ì‚¬ì´ì˜ '/' ì•ë’¤ì— ê³µë°±ì„ ì¶”ê°€í•˜ì—¬ 'ì œì¡°ì› / ì†Œì¬ì§€'ë¡œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.",
    "law_reference": ""
  }
  
  **ì˜ˆì‹œ 7: ê¸°í˜¸ ì¶”ê°€ ì˜¤ë¥˜**
  {
    "type": "Extra_Info",
    "location": "ì£¼ì˜ì‚¬í•­",
    "issue": "ë¬¸êµ¬ ì‹œì‘ ë¶€ë¶„ì— 'â— ' ê¸°í˜¸ê°€ ê¸°ì¤€ì„œì— ì—†ìŠµë‹ˆë‹¤.",
    "expected": "ì£¼ì˜ì‚¬í•­ ë°˜ë“œì‹œ ëƒ‰ì¥ë³´ê´€í•˜ì‹œê³ ...",
    "actual": "â— ì£¼ì˜ì‚¬í•­ ë°˜ë“œì‹œ ëƒ‰ì¥ë³´ê´€í•˜ì‹œê³ ...",
    "suggestion": "ê¸°ì¤€ì„œì— ë”°ë¼ 'â— ' ê¸°í˜¸ë¥¼ ì œê±°í•˜ê±°ë‚˜ ê¸°ì¤€ì„œì— í•´ë‹¹ ê¸°í˜¸ë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.",
    "law_reference": ""
  }
}
"""





# --- íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ---

def process_file_to_part(file_storage):
    """íŒŒì¼ì„ Geminiê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” Part ê°ì²´ë¡œ ë³€í™˜"""
    mime_type = file_storage.mimetype
    file_data = file_storage.read()
    file_storage.seek(0)  # í¬ì¸í„° ì´ˆê¸°í™”

    # ì—‘ì…€ íŒŒì¼ì€ í…ìŠ¤íŠ¸(CSV)ë¡œ ë³€í™˜í•´ì„œ ì£¼ëŠ”ê²Œ AIê°€ ë” ì˜ ì´í•´í•¨
    if mime_type in ['application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'application/vnd.ms-excel']:
        try:
            df = pd.read_excel(io.BytesIO(file_data))
            csv_text = df.to_csv(index=False)
            return {"text": f"--- [Excel ë°°í•©ë¹„ ë°ì´í„°] ---\n{csv_text}"}
        except Exception as e:
            print(f"ì—‘ì…€ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None

    # [NEW] ì´ë¯¸ì§€ íŒŒì¼ì¸ ê²½ìš°: ì„ ëª…ë„ ë³´ì • (OCR ì •í™•ë„ UP)
    if mime_type.startswith('image/'):
        try:
            img = PIL.Image.open(io.BytesIO(file_data))

            # 1. í‘ë°± ë³€í™˜ (ê¸€ì ìœ¤ê³½ ê°•ì¡°)
            img = img.convert('L')

            # 2. ëŒ€ë¹„(Contrast) 2ë°° ì¦ê°€
            enhancer = PIL.ImageEnhance.Contrast(img)
            img = enhancer.enhance(2.0)

            # 3. ì„ ëª…ë„(Sharpness) 1.5ë°° ì¦ê°€
            enhancer = PIL.ImageEnhance.Sharpness(img)
            img = enhancer.enhance(1.5)

            # ë³´ì •ëœ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ë°”ì´íŠ¸ë¡œ ë³€í™˜
            byte_io = io.BytesIO()
            # ì›ë³¸ í¬ë§· ìœ ì§€í•˜ë˜, ì—†ìœ¼ë©´ JPEG ì‚¬ìš©
            fmt = img.format if img.format else 'JPEG'
            img.save(byte_io, format=fmt)
            byte_io.seek(0)

            return {"mime_type": mime_type, "data": byte_io.read()}

        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ë³´ì • ì‹¤íŒ¨ (ì›ë³¸ ì‚¬ìš©): {e}")
            # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            return {"mime_type": mime_type, "data": file_data}

    # PDF ë“± ê¸°íƒ€ íŒŒì¼ì€ ê·¸ëŒ€ë¡œ ì „ë‹¬
    return {"mime_type": mime_type, "data": file_data}


def clean_html_text(text):
    """HTML íƒœê·¸ì™€ HTML ì½”ë“œë¥¼ ì™„ì „íˆ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ ë‚´ìš©(ë²•ë ¹ ë¬¸êµ¬ í¬í•¨)ë§Œ ìœ ì§€"""
    if not isinstance(text, str):
        return text
    
    # HTML ì—”í‹°í‹° ë””ì½”ë”© ë¨¼ì € ìˆ˜í–‰ (ì˜ˆ: &lt; â†’ <, &gt; â†’ >, &amp; â†’ &)
    text = unescape(text)
    
    # HTML ì½”ë“œ ë¸”ë¡ íŒ¨í„´ ì œê±° (ì˜ˆ: "<div style=\"margin-top:12px;\">...</div>")
    # ì—¬ëŸ¬ ì¤„ì— ê±¸ì¹œ HTML ì½”ë“œë„ ì œê±°
    text = re.sub(r'<div[^>]*>.*?</div>', '', text, flags=re.DOTALL | re.IGNORECASE)
    text = re.sub(r'<ul[^>]*>.*?</ul>', '', text, flags=re.DOTALL | re.IGNORECASE)
    text = re.sub(r'<li[^>]*>.*?</li>', '', text, flags=re.DOTALL | re.IGNORECASE)
    
    # HTML íƒœê·¸ ì™„ì „íˆ ì œê±° (ë‚´ìš©ì€ ìœ ì§€)
    # ì˜ˆ: "<div>ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ ì œXì¡° ìœ„ë°˜</div>" â†’ "ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ ì œXì¡° ìœ„ë°˜"
    text = re.sub(r'<[^>]+>', '', text)
    
    # HTML ì½”ë“œ íŒ¨í„´ ì œê±° (ì˜ˆ: "<div style=...>", "<ul style=...>" ë“±)
    text = re.sub(r'<div[^>]*>', '', text, flags=re.IGNORECASE)
    text = re.sub(r'</div>', '', text, flags=re.IGNORECASE)
    text = re.sub(r'<ul[^>]*>', '', text, flags=re.IGNORECASE)
    text = re.sub(r'</ul>', '', text, flags=re.IGNORECASE)
    text = re.sub(r'<li[^>]*>', '', text, flags=re.IGNORECASE)
    text = re.sub(r'</li>', '', text, flags=re.IGNORECASE)
    text = re.sub(r'<[^>]+>', '', text)  # ë‚¨ì€ ëª¨ë“  HTML íƒœê·¸ ì œê±°
    
    # HTML ì†ì„± íŒ¨í„´ ì œê±° (ì˜ˆ: "style=\"margin-top:12px;\"")
    text = re.sub(r'style\s*=\s*["\'][^"\']*["\']', '', text, flags=re.IGNORECASE)
    text = re.sub(r'font-weight\s*:\s*\d+', '', text, flags=re.IGNORECASE)
    text = re.sub(r'margin[^;]*;?', '', text, flags=re.IGNORECASE)
    text = re.sub(r'padding[^;]*;?', '', text, flags=re.IGNORECASE)
    text = re.sub(r'color[^;]*;?', '', text, flags=re.IGNORECASE)
    text = re.sub(r'font-size[^;]*;?', '', text, flags=re.IGNORECASE)
    
    # ì—°ì†ëœ ê³µë°±ë§Œ ì •ë¦¬ (ì¤„ë°”ê¿ˆê³¼ ë‚´ìš©ì€ ë³´ì¡´)
    text = re.sub(r'[ \t]+', ' ', text)  # íƒ­ê³¼ ê³µë°±ë§Œ ì •ë¦¬
    text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)  # 3ê°œ ì´ìƒì˜ ì—°ì† ì¤„ë°”ê¿ˆë§Œ 2ê°œë¡œ
    
    return text.strip()

def detect_label_area(image_file):
    """ì´ë¯¸ì§€ì—ì„œ ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  í¬ë¡­"""
    try:
        image_data = image_file.read()
        image_file.seek(0)
        
        img_pil = PIL.Image.open(io.BytesIO(image_data))
        original_size = img_pil.size
        
        # AIì—ê²Œ ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ ì°¾ê¸° ìš”ì²­
        model = genai.GenerativeModel(MODEL_NAME)
        
        detection_prompt = """
ì´ ì´ë¯¸ì§€ëŠ” ì‹í’ˆ í¬ì¥ì§€ ë””ìì¸ì…ë‹ˆë‹¤.
ì´ë¯¸ì§€ì—ì„œ **ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­**ë§Œ ì°¾ì•„ì£¼ì„¸ìš”.

ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ì€ ë‹¤ìŒ ì •ë³´ê°€ í¬í•¨ëœ ì‚¬ê°í˜• ì˜ì—­ì…ë‹ˆë‹¤:
- ì œí’ˆëª…, ì‹í’ˆìœ í˜•, ë‚´ìš©ëŸ‰
- ì›ì¬ë£Œëª…
- ì˜ì–‘ì •ë³´
- ì•Œë ˆë¥´ê¸° ì •ë³´
- ì œì¡°ì› ì •ë³´
- ì£¼ì˜ì‚¬í•­

**ë¬´ì‹œí•  ì˜ì—­:**
- ë¸Œëœë“œ ë¡œê³ 
- ì œí’ˆ ì‚¬ì§„
- ì¡°ë¦¬ë²•/ë ˆì‹œí”¼
- í™ë³´ ë¬¸êµ¬
- ì¥ì‹ ìš”ì†Œ

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{
    "found": true/false,
    "bbox": {
        "x1": ì™¼ìª½ ìƒë‹¨ X ì¢Œí‘œ (í”½ì…€),
        "y1": ì™¼ìª½ ìƒë‹¨ Y ì¢Œí‘œ (í”½ì…€),
        "x2": ì˜¤ë¥¸ìª½ í•˜ë‹¨ X ì¢Œí‘œ (í”½ì…€),
        "y2": ì˜¤ë¥¸ìª½ í•˜ë‹¨ Y ì¢Œí‘œ (í”½ì…€)
    },
    "description": "ì°¾ì€ ì˜ì—­ ì„¤ëª…"
}

ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ "found": falseë¡œ ì‘ë‹µí•˜ì„¸ìš”.
"""
        
        response = model.generate_content([detection_prompt, img_pil])
        result_text = response.text.strip()
        
        # JSON íŒŒì‹±
        if result_text.startswith("```json"):
            result_text = result_text[7:-3]
        elif result_text.startswith("```"):
            lines = result_text.split("\n")
            if lines[0].startswith("```"):
                result_text = "\n".join(lines[1:-1])
        
        detection_result = json.loads(result_text)
        
        if detection_result.get("found", False) and "bbox" in detection_result:
            bbox = detection_result["bbox"]
            x1 = max(0, int(bbox.get("x1", 0)))
            y1 = max(0, int(bbox.get("y1", 0)))
            x2 = min(original_size[0], int(bbox.get("x2", original_size[0])))
            y2 = min(original_size[1], int(bbox.get("y2", original_size[1])))
            
            # ì˜ì—­ í¬ë¡­
            cropped_img = img_pil.crop((x1, y1, x2, y2))
            print(f"âœ… ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ ê°ì§€: ({x1}, {y1}) ~ ({x2}, {y2}), í¬ê¸°: {cropped_img.size}")
            
            # í¬ë¡­ëœ ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
            output = io.BytesIO()
            cropped_img.save(output, format='PNG')
            output.seek(0)
            
            return output, True
        else:
            print("âš ï¸ ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì „ì²´ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            image_file.seek(0)
            return image_file, False
            
    except Exception as e:
        print(f"âŒ ì˜ì—­ ê°ì§€ ì‹¤íŒ¨: {e}, ì „ì²´ ì´ë¯¸ì§€ ì‚¬ìš©")
        image_file.seek(0)
        return image_file, False

def clean_ai_response(data):
    """AI ì‘ë‹µì—ì„œ HTML íƒœê·¸ë¥¼ ì œê±°í•˜ê³  ì •ë¦¬"""
    if isinstance(data, dict):
        cleaned = {}
        for key, value in data.items():
            if key == 'violations' and isinstance(value, list):
                # violations ë°°ì—´ì˜ ê° í•­ëª©ì—ì„œ HTML ì œê±°
                cleaned_violations = []
                for item in value:
                    if isinstance(item, dict):
                        # ê°ì²´ì¸ ê²½ìš°
                        cleaned_item = {}
                        for k, v in item.items():
                            if isinstance(v, str):
                                cleaned_item[k] = clean_html_text(v)
                            else:
                                cleaned_item[k] = v
                        cleaned_violations.append(cleaned_item)
                    else:
                        # ë¬¸ìì—´ì¸ ê²½ìš°
                        cleaned_violations.append(clean_html_text(item))
                cleaned[key] = cleaned_violations
            elif key == 'issues' and isinstance(value, list):
                # issues ë°°ì—´ì˜ ê° í•­ëª© ì²˜ë¦¬
                cleaned[key] = []
                for item in value:
                    if isinstance(item, dict):
                        cleaned_item = {}
                        for k, v in item.items():
                            cleaned_item[k] = clean_html_text(v) if isinstance(v, str) else v
                        cleaned[key].append(cleaned_item)
                    else:
                        cleaned[key].append(clean_html_text(item) if isinstance(item, str) else item)
            elif isinstance(value, str):
                cleaned[key] = clean_html_text(value)
            elif isinstance(value, (dict, list)):
                cleaned[key] = clean_ai_response(value)
            else:
                cleaned[key] = value
        return cleaned
    elif isinstance(data, list):
        return [clean_ai_response(item) for item in data]
    else:
        return clean_html_text(data) if isinstance(data, str) else data

def extract_ingredient_info_from_image(image_file):
    """ì›ì¬ë£Œ í‘œì‹œì‚¬í•­ ì´ë¯¸ì§€ì—ì„œ í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ"""
    try:
        image_data = image_file.read()
        image_file.seek(0)
        
        img_pil = PIL.Image.open(io.BytesIO(image_data))
        model = genai.GenerativeModel(MODEL_NAME)
        
        parts = [PROMPT_EXTRACT_INGREDIENT_INFO, img_pil]
        response = model.generate_content(parts)
        
        result_text = response.text.strip()
        # JSON íŒŒì‹±
        if result_text.startswith("```json"):
            result_text = result_text[7:-3]
        elif result_text.startswith("```"):
            result_text = result_text.split("```")[1].strip()
            if result_text.startswith("json"):
                result_text = result_text[4:].strip()
        
        return json.loads(result_text)
    except json.JSONDecodeError as e:
        print(f"ì›ì¬ë£Œ ì •ë³´ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        print(f"ì‘ë‹µ í…ìŠ¤íŠ¸: {result_text[:500]}...")
        return None
    except Exception as e:
        print(f"ì›ì¬ë£Œ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return None

def create_standard_excel(data):
    """ê¸°ì¤€ ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ìƒì„±"""
    output = io.BytesIO()
    
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        # 1. ì œí’ˆ ì •ë³´ ì‹œíŠ¸
        if 'product_info' in data:
            product_df = pd.DataFrame([data['product_info']])
            product_df.to_excel(writer, sheet_name='ì œí’ˆì •ë³´', index=False)
        
        # 2. ì›ì¬ë£Œëª… ì‹œíŠ¸
        if 'ingredients' in data:
            ingredients_data = []
            if 'structured_list' in data['ingredients']:
                for idx, item in enumerate(data['ingredients']['structured_list'], 1):
                    ingredients_data.append({
                        'ìˆœë²ˆ': idx,
                        'ì›ì¬ë£Œëª…': item
                    })
            ingredients_df = pd.DataFrame(ingredients_data)
            if not ingredients_df.empty:
                ingredients_df.to_excel(writer, sheet_name='ì›ì¬ë£Œëª…', index=False)
            
            # ì—°ì† í…ìŠ¤íŠ¸ë„ ì¶”ê°€
            if 'continuous_text' in data['ingredients']:
                continuous_df = pd.DataFrame([{
                    'ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸': data['ingredients']['continuous_text']
                }])
                continuous_df.to_excel(writer, sheet_name='ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸', index=False)
        
        # 3. ì•Œë ˆë¥´ê¸° ì •ë³´ ì‹œíŠ¸
        if 'allergens' in data:
            allergens_data = []
            if 'contains' in data['allergens']:
                allergens_data.append({
                    'í•­ëª©': 'í•¨ìœ  ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ',
                    'ë‚´ìš©': ', '.join(data['allergens']['contains'])
                })
            if 'manufacturing_facility' in data['allergens']:
                allergens_data.append({
                    'í•­ëª©': 'ì œì¡°ì‹œì„¤ ì•ˆë‚´',
                    'ë‚´ìš©': data['allergens']['manufacturing_facility']
                })
            if allergens_data:
                allergens_df = pd.DataFrame(allergens_data)
                allergens_df.to_excel(writer, sheet_name='ì•Œë ˆë¥´ê¸°ì •ë³´', index=False)
        
        # 4. ì˜ì–‘ì •ë³´ ì‹œíŠ¸
        if 'nutrition_info' in data and 'per_100g' in data['nutrition_info']:
            nutrition_data = []
            nut = data['nutrition_info']['per_100g']
            if 'calories' in nut:
                nutrition_data.append({
                    'ì˜ì–‘ì„±ë¶„': 'ì´ ì—´ëŸ‰',
                    '100g ë‹¹': nut['calories'],
                    '1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)': '-'
                })
            for key, value in nut.items():
                if key != 'calories' and isinstance(value, dict):
                    nutrition_data.append({
                        'ì˜ì–‘ì„±ë¶„': key,
                        '100g ë‹¹': value.get('amount', ''),
                        '1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)': value.get('daily_value', '')
                    })
            if nutrition_data:
                nutrition_df = pd.DataFrame(nutrition_data)
                nutrition_df.to_excel(writer, sheet_name='ì˜ì–‘ì •ë³´', index=False)
        
        # 5. ì œì¡°ì› ì •ë³´ ì‹œíŠ¸
        if 'manufacturer' in data:
            manufacturer_df = pd.DataFrame([data['manufacturer']])
            manufacturer_df.to_excel(writer, sheet_name='ì œì¡°ì›ì •ë³´', index=False)
        
        # 6. ì£¼ì˜ì‚¬í•­ ì‹œíŠ¸
        if 'precautions' in data:
            precautions_df = pd.DataFrame([{'ì£¼ì˜ì‚¬í•­': item} for item in data['precautions']])
            precautions_df.to_excel(writer, sheet_name='ì£¼ì˜ì‚¬í•­', index=False)
        
        # 7. ìƒì„¸ ì •ë³´ ì‹œíŠ¸ (ì›ì¬ë£Œ ìƒì„¸)
        if 'details' in data and data['details']:
            details_df = pd.DataFrame(data['details'])
            details_df.to_excel(writer, sheet_name='ì›ì¬ë£Œìƒì„¸', index=False)
    
    output.seek(0)
    return output


# --- ë¼ìš°íŠ¸ ---

@app.route('/')
def index():
    return render_template('index.html')


# 1ë‹¨ê³„: ì •ë‹µì§€ ë§Œë“¤ê¸° (ì—‘ì…€ + ì›ì¬ë£Œ ì‚¬ì§„ë“¤ ëª½ë•…)
@app.route('/api/create-standard', methods=['POST'])
def create_standard():
    print("âš™ï¸ 1ë‹¨ê³„: ê¸°ì¤€ ë°ì´í„° ìƒì„± ì‹œì‘...")

    # 1. ì—‘ì…€ íŒŒì¼ (ë°°í•©ë¹„)
    excel_file = request.files.get('excel_file')

    # 2. ì›ì¬ë£Œ ì´ë¯¸ì§€ë“¤ (ì—¬ëŸ¬ ê°œ)
    raw_images = request.files.getlist('raw_images')

    if not excel_file:
        return jsonify({"error": "ë°°í•©ë¹„ ì—‘ì…€ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    # AIì—ê²Œ ë³´ë‚¼ ë°ì´í„° ê¾¸ëŸ¬ë¯¸ ë§Œë“¤ê¸°
    parts = []

    # (1) í”„ë¡¬í”„íŠ¸ + ë²•ë ¹ ì •ë³´
    enhanced_prompt = PROMPT_CREATE_STANDARD
    if ALL_LAW_TEXT:
        enhanced_prompt += f"\n\n--- [ì°¸ê³  ë²•ë ¹] ---\n{ALL_LAW_TEXT}\n--- [ë²•ë ¹ ë] ---\n"
    parts.append(enhanced_prompt)

    # (2) ì—‘ì…€ ë°ì´í„°
    excel_part = process_file_to_part(excel_file)
    if excel_part: parts.append(excel_part)

    # (3) ì›ì¬ë£Œ ì‚¬ì§„ë“¤ - í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ
    ingredient_info_list = []
    for img in raw_images[:15]:
        print(f"ğŸ“· ì›ì¬ë£Œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘: {img.filename}")
        ingredient_info = extract_ingredient_info_from_image(img)
        if ingredient_info:
            ingredient_info_list.append(ingredient_info)
    
    # ì¶”ì¶œëœ ì›ì¬ë£Œ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ê°€
    if ingredient_info_list:
        ingredients_text = "--- [ì›ì¬ë£Œ í‘œì‹œì‚¬í•­ì—ì„œ ì¶”ì¶œí•œ ì •ë³´] ---\n"
        for idx, info in enumerate(ingredient_info_list, 1):
            ingredients_text += f"\n[ì›ì¬ë£Œ {idx}]\n"
            ingredients_text += json.dumps(info, ensure_ascii=False, indent=2)
            ingredients_text += "\n"
        ingredients_text += "--- [ì›ì¬ë£Œ ì •ë³´ ë] ---\n"
        parts.append({"text": ingredients_text})

    print(f"ğŸ“‚ ì²˜ë¦¬ ì¤‘: ì—‘ì…€ 1ê°œ + ì›ì¬ë£Œ ì´ë¯¸ì§€ {len(raw_images)}ì¥ (ì •ë³´ ì¶”ì¶œ ì™„ë£Œ)")

    try:
        # [ìˆ˜ì •í•  ë¶€ë¶„] ì°½ì˜ì„±(Temperature) 0ìœ¼ë¡œ ì„¤ì •í•´ì„œ ë¡œë´‡ì²˜ëŸ¼ ë§Œë“¤ê¸°
        generation_config = {"temperature": 0.0}
        model = genai.GenerativeModel(MODEL_NAME, generation_config=generation_config)

        response = model.generate_content(parts)

        # JSON íŒŒì‹±
        result_text = response.text.strip()
        
        # JSON ì½”ë“œ ë¸”ë¡ ì œê±°
        if result_text.startswith("```json"):
            result_text = result_text[7:]
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        elif result_text.startswith("```"):
            # ``` ... ``` í˜•ì‹ ì²˜ë¦¬
            lines = result_text.split("\n")
            if lines[0].startswith("```"):
                result_text = "\n".join(lines[1:])
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        
        result_text = result_text.strip()
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            result = json.loads(result_text)
        except json.JSONDecodeError as json_err:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {json_err}")
            print(f"ì‘ë‹µ í…ìŠ¤íŠ¸ (ì²˜ìŒ 1000ì): {result_text[:1000]}")
            print(f"ì˜¤ë¥˜ ìœ„ì¹˜: line {json_err.lineno}, column {json_err.colno}")
            # JSON ìˆ˜ì • ì‹œë„ (ë§ˆì§€ë§‰ ì‰¼í‘œ ì œê±° ë“±)
            try:
                # ë§ˆì§€ë§‰ ì‰¼í‘œ ì œê±° ì‹œë„
                result_text_fixed = result_text.replace(',\n}', '\n}').replace(',\n]', '\n]')
                result = json.loads(result_text_fixed)
                print("âœ… JSON ìˆ˜ì • í›„ íŒŒì‹± ì„±ê³µ")
            except:
                return jsonify({"error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(json_err)}. ì‘ë‹µì˜ ì¼ë¶€: {result_text[:200]}..."}), 500
        
        return jsonify(result)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# ê¸°ì¤€ ë°ì´í„° ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
@app.route('/api/download-standard-excel', methods=['POST'])
def download_standard_excel():
    """ê¸°ì¤€ ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "ê¸°ì¤€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400
        
        excel_buffer = create_standard_excel(data)
        product_name = data.get('product_info', {}).get('product_name', 'ê¸°ì¤€ë°ì´í„°') or data.get('product_name', 'ê¸°ì¤€ë°ì´í„°')
        filename = f"{product_name}_ê¸°ì¤€ë°ì´í„°.xlsx"
        
        return send_file(
            excel_buffer,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name=filename
        )
    except Exception as e:
        print(f"âŒ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

# ì—‘ì…€ íŒŒì¼ì—ì„œ ê¸°ì¤€ ë°ì´í„° ì½ê¸°
@app.route('/api/read-standard-excel', methods=['POST'])
def read_standard_excel():
    """ì—‘ì…€ íŒŒì¼ì—ì„œ ê¸°ì¤€ ë°ì´í„°ë¥¼ ì½ì–´ì˜´"""
    try:
        excel_file = request.files.get('excel_file')
        if not excel_file:
            return jsonify({"error": "ì—‘ì…€ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        df_dict = pd.read_excel(io.BytesIO(excel_file.read()), sheet_name=None, engine='openpyxl')
        
        # ì—‘ì…€ ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        result = {}
        
        if 'ì œí’ˆì •ë³´' in df_dict:
            product_info = df_dict['ì œí’ˆì •ë³´'].to_dict('records')[0]
            result['product_info'] = product_info
        
        # ì²« ë²ˆì§¸ ì‹œíŠ¸ë¥¼ ìš°ì„  ì‚¬ìš©
        first_sheet_name = list(df_dict.keys())[0]
        first_sheet_df = df_dict[first_sheet_name]
        
        # ì›ì¬ë£Œëª… ì²˜ë¦¬ (ì‹œíŠ¸ ì´ë¦„ì— ê´€ê³„ì—†ì´ ì²« ë²ˆì§¸ ì‹œíŠ¸ ì‚¬ìš©)
        if 'ì›ì¬ë£Œëª…' in df_dict:
            ingredients_list = df_dict['ì›ì¬ë£Œëª…']['ì›ì¬ë£Œëª…'].dropna().tolist()
            result['ingredients'] = {
                'structured_list': ingredients_list,
                'continuous_text': ', '.join(ingredients_list)
            }
        elif 'ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸' in df_dict:
            continuous_text = df_dict['ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸']['ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸'].iloc[0]
            result['ingredients'] = {
                'structured_list': continuous_text.split(', '),
                'continuous_text': continuous_text
            }
        elif not first_sheet_df.empty:
            # ì²« ë²ˆì§¸ ì‹œíŠ¸ì˜ ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ ì›ì¬ë£Œëª…ìœ¼ë¡œ ì‚¬ìš©
            first_column = first_sheet_df.columns[0]
            if 'ì›ì¬ë£Œëª…' in first_sheet_df.columns:
                ingredients_list = first_sheet_df['ì›ì¬ë£Œëª…'].dropna().tolist()
            else:
                ingredients_list = first_sheet_df[first_column].dropna().astype(str).tolist()
            
            if ingredients_list:
                result['ingredients'] = {
                    'structured_list': ingredients_list,
                    'continuous_text': ', '.join(ingredients_list)
                }
        
        if 'ì•Œë ˆë¥´ê¸°ì •ë³´' in df_dict:
            allergens_df = df_dict['ì•Œë ˆë¥´ê¸°ì •ë³´']
            result['allergens'] = {}
            for _, row in allergens_df.iterrows():
                if row['í•­ëª©'] == 'í•¨ìœ  ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ':
                    result['allergens']['contains'] = row['ë‚´ìš©'].split(', ')
                elif row['í•­ëª©'] == 'ì œì¡°ì‹œì„¤ ì•ˆë‚´':
                    result['allergens']['manufacturing_facility'] = row['ë‚´ìš©']
        
        if 'ì˜ì–‘ì •ë³´' in df_dict:
            nutrition_df = df_dict['ì˜ì–‘ì •ë³´']
            per_100g = {}
            for _, row in nutrition_df.iterrows():
                if row['ì˜ì–‘ì„±ë¶„'] == 'ì´ ì—´ëŸ‰':
                    per_100g['calories'] = row['100g ë‹¹']
                else:
                    per_100g[row['ì˜ì–‘ì„±ë¶„']] = {
                        'amount': row['100g ë‹¹'],
                        'daily_value': row['1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)']
                    }
            result['nutrition_info'] = {'per_100g': per_100g}
        
        if 'ì œì¡°ì›ì •ë³´' in df_dict:
            result['manufacturer'] = df_dict['ì œì¡°ì›ì •ë³´'].to_dict('records')[0]
        
        if 'ì£¼ì˜ì‚¬í•­' in df_dict:
            result['precautions'] = df_dict['ì£¼ì˜ì‚¬í•­']['ì£¼ì˜ì‚¬í•­'].tolist()
        
        if 'ì›ì¬ë£Œìƒì„¸' in df_dict:
            result['details'] = df_dict['ì›ì¬ë£Œìƒì„¸'].to_dict('records')
        
        return jsonify(result)
    except Exception as e:
        print(f"âŒ ì—‘ì…€ ì½ê¸° ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

# 2ë‹¨ê³„: ê²€ì¦í•˜ê¸° (ì—‘ì…€ íŒŒì¼ ë˜ëŠ” JSON + ë””ìì¸ ì´ë¯¸ì§€)
@app.route('/api/verify-design', methods=['POST'])
def verify_design():
    print("ğŸ•µï¸â€â™‚ï¸ 2ë‹¨ê³„: ë””ìì¸ ê²€ì¦ ì‹œì‘...")

    # 1. íŒŒì¼ ë°›ê¸°
    design_file = request.files.get('design_file')
    standard_excel = request.files.get('standard_excel')
    standard_json = request.form.get('standard_data')

    if not design_file:
        return jsonify({"error": "ë””ìì¸ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    # 2. ê¸°ì¤€ ë°ì´í„° ë¡œë”© (ì—‘ì…€ -> JSON)
    if standard_excel:
        try:
            df_dict = pd.read_excel(io.BytesIO(standard_excel.read()), sheet_name=None, engine='openpyxl')
            first_sheet_name = list(df_dict.keys())[0]
            first_sheet_df = df_dict[first_sheet_name]

            standard_data = {}
            if not first_sheet_df.empty:
                # ì›ì¬ë£Œëª… ì»¬ëŸ¼ ì°¾ê¸° (ë‹¨ìˆœí™”)
                col = first_sheet_df.columns[0]
                if 'ì›ì¬ë£Œëª…' in first_sheet_df.columns: col = 'ì›ì¬ë£Œëª…'

                ingredients_list = first_sheet_df[col].dropna().astype(str).tolist()
                standard_data = {'ingredients': {'structured_list': ingredients_list,
                                                 'continuous_text': ', '.join(ingredients_list)}}

            standard_json = json.dumps(standard_data, ensure_ascii=False)
        except Exception as e:
            return jsonify({"error": f"ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨: {str(e)}"}), 400

    # 3. ë²•ë ¹ íŒŒì¼ ì½ê¸° (ìˆ˜ì •ë¨: ëª¨ë“  ë²•ë ¹ íŒŒì¼ ë™ë“±í•˜ê²Œ ë¡œë”©)
    law_text = ""

    # (1) í˜„ì¬ í´ë”ì˜ ëª¨ë“  'law_'ë¡œ ì‹œì‘í•˜ëŠ” txt íŒŒì¼ ì°¾ê¸°
    # law_context.txt, law_text_ì‹í’ˆìœ„ìƒë²•.txt ë“± ëª¨ë‘ í¬í•¨ë¨
    all_law_files = glob.glob('law_*.txt')

    print(f"ğŸ“š ë²•ë ¹ íŒŒì¼ ë¡œë”© ì¤‘: {len(all_law_files)}ê°œ ë°œê²¬")

    for file_path in all_law_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                # ê° ë²•ë ¹ íŒŒì¼ ë‚´ìš©ì„ ëª…í™•íˆ êµ¬ë¶„í•´ì„œ í•©ì¹˜ê¸°
                law_text += f"\n\n=== [ì°¸ê³  ë²•ë ¹: {file_path}] ===\n{content}\n==========================\n"
        except Exception as e:
            print(f"âš ï¸ ë²•ë ¹ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ ({file_path}): {e}")

    # 4. AI í”„ë¡¬í”„íŠ¸ ì¡°ë¦½
    parts = [f"""
    {PROMPT_VERIFY_DESIGN}

    [ì°¸ê³  ë²•ë ¹]
    {law_text[:60000]}

    [ê¸°ì¤€ ë°ì´í„°]
    {standard_json}
    """]

    if design_file:
        # ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ë§Œ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  í¬ë¡­
        print("ğŸ” ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ ìë™ ê°ì§€ ì¤‘...")
        cropped_image, is_cropped = detect_label_area(design_file)
        
        if is_cropped:
            print("âœ‚ï¸ ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ë§Œ í¬ë¡­í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            # í¬ë¡­ëœ ì´ë¯¸ì§€ë¥¼ PIL Imageë¡œ ë³€í™˜
            cropped_image.seek(0)
            cropped_pil = PIL.Image.open(cropped_image)
            parts.append(cropped_pil)
        else:
            print("ğŸ“„ ì „ì²´ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            parts.append(process_file_to_part(design_file))

    # 5. AI í˜¸ì¶œ ë° ê²°ê³¼ ì²˜ë¦¬ (ì—¬ê¸°ê°€ ì¤‘ìš”)
    try:
        # ì°½ì˜ì„± 0.0 ì„¤ì • (ì •ê·œì„± í™•ë³´)
        model = genai.GenerativeModel(
            MODEL_NAME,
            generation_config={"temperature": 0.0}
        )

        response = model.generate_content(parts)
        result_text = response.text.strip()

        # [ê°•ë ¥í•œ JSON íŒŒì‹± ë¡œì§] ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ JSONë§Œ ì¶”ì¶œ
        json_match = re.search(r"(\{.*\})", result_text, re.DOTALL)

        if json_match:
            clean_json = json_match.group(1)
            # ê°„ë‹¨í•œ ì‰¼í‘œ ë³´ì •
            clean_json = clean_json.replace(",\n}", "\n}").replace(",\n]", "\n]")
            result = json.loads(clean_json)
            # HTML íƒœê·¸ ì œê±°
            result = clean_ai_response(result)
            return jsonify(result)
        else:
            # JSON íŒ¨í„´ ëª» ì°¾ìœ¼ë©´ ì›ë³¸ì—ì„œ ì‹œë„ (í˜¹ì‹œ ëª¨ë¥´ë‹ˆ)
            clean_json = result_text.replace("``````", "").strip()
            result = json.loads(clean_json)
            # HTML íƒœê·¸ ì œê±°
            result = clean_ai_response(result)
            return jsonify(result)

    except Exception as e:
        print(f"âŒ ê²€ì¦ ì˜¤ë¥˜: {e}")
        # ìƒì„¸ ì—ëŸ¬ ë¡œê·¸ ì¶œë ¥
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# QA ìë£Œ ì—…ë¡œë“œ ë° ì‹í’ˆí‘œì‹œì‚¬í•­ ì‘ì„± API
@app.route('/api/upload-qa', methods=['POST'])
def upload_qa():
    """QA ìë£Œë¥¼ ì—…ë¡œë“œí•˜ê³  ì‹í’ˆí‘œì‹œì‚¬í•­ì„ ì‘ì„±í•©ë‹ˆë‹¤."""
    print("ğŸ“‹ QA ìë£Œ ì—…ë¡œë“œ ë° ì‹í’ˆí‘œì‹œì‚¬í•­ ì‘ì„± ì‹œì‘...")
    
    # QA ìë£Œ íŒŒì¼ë“¤ (ì—‘ì…€, ì´ë¯¸ì§€ ë“±)
    qa_files = request.files.getlist('qa_files')
    
    if not qa_files or len(qa_files) == 0:
        return jsonify({"error": "QA ìë£Œ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    # AIì—ê²Œ ë³´ë‚¼ ë°ì´í„° ê¾¸ëŸ¬ë¯¸ ë§Œë“¤ê¸°
    parts = []
    
    qa_prompt = """
ë‹¹ì‹ ì€ ì‹í’ˆí‘œì‹œì‚¬í•­ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ QA ìë£Œë¥¼ ë¶„ì„í•˜ì—¬ ë²•ë¥ ì„ ì¤€ìˆ˜í•˜ëŠ” ì‹í’ˆí‘œì‹œì‚¬í•­ì„ ì‘ì„±í•˜ì„¸ìš”.

[ì‘ì—… ë‹¨ê³„]
1. QA ìë£Œ ë¶„ì„: ì—‘ì…€, ì´ë¯¸ì§€ ë“± ëª¨ë“  QA ìë£Œë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.
2. ë²•ë¥  ê²€í† : ì œê³µëœ ë²•ë ¹ì„ ì°¸ê³ í•˜ì—¬ í•„ìˆ˜ í‘œì‹œì‚¬í•­ì´ ëª¨ë‘ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
3. ì‹í’ˆí‘œì‹œì‚¬í•­ ì‘ì„±: ë²•ë¥ ì„ ì¤€ìˆ˜í•˜ëŠ” ì™„ì „í•œ ì‹í’ˆí‘œì‹œì‚¬í•­ì„ ì‘ì„±í•˜ì„¸ìš”.

[ì¶œë ¥ ì–‘ì‹ - JSON]
{
    "product_name": "ì œí’ˆëª…",
    "label_text": "ì‘ì„±ëœ ì‹í’ˆí‘œì‹œì‚¬í•­ ì „ì²´ í…ìŠ¤íŠ¸",
    "law_compliance": {
        "status": "compliant" | "needs_review",
        "issues": ["ë²•ë¥  ê²€í†  ì‚¬í•­ ëª©ë¡"]
    },
    "sections": {
        "ingredients": "ì›ì¬ë£Œëª…",
        "nutrition": "ì˜ì–‘ì •ë³´",
        "allergens": "ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ",
        "storage": "ë³´ê´€ë°©ë²•",
        "manufacturer": "ì œì¡°ì‚¬ ì •ë³´"
    }
}
"""
    
    # ë²•ë ¹ ì •ë³´ ì¶”ê°€
    if ALL_LAW_TEXT:
        qa_prompt += f"\n\n--- [ì°¸ê³  ë²•ë ¹] ---\n{ALL_LAW_TEXT}\n--- [ë²•ë ¹ ë] ---\n"
    
    parts.append(qa_prompt)
    
    # QA íŒŒì¼ë“¤ ì²˜ë¦¬
    for qa_file in qa_files[:20]:  # ìµœëŒ€ 20ê°œ íŒŒì¼
        file_part = process_file_to_part(qa_file)
        if file_part:
            parts.append(file_part)
    
    print(f"ğŸ“‚ QA ìë£Œ ì²˜ë¦¬ ì¤‘: {len(qa_files)}ê°œ íŒŒì¼")
    
    try:
        model = genai.GenerativeModel(MODEL_NAME)
        response = model.generate_content(parts)
        
        # JSON íŒŒì‹±
        result_text = response.text.strip()
        
        # JSON ì½”ë“œ ë¸”ë¡ ì œê±°
        if result_text.startswith("```json"):
            result_text = result_text[7:]
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        elif result_text.startswith("```"):
            lines = result_text.split("\n")
            if lines[0].startswith("```"):
                result_text = "\n".join(lines[1:])
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        
        result_text = result_text.strip()
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            result = json.loads(result_text)
        except json.JSONDecodeError as json_err:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {json_err}")
            print(f"ì‘ë‹µ í…ìŠ¤íŠ¸ (ì²˜ìŒ 1000ì): {result_text[:1000]}")
            print(f"ì˜¤ë¥˜ ìœ„ì¹˜: line {json_err.lineno}, column {json_err.colno}")
            # JSON ìˆ˜ì • ì‹œë„
            try:
                result_text_fixed = result_text.replace(',\n}', '\n}').replace(',\n]', '\n]')
                result = json.loads(result_text_fixed)
                print("âœ… JSON ìˆ˜ì • í›„ íŒŒì‹± ì„±ê³µ")
            except:
                return jsonify({"error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(json_err)}. ì‘ë‹µì˜ ì¼ë¶€: {result_text[:200]}..."}), 500
        
        return jsonify(result)
        
    except Exception as e:
        print(f"âŒ QA ìë£Œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


if __name__ == '__main__':
    print("ğŸš€ ì‚¼ì§„ì–´ë¬µ ì‹í’ˆí‘œì‹œì‚¬í•­ ì™„ì„± í”Œë«í¼ V3.0 ê°€ë™")
    print("   - ì›ë¶€ì¬ë£Œ í‘œì‹œì‚¬í•­ ìŠ¤ë§ˆíŠ¸ ì¶”ì¶œ")
    print("   - ë²•ë¥  ê²€í†  ê¸°ëŠ¥ í†µí•©")
    print("   - QA ìë£Œ ì—…ë¡œë“œ ì§€ì›")
    from waitress import serve

    serve(app, host='0.0.0.0', port=8080)
