import os
import json
import io
import glob
import traceback
import base64
import difflib

import pandas as pd
from flask import Flask, request, jsonify, render_template, send_file
from flask_cors import CORS
from dotenv import load_dotenv
from openai import OpenAI
import PIL.Image
import re
import html

# Optional OCR fallback (if installed)
try:
    import pytesseract
    TESSERACT_AVAILABLE = True
except Exception:
    TESSERACT_AVAILABLE = False

# Optional PDF->Image (if installed)
try:
    from pdf2image import convert_from_bytes
    PDF2IMAGE_AVAILABLE = True
except Exception:
    PDF2IMAGE_AVAILABLE = False

# --- ì„¤ì • ë° ì´ˆê¸°í™” ---
load_dotenv()
app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False  # í•œê¸€ ê¹¨ì§ ë°©ì§€
CORS(app)

# âœ… OpenAI API ì„¤ì • (ë¬´ì¡°ê±´ ChatGPTë§Œ ì‚¬ìš©)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    print("ğŸš¨ ê²½ê³ : .env íŒŒì¼ì— OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤!")
    client = None
else:
    client = OpenAI(api_key=OPENAI_API_KEY)

# ChatGPT ë©€í‹°ëª¨ë‹¬ ëª¨ë¸
MODEL_NAME = "gpt-4.1-mini"   # í…ìŠ¤íŠ¸+ì´ë¯¸ì§€ ëª¨ë‘ ì§€ì›


# --- ê³µí†µ OpenAI í˜¸ì¶œ í—¬í¼ ---

def to_image_data_url(img_bytes: bytes, mime_type: str = "image/png") -> str:
    """ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ë¥¼ data URL(base64)ë¡œ ë³€í™˜"""
    b64 = base64.b64encode(img_bytes).decode("utf-8")
    return f"data:{mime_type};base64,{b64}"


def call_openai_from_parts(parts, json_mode: bool = True) -> str:
    """
    OpenAI Responses API í˜¸ì¶œ.
    - parts: ë¬¸ìì—´, PIL.Image.Image ì„ì—¬ ìˆëŠ” ë¦¬ìŠ¤íŠ¸
    - json_mode: Trueë©´ "JSONë§Œ ì¶œë ¥"ì´ë¼ê³  ì‹œìŠ¤í…œ ì§€ì‹œë¥¼ ì•ì— ë¶™ì„
    - ë°˜í™˜ê°’: ChatGPTê°€ ë°˜í™˜í•œ í…ìŠ¤íŠ¸ ì „ì²´ (string)
    """
    if client is None:
        raise RuntimeError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

    content = []

    if json_mode:
        # JSON ê°•ì œ ì§€ì‹œ
        content.append({
            "type": "input_text",
            "text": (
                "í•­ìƒ ìœ íš¨í•œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. "
                "ë§ˆí¬ë‹¤ìš´, ì½”ë“œë¸”ë¡, ì„¤ëª… ë¬¸ì¥ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
            ),
        })

    for p in parts:
        if isinstance(p, str):
            content.append({"type": "input_text", "text": p})
        elif isinstance(p, PIL.Image.Image):
            buf = io.BytesIO()
            fmt = p.format if p.format else "PNG"
            p.save(buf, format=fmt)
            buf.seek(0)
            data_url = to_image_data_url(buf.getvalue(), mime_type=f"image/{fmt.lower()}")
            content.append({
                "type": "input_image",
                "image_url": {"url": data_url},
            })
        else:
            # dict ë“± ê¸°íƒ€ íƒ€ì…ì€ í•„ìš”ì‹œ í™•ì¥
            pass

    resp = client.responses.create(
        model=MODEL_NAME,
        input=[{"role": "user", "content": content}],
        temperature=0.0,
        max_output_tokens=32768,
    )

    # text ê²°ê³¼ë§Œ ëª¨ìœ¼ê¸° (Responses API output êµ¬ì¡° ê¸°ì¤€)
    result_chunks = []
    for out in getattr(resp, "output", []):
        for c in getattr(out, "content", []):
            if getattr(c, "type", None) == "output_text" and getattr(c, "text", None):
                result_chunks.append(c.text)
    result_text = "".join(result_chunks).strip()
    return result_text


# --- ë²•ë ¹ í…ìŠ¤íŠ¸ ë¡œë“œ ---
def load_law_texts() -> str:
    print("ğŸ“š ë²•ë ¹ íŒŒì¼ë“¤ì„ ì½ì–´ì˜¤ëŠ” ì¤‘...")
    law_files = glob.glob("law_text_*.txt") + glob.glob("../law_text_*.txt")
    if not law_files:
        print("âš ï¸ ë²•ë ¹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë²•ë¥  ê²€í†  ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return ""
    all_law_text = ""
    for file_path in law_files:
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                all_law_text += f"--- ë²•ë ¹ [{file_path}] ì‹œì‘ ---\n\n"
                all_law_text += f.read()
                all_law_text += f"\n\n--- ë²•ë ¹ [{file_path}] ë ---\n\n"
            print(f"âœ… ë²•ë ¹ íŒŒì¼ '{file_path}' ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ë²•ë ¹ íŒŒì¼ '{file_path}' ì½ê¸° ì‹¤íŒ¨: {e}")
    print(f"âœ… ëª¨ë“  ë²•ë ¹ íŒŒì¼ ë¡œë“œ ì™„ë£Œ (ì´ {len(all_law_text)}ì)")
    return all_law_text

ALL_LAW_TEXT = load_law_texts()

# --- í”„ë¡¬í”„íŠ¸ (ì§€ì‹œì‚¬í•­) ---
PROMPT_EXTRACT_INGREDIENT_INFO = """
ì´ ì´ë¯¸ì§€ëŠ” ì›ë¶€ì¬ë£Œ í‘œì‹œì‚¬í•­ ì‚¬ì§„ì…ë‹ˆë‹¤. 
**í•„ìˆ˜ì ìœ¼ë¡œ ì¶”ì¶œí•´ì•¼ í•  ì •ë³´ë§Œ** ì¶”ì¶œí•˜ì„¸ìš”.

[ì¶”ì¶œí•´ì•¼ í•  ì •ë³´]
1. **ì›ì¬ë£Œëª…**: ì›ì¬ë£Œì˜ ì •í™•í•œ ëª…ì¹­
2. **ë³µí•©ì›ì¬ë£Œ ë‚´ì—­**: ê´„í˜¸ ì•ˆì˜ í•˜ìœ„ ì›ì¬ë£Œ ì •ë³´ (ì˜ˆ: (íƒˆì§€ëŒ€ë‘, ì†Œë§¥))
3. **ì›ì‚°ì§€ ì •ë³´**: ì›ì‚°ì§€ í‘œê¸° (ì˜ˆ: ì™¸êµ­ì‚°, êµ­ë‚´ì‚°, ì¸ë„ì‚° ë“±)
4. **ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ**: ì•Œë ˆë¥´ê¸° í‘œì‹œ ì •ë³´
5. **ì‹í’ˆì²¨ê°€ë¬¼**: ì²¨ê°€ë¬¼ëª…ê³¼ ìš©ë„ ë³‘ê¸° ì—¬ë¶€

[ì¶œë ¥ í˜•ì‹]
JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{
    "ingredient_name": "ì›ì¬ë£Œëª…",
    "sub_ingredients": "í•˜ìœ„ì›ì¬ë£Œ ë‚´ì—­ (ë³µí•©ì›ì¬ë£Œì¸ ê²½ìš°)",
    "origin": "ì›ì‚°ì§€ ì •ë³´",
    "allergens": ["ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ ëª©ë¡"],
    "additives": ["ì‹í’ˆì²¨ê°€ë¬¼ ëª©ë¡"]
}
ì›ì¬ë£Œëª…ì´ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ "ingredient_name"ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë‘ì„¸ìš”.
"""

PROMPT_CREATE_STANDARD = """
ë‹¹ì‹ ì€ ì‹í’ˆ ê·œì • ë° í‘œì‹œì‚¬í•­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ [ë°°í•©ë¹„ ë°ì´í„°(Excel)]ì™€ [ì›ì¬ë£Œ í‘œì‹œì‚¬í•­ì—ì„œ ì¶”ì¶œëœ ì •ë³´]ë¥¼ ì¢…í•©í•˜ì—¬,
ë²•ì ìœ¼ë¡œ ì™„ë²½í•œ 'ì‹í’ˆí‘œì‹œì‚¬í•­ ê¸°ì¤€ ë°ì´í„°(Standard)'ë¥¼ ì‹¤ì œ ë¼ë²¨ í˜•ì‹ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.

[ì¶œë ¥ ì–‘ì‹ - JSONë§Œ ì¶œë ¥]
{
  "product_info": {
    "product_name": "ì œí’ˆëª…",
    "food_type": "ì‹í’ˆì˜ ìœ í˜•",
    "net_weight": "ë‚´ìš©ëŸ‰",
    "expiration_date": "ì†Œë¹„ê¸°í•œ",
    "storage_method": "ë³´ê´€ë°©ë²•",
    "packaging_material": "í¬ì¥ì¬ì§ˆ",
    "item_report_number": "í’ˆëª©ë³´ê³ ë²ˆí˜¸",
    "front_calories": "ì „ë©´ë¶€ ì´ì—´ëŸ‰/ë¬¸êµ¬"
  },
  "ingredients": {
    "structured_list": ["..."],
    "continuous_text": "ì›ì¬ë£Œëª…, ì›ì¬ë£Œëª…2, ..."
  },
  "allergens": {
    "contains": ["ëŒ€ë‘", "ê²Œ"],
    "manufacturing_facility": "ì œì¡°ì‹œì„¤ ì•ˆë‚´ ë¬¸êµ¬"
  },
  "nutrition_info": {
    "total_content": "1000 g",
    "per_100g": {
      "calories": "130 Kcal"
    },
    "disclaimer": "ì˜ì–‘ì •ë³´ ì£¼ì˜ ë¬¸êµ¬ ë“±"
  },
  "manufacturer": {
    "name": "ì œì¡°ì—…ì²´ëª…",
    "address": "ì£¼ì†Œ"
  },
  "precautions": ["ì£¼ì˜ì‚¬í•­1", "ì£¼ì˜ì‚¬í•­2"],
  "law_compliance": {
    "status": "compliant" | "needs_review",
    "issues": ["ë²•ë¥  ìœ„ë°˜ ì‚¬í•­ ëª©ë¡ (ìˆëŠ” ê²½ìš°)"]
  },
  "details": [
    {"name": "ì›ì¬ë£Œëª…", "ratio": "ë°°í•©ë¹„ìœ¨", "origin": "ì›ì‚°ì§€", "sub_ingredients": "í•˜ìœ„ì›ë£Œ"}
  ]
}
"""

PROMPT_VERIFY_DESIGN = """
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ì‹í’ˆí‘œì‹œì‚¬í•­ ì •ë°€ ê°ì‚¬ AIì´ì ìë™ ì±„ì ê¸°ì…ë‹ˆë‹¤.
ì œê³µëœ [Standard(ê¸°ì¤€ì„œ)]ì™€ [Design OCR(raw_text)]ë¥¼ 1:1 ì •ë°€ ëŒ€ì¡°í•˜ì—¬ ì±„ì í•˜ì„¸ìš”.

[ì…ë ¥]
1) Standard: JSON í˜•ì‹ì˜ ê¸°ì¤€ ë°ì´í„°
2) Design OCR í…ìŠ¤íŠ¸: ì„œë²„ì—ì„œ ë¯¸ë¦¬ ì¶”ì¶œí•œ ìˆœìˆ˜ í…ìŠ¤íŠ¸ (ì´ë¯¸ì§€ OCR ê²°ê³¼)

[ì ˆëŒ€ ê·œì¹™]
- Standardì™€ ë””ìì¸ OCR í…ìŠ¤íŠ¸ì— **ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ë‚´ìš©ë§Œ** ì‚¬ìš©í•˜ì„¸ìš”.
- ë§ì¶¤ë²•, ë„ì–´ì“°ê¸°, ìˆ«ì, ë‹¨ìœ„, íŠ¹ìˆ˜ë¬¸ì ì°¨ì´ë¥¼ ê·¸ëŒ€ë¡œ ê¸°ë°˜ìœ¼ë¡œë§Œ ë¹„êµí•˜ì„¸ìš”.
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” â€œ500gâ€, â€œì†”ë¹„í†¨â€ ë“±ì˜ ê°’ì€ ìƒìƒí•´ì„œ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.
- "expected" ê°’ì€ ë°˜ë“œì‹œ Standardì—ì„œ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ë¬¸ìì—´ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•´ì„œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
- "actual" ê°’ì€ ë°˜ë“œì‹œ ë””ìì¸ OCR í…ìŠ¤íŠ¸(design_ocr_text)ì—ì„œ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ë¬¸ìì—´ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•´ì„œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

[ê°ì  ê¸°ì¤€í‘œ (ì´ì  100ì ì—ì„œ ì‹œì‘)]
1. ì›ì¬ë£Œëª… ì˜¤ë¥˜ (-5ì /ê±´)
2. ì˜ì–‘ì„±ë¶„ ì˜¤ë¥˜ (-5ì /ê±´)
3. ë²•ì  ì˜ë¬´ ë¬¸êµ¬ ëˆ„ë½ (-10ì /ê±´)
4. ë‹¨ìˆœ ì˜¤íƒ€ (-2ì /ê±´)

[ì¶œë ¥ í˜•ì‹ - JSONë§Œ ì¶œë ¥]
{
  "design_ocr_text": "ë””ìì¸ ì „ì²´ í…ìŠ¤íŠ¸(raw_text ë˜ëŠ” OCR ê²°ê³¼) ê·¸ëŒ€ë¡œ",
  "score": 100,
  "law_compliance": {
    "status": "compliant" | "violation",
    "violations": ["ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ ì œXì¡° ìœ„ë°˜..."]
  },
  "issues": [
    {
      "type": "Critical" | "Minor" | "Law_Violation",
      "location": "í•­ëª©ëª… (ì˜ˆ: ì˜ì–‘ì •ë³´)",
      "issue": "ì˜¤ë¥˜ ìƒì„¸ ì„¤ëª…",
      "expected": "ê¸°ì¤€ì„œ ë°ì´í„°ì—ì„œ ì‹¤ì œ ë°œì·Œí•œ í…ìŠ¤íŠ¸",
      "actual": "ë””ìì¸ OCRì—ì„œ ì‹¤ì œ ë°œì·Œí•œ í‹€ë¦° í…ìŠ¤íŠ¸",
      "suggestion": "ìˆ˜ì • ì œì•ˆ"
    }
  ]
}
"""

# --- í…ìŠ¤íŠ¸/HTML ì •ë¦¬ í•¨ìˆ˜ ---
def clean_html_text(text):
    if not text:
        return ""
    text = html.unescape(str(text))
    prev_text = ""
    while prev_text != text:
        prev_text = text
        text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'style\s*=\s*["\'][^"\']*["\']', '', text, flags=re.IGNORECASE)
    text = re.sub(r'class\s*=\s*["\'][^"\']*["\']', '', text, flags=re.IGNORECASE)
    text = re.sub(r'font-weight\s*:\s*\d+', '', text, flags=re.IGNORECASE)
    text = re.sub(r'margin[^;]*;?', '', text, flags=re.IGNORECASE)
    text = re.sub(r'padding[^;]*;?', '', text, flags=re.IGNORECASE)
    text = re.sub(r'color[^;]*;?', '', text, flags=re.IGNORECASE)
    text = re.sub(r'font-size[^;]*;?', '', text, flags=re.IGNORECASE)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def clean_ai_response(data):
    if isinstance(data, dict):
        cleaned = {}
        for key, value in data.items():
            if key in ['violations', 'issues'] and isinstance(value, list):
                cleaned[key] = []
                for item in value:
                    if isinstance(item, dict):
                        cleaned_item = {}
                        for k, v in item.items():
                            if isinstance(v, str):
                                cleaned_item[k] = clean_html_text(v)
                            else:
                                cleaned_item[k] = clean_ai_response(v)
                        cleaned[key].append(cleaned_item)
                    elif isinstance(item, str):
                        cleaned[key].append(clean_html_text(item))
                    else:
                        cleaned[key].append(clean_ai_response(item))
            elif isinstance(value, str):
                cleaned[key] = clean_html_text(value)
            else:
                cleaned[key] = clean_ai_response(value)
        return cleaned
    elif isinstance(data, list):
        return [clean_ai_response(item) for item in data]
    elif isinstance(data, str):
        return clean_html_text(data)
    else:
        return data


# --- ChatGPT Vision OCR (ìš°ì„  ì‚¬ìš©) ---
def ocr_image_bytes_with_chatgpt(image_bytes: bytes) -> str:
    """
    ChatGPT ë©€í‹°ëª¨ë‹¬ë¡œ OCRë§Œ ìˆ˜í–‰ (í…ìŠ¤íŠ¸ë§Œ ê·¸ëŒ€ë¡œ ë‹¬ë¼ê³  ê°•í•˜ê²Œ ì§€ì‹œ).
    ì‹¤íŒ¨í•˜ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜.
    """
    if client is None:
        return ""

    try:
        img = PIL.Image.open(io.BytesIO(image_bytes)).convert("RGB")
        # ë„ˆë¬´ í¬ë©´ ì•½ê°„ ì¤„ì´ê¸°
        max_size = 1600
        if max(img.size) > max_size:
            ratio = max_size / max(img.size)
            new_size = (int(img.width * ratio), int(img.height * ratio))
            img = img.resize(new_size, PIL.Image.Resampling.LANCZOS)
            print(f"ğŸ“‰ OCRìš© ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ: {new_size}")

        ocr_prompt = """
ì´ ì´ë¯¸ì§€ëŠ” ì‹í’ˆ í¬ì¥ì§€/ë¼ë²¨ ì‚¬ì§„ì…ë‹ˆë‹¤.
**ì´ë¯¸ì§€ ì•ˆì— ë³´ì´ëŠ” ëª¨ë“  ê¸€ìë¥¼ ê·¸ëŒ€ë¡œ ì ì–´ ì£¼ì„¸ìš”.**

[ì¤‘ìš”]
- ì¤„ë°”ê¿ˆ, ê³µë°±, ìˆ«ì, ê¸°í˜¸ë¥¼ ìµœëŒ€í•œ ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”.
- ì˜ë¯¸ë¥¼ ìš”ì•½í•˜ê±°ë‚˜ ì„¤ëª…í•˜ì§€ ë§ê³ , ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
- í•œêµ­ì–´ëŠ” í•œêµ­ì–´ë¡œ, ì˜ì–´/ìˆ«ìëŠ” ìˆëŠ” ê·¸ëŒ€ë¡œ ì ì–´ ì£¼ì„¸ìš”.
"""
        parts = [ocr_prompt, img]
        text = call_openai_from_parts(parts, json_mode=False).strip()

        # í˜¹ì‹œ ì½”ë“œë¸”ë¡ìœ¼ë¡œ ì˜¤ë©´ ì œê±°
        if text.startswith("```"):
            lines = text.split("\n")
            if lines and lines[0].startswith("```"):
                lines = lines[1:]
            if lines and lines[-1].strip().startswith("```"):
                lines = lines[:-1]
            text = "\n".join(lines).strip()

        if text:
            print("âœ… ChatGPT OCR ì„±ê³µ (vision)")
            return text
        else:
            print("âš ï¸ ChatGPT OCR ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŒ")
            return ""
    except Exception as e:
        print("âŒ ChatGPT OCR ì‹¤íŒ¨:", e)
        return ""


# --- OCR í´ë°± ---
def ocr_bytes_to_text(image_bytes: bytes) -> str:
    """
    1ìˆœìœ„: ChatGPT Vision OCR
    2ìˆœìœ„: pytesseract (ì„¤ì¹˜ëœ ê²½ìš°)
    """
    # 1) ChatGPT Vision
    text = ocr_image_bytes_with_chatgpt(image_bytes)
    if text:
        return text

    # 2) pytesseract
    if not TESSERACT_AVAILABLE:
        return ""
    try:
        img = PIL.Image.open(io.BytesIO(image_bytes)).convert("RGB")
        text = pytesseract.image_to_string(img, lang='kor+eng')
        text = text.strip()
        if text:
            print("âœ… pytesseract OCR ì„±ê³µ (í´ë°±)")
        else:
            print("âš ï¸ pytesseract OCR ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŒ")
        return text
    except Exception as e:
        print("OCR í´ë°± ì‹¤íŒ¨:", e)
        return ""


# --- OCR 3íšŒ ì‹¤í–‰ ë° ê²°ê³¼ ë¹„êµ ---
def ocr_multiple_times(image_bytes: bytes, num_runs: int = 3) -> list:
    """
    OCRì„ ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    """
    results = []
    for i in range(num_runs):
        print(f"ğŸ”„ OCR ì‹¤í–‰ {i+1}/{num_runs}...")
        text = ocr_bytes_to_text(image_bytes)
        if text:
            results.append(text)
        else:
            print(f"âš ï¸ OCR ì‹¤í–‰ {i+1} ì‹¤íŒ¨")
    return results


def verify_with_ocr(ocr_text: str, standard_json: str) -> dict:
    """
    OCR í…ìŠ¤íŠ¸ì™€ Standardë¥¼ ë¹„êµí•˜ì—¬ ê²€ì¦ ê²°ê³¼ ë°˜í™˜
    (í•œ ë²ˆì˜ OCR ê²°ê³¼ì— ëŒ€í•´ ë…ë¦½ì ìœ¼ë¡œ ê²€ì¦)
    """
    if not ocr_text:
        return {"issues": [], "design_ocr_text": ""}

    try:
        enhanced_prompt = PROMPT_VERIFY_DESIGN
        if ALL_LAW_TEXT:
            enhanced_prompt += f"\n\n--- [ì°¸ê³  ë²•ë ¹] ---\n{ALL_LAW_TEXT}\n--- [ë²•ë ¹ ë] ---\n"

        parts = [
            enhanced_prompt,
            f"\n--- [ê¸°ì¤€ ë°ì´í„°(Standard)] ---\n{standard_json}",
            f"\n--- [ë””ìì¸ OCR í…ìŠ¤íŠ¸] ---\n{ocr_text}\n--- [ë””ìì¸ OCR í…ìŠ¤íŠ¸ ë] ---\n",
        ]

        result_text = call_openai_from_parts(parts, json_mode=True).strip()

        # JSON íŒŒì‹± ì „ ì½”ë“œë¸”ëŸ­ ì œê±°
        if result_text.startswith("```json"):
            result_text = result_text[7:]
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        elif result_text.startswith("```"):
            lines = result_text.split("\n")
            if lines and lines[0].startswith("```"):
                lines = lines[1:]
            if lines and lines[-1].strip().startswith("```"):
                lines = lines[:-1]
            result_text = "\n".join(lines).strip()

        result = json.loads(result_text)
        result = clean_ai_response(result)

        # design_ocr_textê°€ ì—†ìœ¼ë©´ ìš°ë¦¬ê°€ ì‚¬ìš©í•œ OCR í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ë„£ëŠ”ë‹¤.
        result.setdefault("design_ocr_text", ocr_text)
        return result
    except Exception as e:
        print(f"âŒ ê²€ì¦ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
        return {"issues": [], "design_ocr_text": ocr_text}


def find_common_errors(ocr_results: list, standard_json: str) -> dict:
    """
    3ë²ˆì˜ OCR ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ 2ë²ˆ ì´ìƒ ì¼ì¹˜í•˜ëŠ” ì˜¤ë¥˜ë§Œ ë°˜í™˜.

    - OCR ê²°ê³¼ë§ˆë‹¤ verify_with_ocr ë¡œ ë…ë¦½ ê²€ì¦.
    - ê°™ì€ (location, expected)ë¥¼ ê°€ì§„ issue ë¥¼ â€˜ê°™ì€ ì˜¤ë¥˜â€™ë¡œ ì¸ì‹.
    - ê°™ì€ ì˜¤ë¥˜ê°€ 3ë²ˆ ì¤‘ 2ë²ˆ ì´ìƒ ë“±ì¥í•˜ë©´ ìµœì¢… issues ì— í¬í•¨.
    - 1ë²ˆë§Œ ë“±ì¥í•œ ì˜¤ë¥˜ëŠ” ëª¨ë‘ ì œì™¸.
    """
    if not ocr_results:
        return {"ocr_text": "", "issues": [], "design_ocr_text": ""}

    # ê° OCR ê²°ê³¼ì— ëŒ€í•´ ë…ë¦½ ê²€ì¦ ìˆ˜í–‰
    all_verifications = []
    for i, ocr_text in enumerate(ocr_results):
        print(f"ğŸ” OCR ê²°ê³¼ {i+1}/{len(ocr_results)} ê²€ì¦ ì¤‘...")
        result = verify_with_ocr(ocr_text, standard_json)
        issues = result.get("issues", []) or []
        print(f"   â†’ {len(issues)}ê°œ ì˜¤ë¥˜ ë°œê²¬")
        all_verifications.append({
            "ocr_text": ocr_text,
            "design_ocr_text": result.get("design_ocr_text", ocr_text),
            "issues": issues,
        })

    # location+expected ë¥¼ key ë¡œ í•´ì„œ ë“±ì¥ íšŸìˆ˜ ì¹´ìš´íŠ¸
    issue_counts = {}
    issue_repr = {}  # ëŒ€í‘œ issue ì €ì¥

    def norm(s):
        return (s or "").strip()

    for ver in all_verifications:
        for issue in ver["issues"]:
            loc = norm(issue.get("location"))
            exp = norm(issue.get("expected"))

            # locationê³¼ expected ë‘˜ ë‹¤ ì—†ìœ¼ë©´ í‚¤ë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
            if not loc and not exp:
                continue

            key = (loc, exp)
            issue_counts[key] = issue_counts.get(key, 0) + 1
            # ê°€ì¥ ë¨¼ì € ë³¸ issueë¥¼ ëŒ€í‘œë¡œ ì‚¬ìš©
            if key not in issue_repr:
                issue_repr[key] = issue

    # 2ë²ˆ ì´ìƒ ë“±ì¥í•œ ì˜¤ë¥˜ë§Œ ë‚¨ê¹€
    common_issues = []
    for key, count in issue_counts.items():
        if count >= 2:
            issue = issue_repr[key]
            common_issues.append(issue)
            print(f"âœ… ê³µí†µ ì˜¤ë¥˜ ({count}/{len(ocr_results)}íšŒ): "
                  f"[{key[0]}] expected='{key[1]}'")
        else:
            print(f"âŒ ë‹¨ì¼ ë°œê²¬ ì˜¤ë¥˜ ì œì™¸ (1/{len(ocr_results)}íšŒ): "
                  f"[{key[0]}] expected='{key[1]}'")

    print(f"ğŸ“Š ì´ {sum(len(v['issues']) for v in all_verifications)}ê°œ ì˜¤ë¥˜ ì¤‘ "
          f"{len(common_issues)}ê°œê°€ 2íšŒ ì´ìƒ ì¼ì¹˜í•˜ì—¬ ìµœì¢… ì„ íƒë¨")

    # ì²« ë²ˆì§¸ OCR ê²°ê³¼ë¥¼ ëŒ€í‘œ í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
    main_ocr = all_verifications[0]["ocr_text"]
    main_design_ocr = all_verifications[0]["design_ocr_text"]

    return {
        "ocr_text": main_ocr,
        "design_ocr_text": main_design_ocr,
        "issues": common_issues,
    }


def filter_issues_by_text_evidence(result, standard_json: str, ocr_text: str):
    """
    LLM í—›ì†Œë¦¬ ë°©ì§€ í•„í„°:

    1) expected(ì •ë‹µ)ëŠ” ë°˜ë“œì‹œ Standard JSON í…ìŠ¤íŠ¸ ì•ˆì— ì‹¤ì œ ì¡´ì¬í•´ì•¼ í•¨
    2) actual(ì‹¤ì œ)ëŠ” ë°˜ë“œì‹œ OCR í…ìŠ¤íŠ¸ ì•ˆì— ì‹¤ì œ ì¡´ì¬í•´ì•¼ í•¨

    ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ì—†ìœ¼ë©´ ê·¸ issue ëŠ” ì œê±°.
    """
    if not isinstance(result, dict):
        return result

    try:
        std_obj = json.loads(standard_json) if standard_json else {}
        std_text = json.dumps(std_obj, ensure_ascii=False)
    except Exception:
        std_text = standard_json or ""

    ocr_text = ocr_text or ""

    issues = result.get("issues", [])
    if not isinstance(issues, list):
        return result

    filtered = []
    for issue in issues:
        if not isinstance(issue, dict):
            continue

        expected = str(issue.get("expected", "") or "")
        actual = str(issue.get("actual", "") or "")

        if expected and expected not in std_text:
            print("ğŸš« expected ê°€ Standard ì•ˆì— ì—†ìŒ â†’ ì´ìŠˆ ì œê±°:", expected)
            continue
        if actual and actual not in ocr_text:
            print("ğŸš« actual ì´ OCR í…ìŠ¤íŠ¸ ì•ˆì— ì—†ìŒ â†’ ì´ìŠˆ ì œê±°:", actual)
            continue

        filtered.append(issue)

    result["issues"] = filtered
    return result


def mark_possible_ocr_error_issues(result, hard_drop_distance: int = 1, soft_drop_distance: int = 2):
    """
    expected / actual ê°„ ì°¨ì´ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ OCR ë…¸ì´ì¦ˆë¡œ ì²˜ë¦¬.
    (ì—¬ê¸°ì„œëŠ” ì¼ë‹¨ ê·¸ëŒ€ë¡œ íŒ¨ìŠ¤. í•„ìš”í•˜ë©´ ì¶”ê°€ ê·œì¹™ ë„£ìœ¼ë©´ ë¨.)
    """
    return result


def highlight_ocr_errors(ocr_text: str, issues: list) -> str:
    """
    OCR í…ìŠ¤íŠ¸ì—ì„œ ì˜¤ë¥˜ ë¶€ë¶„ì„ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬
    """
    if not ocr_text or not issues:
        return ocr_text

    import html as html_mod
    highlighted_text = html_mod.escape(ocr_text)

    for issue in issues:
        actual = issue.get("actual", "")
        if not actual:
            continue
        escaped_actual = html_mod.escape(actual)
        if escaped_actual in highlighted_text:
            highlighted = (
                "<span style=\"background-color:#ffcccc;"
                " color:#cc0000; font-weight:bold; padding:2px 4px;"
                " border-radius:3px;\">"
                f"{escaped_actual}</span>"
            )
            # í•œ ë²ˆë§Œ êµì²´
            highlighted_text = highlighted_text.replace(escaped_actual, highlighted, 1)

    highlighted_text = highlighted_text.replace("\n", "<br>")
    return highlighted_text


# --- íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜ ---
def process_file_to_part(file_storage):
    """
    íŒŒì¼ì„ ëª¨ë¸ íŒŒíŠ¸ë¡œ ë³€í™˜.
    - ì—‘ì…€: í…ìŠ¤íŠ¸(CSV) ìŠ¤íŠ¸ë§ ë°˜í™˜
    - ì´ë¯¸ì§€: PIL.Image ê°ì²´ ë°˜í™˜ (ëª¨ë¸ ì…ë ¥ìš©)
    - PDF: ì²« í˜ì´ì§€ ì´ë¯¸ì§€ë¥¼ PIL.Imageë¡œ ë³€í™˜ (ê°€ëŠ¥í•œ ê²½ìš°)
    - ê¸°íƒ€: {'mime_type','data'} ë°˜í™˜
    """
    mime_type = file_storage.mimetype or ""
    file_data = file_storage.read()
    file_storage.seek(0)

    # ì—‘ì…€ -> CSV í…ìŠ¤íŠ¸
    if mime_type in [
        'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
        'application/vnd.ms-excel',
    ]:
        try:
            df = pd.read_excel(io.BytesIO(file_data))
            csv_text = df.to_csv(index=False)
            return {"text": f"--- [Excel ë°°í•©ë¹„ ë°ì´í„°] ---\n{csv_text}"}
        except Exception as e:
            print(f"ì—‘ì…€ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None

    # ì´ë¯¸ì§€ -> PIL.Image ê°ì²´ ë°˜í™˜
    if mime_type.startswith('image/'):
        try:
            img = PIL.Image.open(io.BytesIO(file_data)).convert("RGB")
            max_size = 1500
            if max(img.size) > max_size:
                ratio = max_size / max(img.size)
                new_size = (int(img.width * ratio), int(img.height * ratio))
                img = img.resize(new_size, PIL.Image.Resampling.LANCZOS)
                print(f"ğŸ“‰ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§•: {new_size}")
            return img
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨, bytesë¡œ ë°˜í™˜: {e}")
            return {"mime_type": mime_type, "data": file_data}

    # PDF -> ì´ë¯¸ì§€(ì²« í˜ì´ì§€)
    if mime_type == 'application/pdf' and PDF2IMAGE_AVAILABLE:
        try:
            images = convert_from_bytes(file_data, dpi=200)
            if images:
                print(f"ğŸ“„ PDF->ì´ë¯¸ì§€ ë³€í™˜: {len(images)} í˜ì´ì§€ (ì²« í˜ì´ì§€ ì‚¬ìš©)")
                return images[0].convert("RGB")
        except Exception as e:
            print("PDF->ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨:", e)
            return {"mime_type": mime_type, "data": file_data}

    return {"mime_type": mime_type, "data": file_data}


# --- ì´ë¯¸ì§€ì—ì„œ ì›ì¬ë£Œ ì •ë³´ ì¶”ì¶œ (ChatGPT + OCR í´ë°± ê²°í•©) ---
def extract_ingredient_info_from_image(image_file):
    """ì›ì¬ë£Œ í‘œì‹œì‚¬í•­ ì´ë¯¸ì§€ì—ì„œ í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ (ìš°ì„  ChatGPT, ì‹¤íŒ¨ ì‹œ OCR í´ë°±)"""
    try:
        image_data = image_file.read()
        image_file.seek(0)
        img_pil = PIL.Image.open(io.BytesIO(image_data)).convert("RGB")

        parts = [PROMPT_EXTRACT_INGREDIENT_INFO, img_pil]
        result_text = call_openai_from_parts(parts, json_mode=True)

        print("---- extract_ingredient_info_from_image ì‘ë‹µ(ì›ë¬¸ ì¼ë¶€) ----")
        print(result_text[:4000])
        print("--------------------------------------------------")

        # ChatGPT ì‘ë‹µì´ ì™„ì „ ë¹„ì—ˆìœ¼ë©´ ë°”ë¡œ OCR í´ë°±
        if not result_text:
            ocr_text = ocr_bytes_to_text(image_data)
            if ocr_text:
                return {"ocr_fallback_text": ocr_text}
            return None

        # ```json ... ``` ì œê±°
        if result_text.startswith("```json"):
            result_text = result_text[7:-3] if result_text.endswith("```") else result_text[7:]
        elif result_text.startswith("```"):
            result_text = result_text.split("```", 1)[1].strip() if "```" in result_text else result_text
            if result_text.startswith("json"):
                result_text = result_text[4:].strip()
        result_text = result_text.strip()

        # JSON íŒŒì‹± ì‹œë„
        try:
            return json.loads(result_text)
        except json.JSONDecodeError as e:
            print(f"ì›ì¬ë£Œ ì •ë³´ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print("ì‘ë‹µ í…ìŠ¤íŠ¸ ì¼ë¶€:", result_text[:1000])
            # JSONì´ ë§ê°€ì¡Œì„ ë•Œë„ OCR í´ë°± í•œ ë²ˆ ë” ì‹œë„
            ocr_text = ocr_bytes_to_text(image_data)
            if ocr_text:
                return {"ocr_fallback_text": ocr_text}
            return None

    except Exception as e:
        print(f"ì›ì¬ë£Œ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return None


# --- API ì—”ë“œí¬ì¸íŠ¸: ë””ìì¸ ê²€ì¦ ---
@app.route('/api/verify-design', methods=['POST'])
def verify_design():
    """
    ë””ìì¸ ê²€ì¦ API
    - OCRì„ 3ë²ˆ ì‹¤í–‰
    - ê° ê²°ê³¼ì— ëŒ€í•´ ë…ë¦½ì ìœ¼ë¡œ ê²€ì¦ ìˆ˜í–‰
    - ê°™ì€ (location, expected)ë¥¼ ê°€ì§„ issueëŠ” ê°™ì€ ì˜¤ë¥˜ë¡œ ì¸ì‹
    - 3ë²ˆ ì¤‘ 2ë²ˆ ì´ìƒ ì¼ì¹˜í•˜ëŠ” ì˜¤ë¥˜ë§Œ ìµœì¢… ê²°ê³¼ì— í¬í•¨
    - ë‹¨ì¼ ë°œê²¬ ì˜¤ë¥˜ëŠ” ì œì™¸
    """
    print("ğŸ•µï¸â€â™‚ï¸ ë””ìì¸ ê²€ì¦ ì‹œì‘...")

    # 1. ë””ìì¸ íŒŒì¼ (PDF or ì´ë¯¸ì§€)
    design_file = request.files.get('design_file')

    # 2. ê¸°ì¤€ ë°ì´í„° (ì—‘ì…€ íŒŒì¼ ë˜ëŠ” JSON ë¬¸ìì—´)
    standard_excel = request.files.get('standard_excel')
    standard_json = request.form.get('standard_data')

    if not design_file:
        return jsonify({"error": "ë””ìì¸ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    if not standard_excel and not standard_json:
        return jsonify({"error": "ê¸°ì¤€ ë°ì´í„°(ì—‘ì…€ íŒŒì¼ ë˜ëŠ” JSON)ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    # ê¸°ì¤€ ë°ì´í„° ì²˜ë¦¬ (ì—‘ì…€ â†’ ê°„ë‹¨ JSON)
    if standard_excel:
        try:
            df_dict = pd.read_excel(
                io.BytesIO(standard_excel.read()),
                sheet_name=None,
                engine='openpyxl'
            )
            if not df_dict:
                return jsonify({"error": "ì—‘ì…€ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."}), 400

            first_sheet_name = list(df_dict.keys())[0]
            first_sheet_df = df_dict[first_sheet_name]

            if first_sheet_df.empty:
                return jsonify({"error": "ì—‘ì…€ íŒŒì¼ì˜ ì²« ë²ˆì§¸ ì‹œíŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."}), 400

            first_column = first_sheet_df.columns[0]
            if 'ì›ì¬ë£Œëª…' in first_sheet_df.columns:
                ingredients_list = first_sheet_df['ì›ì¬ë£Œëª…'].dropna().astype(str).tolist()
            else:
                ingredients_list = first_sheet_df[first_column].dropna().astype(str).tolist()

            if not ingredients_list:
                return jsonify({"error": "ì—‘ì…€ íŒŒì¼ì˜ ì²« ë²ˆì§¸ ì‹œíŠ¸ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

            standard_data = {
                'ingredients': {
                    'structured_list': ingredients_list,
                    'continuous_text': ', '.join(ingredients_list)
                }
            }
            standard_json = json.dumps(standard_data, ensure_ascii=False)
        except Exception as e:
            print(f"âŒ ì—‘ì…€ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            traceback.print_exc()
            return jsonify({"error": f"ì—‘ì…€ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}"}), 400

    # ë””ìì¸ íŒŒì¼ â†’ ì´ë¯¸ì§€ bytes
    try:
        design_data = design_file.read()
        design_file.seek(0)

        if design_file.mimetype == 'application/pdf' and PDF2IMAGE_AVAILABLE:
            images = convert_from_bytes(design_data, dpi=200)
            if not images:
                return jsonify({"error": "PDFì—ì„œ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400
            img_io = io.BytesIO()
            images[0].save(img_io, format='PNG')
            design_image_bytes = img_io.getvalue()
        elif design_file.mimetype.startswith('image/'):
            design_image_bytes = design_data
        else:
            return jsonify({"error": "ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤."}), 400

        # OCRì„ 3ë²ˆ ì‹¤í–‰
        print("ğŸ”„ OCRì„ 3ë²ˆ ì‹¤í–‰í•©ë‹ˆë‹¤...")
        ocr_results = ocr_multiple_times(design_image_bytes, num_runs=3)
        if not ocr_results:
            return jsonify({"error": "OCR ì‹¤í–‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}), 500

        # 3ë²ˆ ê²°ê³¼ë¥¼ ë¹„êµí•´ ê³µí†µ ì˜¤ë¥˜ë§Œ ì¶”ì¶œ
        print("ğŸ” 3ë²ˆì˜ OCR ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ê³µí†µ ì˜¤ë¥˜ë¥¼ ì°¾ëŠ” ì¤‘...")
        common_result = find_common_errors(ocr_results, standard_json)

        # í—›ì†Œë¦¬ í•„í„° ì ìš© (expected âˆˆ Standard, actual âˆˆ OCR)
        common_result = filter_issues_by_text_evidence(
            {"issues": common_result.get("issues", [])},
            standard_json,
            common_result.get("ocr_text", "")
        )
        issues_filtered = common_result.get("issues", [])

        # í•˜ì´ë¼ì´íŠ¸ HTML ìƒì„±
        highlighted_html = highlight_ocr_errors(
            common_result.get("design_ocr_text", common_result.get("ocr_text", "")),
            issues_filtered
        )

        # ì ìˆ˜ëŠ” ë§¤ìš° ë‹¨ìˆœí•˜ê²Œ: ì˜¤ë¥˜ë‹¹ -5ì  (ìµœì†Œ 0)
        score = max(0, 100 - 5 * len(issues_filtered))

        final_result = {
            "design_ocr_text": common_result.get("design_ocr_text", common_result.get("ocr_text", "")),
            "design_ocr_highlighted_html": highlighted_html,
            "score": score,
            "law_compliance": {
                "status": "compliant" if len(issues_filtered) == 0 else "violation",
                "violations": []
            },
            "issues": issues_filtered
        }

        return jsonify(final_result)

    except Exception as e:
        print(f"âŒ ê²€ì¦ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


if __name__ == '__main__':
    print("ğŸš€ ì‚¼ì§„ì–´ë¬µ ì‹í’ˆí‘œì‹œì‚¬í•­ ì™„ì„± í”Œë«í¼ V3.0 ê°€ë™")
    print("   - OCR 3íšŒ + ë‹¤ìˆ˜ê²° ì˜¤ë¥˜ ê²€ì¦")
    from waitress import serve

    serve(
        app,
        host='0.0.0.0',
        port=8080,
        threads=4,
        channel_timeout=600
    )
