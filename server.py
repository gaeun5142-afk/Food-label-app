import os
import json
import io
import glob
import pandas as pd
from flask import Flask, request, jsonify, render_template, send_file
from flask_cors import CORS
from dotenv import load_dotenv
import google.generativeai as genai
import PIL.Image
import PIL.ImageEnhance
import re
import unicodedata
import html as html_mod  # âœ… í•˜ì´ë¼ì´íŠ¸ìš© ì´ìŠ¤ì¼€ì´í”„

# --- ì„¤ì • ë° ì´ˆê¸°í™” ---
load_dotenv()


def normalize_text_strict(text):
    """ì—„ê²©í•œ ë¹„êµìš© ì •ê·œí™” (ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ìœ ì§€)"""
    if not isinstance(text, str):
        text = str(text)
    # ìœ ë‹ˆì½”ë“œë§Œ ì •ê·œí™”, ê³µë°±/íŠ¹ìˆ˜ë¬¸ìëŠ” ìœ ì§€
    return unicodedata.normalize('NFKC', text)


# â­ ë¬¸ì ë‹¨ìœ„ ë¹„êµ (strict)
def compare_texts_strict(standard_text, design_text):
    """ë¬¸ì ë‹¨ìœ„ ì •í™• ë¹„êµ (AI ì—†ì´)"""
    std_norm = normalize_text_strict(standard_text)
    des_norm = normalize_text_strict(design_text)

    issues = []
    max_len = max(len(std_norm), len(des_norm))

    for i in range(max_len):
        std_char = std_norm[i] if i < len(std_norm) else '(ì—†ìŒ)'
        des_char = des_norm[i] if i < len(des_norm) else '(ì—†ìŒ)'

        if std_char != des_char:
            issues.append({
                "position": i,
                "expected": std_char,
                "actual": des_char,
                "context_before": std_norm[max(0, i - 5):i],
                "context_after": std_norm[i + 1:min(len(std_norm), i + 6)]
            })

    return issues


def add_issue_positions(issues, full_text: str):
    """
    issues ë¦¬ìŠ¤íŠ¸ì— 'position' í‚¤ë¥¼ ì±„ì›Œë„£ëŠ” í•¨ìˆ˜.
    full_text: OCRë¡œ ë½‘ì€ ì „ì²´ í…ìŠ¤íŠ¸ (design_ocr_text)

    - ê¸°ë³¸ì ìœ¼ë¡œ issue["actual"] ì „ì²´ ë¬¸ìì—´ ê¸°ì¤€ìœ¼ë¡œ ìœ„ì¹˜ë¥¼ ì°¾ëŠ”ë‹¤.
    - ëª» ì°¾ìœ¼ë©´ issue["expected"]ë¡œ ë‹¤ì‹œ ì‹œë„í•œë‹¤.
    """
    if not full_text or not issues:
        return issues

    text = full_text

    for issue in issues:
        # ì´ë¯¸ positionì´ ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
        if isinstance(issue.get("position"), int):
            continue

        actual = (issue.get("actual") or "").strip()
        expected = (issue.get("expected") or "").strip()

        pos = -1

        # 1) ìš°ì„  actual(ì‹¤ì œ í‘œì‹œëœ ë¬¸ìì—´) ìœ„ì¹˜ ì°¾ê¸°
        if actual:
            pos = text.find(actual)

        # 2) ëª» ì°¾ìœ¼ë©´ expected(ì •ë‹µ) ìœ„ì¹˜ë¼ë„ ì°¾ì•„ë³´ê¸°
        if pos == -1 and expected:
            pos = text.find(expected)

        # 3) ì°¾ìœ¼ë©´ position ì €ì¥
        if pos != -1:
            issue["position"] = pos

    return issues


#5ë²ˆ
def ocr_with_voting(image_file, num_runs=5):
    """ê°™ì€ ì´ë¯¸ì§€ë¥¼ ì—¬ëŸ¬ ë²ˆ OCRí•´ì„œ ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ê²°ê³¼ ì„ íƒ"""
    from collections import Counter

    # â­ í•¨ìˆ˜ ì‹œì‘ ì‹œ íŒŒì¼ í¬ì¸í„° ì´ˆê¸°í™”
    image_file.seek(0)

    results = []
    print(f"ğŸ”„ OCR ì•ˆì •í™”: {num_runs}íšŒ ì‹¤í–‰ ì¤‘...")

    for i in range(num_runs):
        try:
            image_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ì´ˆê¸°í™”
            parts = [
                PROMPT_EXTRACT_RAW_TEXT,
                process_file_to_part(image_file)
            ]

            model = genai.GenerativeModel(MODEL_NAME, generation_config={
                "temperature": 0.0,
                "top_k": 1,
                "max_output_tokens": 8192,
                "response_mime_type": "application/json"
            })

            response = model.generate_content(parts)
            # â­ finish_reason ì²´í¬ ì¶”ê°€
            if response.candidates and response.candidates[0].finish_reason == 2:
                print(f"  âš ï¸ {i+1}ë²ˆì§¸ OCR: í† í° ì œí•œ ì´ˆê³¼, ì¬ì‹œë„ ì¤‘...")
                continue

            result_text = response.text.strip()

            # JSON íŒŒì‹±
            if result_text.startswith("```"):
                result_text = result_text[7:-3]
            elif result_text.startswith("```"):
                result_text = result_text[3:-3]

            ocr_result = json.loads(result_text)
            extracted_text = ocr_result.get('raw_text', '')
            results.append(extracted_text)

            print(f"  {i + 1}/{num_runs} ì™„ë£Œ: {len(extracted_text)}ì")

        except Exception as e:
            print(f"  âš ï¸ {i + 1}ë²ˆì§¸ OCR ì‹¤íŒ¨: {e}")
            continue

    # â­ í•¨ìˆ˜ ì¢…ë£Œ ì „ì—ë„ ë¦¬ì…‹ (ë‹¤ìŒ ì‚¬ìš©ì„ ìœ„í•´)
    image_file.seek(0)

    if not results:
        raise Exception("ëª¨ë“  OCR ì‹œë„ ì‹¤íŒ¨")

    # ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ê²°ê³¼ ì„ íƒ
    counter = Counter(results)
    most_common_text, count = counter.most_common(1)[0]

    print(f"ğŸ“Š íˆ¬í‘œ ê²°ê³¼:")
    for text, freq in counter.most_common():
        print(f"  - {freq}/{num_runs}íšŒ: {text[:50]}...")

    print(f"âœ… ìµœì¢… ì„ íƒ: {count}/{num_runs}íšŒ ì¼ì¹˜")

    return most_common_text


app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}})

# API í‚¤ ì„¤ì •
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
if not GOOGLE_API_KEY:
    print("ğŸš¨ ê²½ê³ : .env íŒŒì¼ì— GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤!")
else:
    genai.configure(api_key=GOOGLE_API_KEY)

# Gemini ëª¨ë¸ ì„¤ì • (ê¸°ë³¸ê°’, ìë™ ê°ì§€ë¡œ ë®ì–´ì”Œì›Œì§ˆ ìˆ˜ ìˆìŒ)
MODEL_NAME = 'gemini-1.5-flash'

# â­ ëª¨ë“  í•¨ìˆ˜ì—ì„œ ë™ì¼í•˜ê²Œ ì‚¬ìš©í•  Generation Config
STABLE_GENERATION_CONFIG = {
    "temperature": 0.0,
    "top_p": 1.0,
    "top_k": 1,
    "candidate_count": 1,
    "max_output_tokens": 32768,
    "response_mime_type": "application/json"
}

# â­ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ê³ ì • íŒŒë¼ë¯¸í„°
IMAGE_TARGET_SIZE = 2400
IMAGE_DPI = 300
CLAHE_CLIP_LIMIT = 2.5
THRESHOLD_BLOCK_SIZE = 15
THRESHOLD_C = 3


# ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ í•¨ìˆ˜
def check_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ í™•ì¸í•˜ê³  ì ì ˆí•œ ëª¨ë¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global MODEL_NAME
    try:
        models = genai.list_models()
        available_models = []
        print("\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡:")
        for m in models:
            if 'generateContent' in m.supported_generation_methods:
                # ëª¨ë¸ ì´ë¦„ì—ì„œ 'models/' ì ‘ë‘ì‚¬ ì œê±°
                model_name = m.name.replace('models/', '')
                available_models.append(model_name)
                print(f"   - {model_name}")

        # Flash ëª¨ë¸ ìš°ì„  ì„ íƒ
        for model in available_models:
            if 'flash' in model.lower():
                MODEL_NAME = model
                print(f"\nâœ… ì¶”ì²œ ëª¨ë¸ ì„ íƒ: {MODEL_NAME}\n")
                return MODEL_NAME

        # Flashê°€ ì—†ìœ¼ë©´ Pro ëª¨ë¸ ì„ íƒ
        for model in available_models:
            if 'pro' in model.lower():
                MODEL_NAME = model
                print(f"\nâœ… Pro ëª¨ë¸ ì„ íƒ: {MODEL_NAME}\n")
                return MODEL_NAME

        # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ëª¨ë¸ ì‚¬ìš©
        if available_models:
            MODEL_NAME = available_models[0]
            print(f"\nâœ… ì²« ë²ˆì§¸ ëª¨ë¸ ì„ íƒ: {MODEL_NAME}\n")
            return MODEL_NAME

        print(f"\nâš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ ì‚¬ìš©: {MODEL_NAME}\n")
        return None
    except Exception as e:
        print(f"âš ï¸ ëª¨ë¸ ëª©ë¡ í™•ì¸ ì‹¤íŒ¨: {e}")
        print(f"âš ï¸ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©: {MODEL_NAME}\n")
        return None


# ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ í™•ì¸ ë° ìë™ ì„¤ì •
if GOOGLE_API_KEY:
    check_available_models()
else:
    print(f"âš ï¸ API í‚¤ê°€ ì—†ì–´ ëª¨ë¸ í™•ì¸ì„ ê±´ë„ˆëœë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©: {MODEL_NAME}\n")


# --- ë²•ë ¹ í…ìŠ¤íŠ¸ ë¡œë“œ ---
def load_law_texts() -> str:
    """ë²•ë ¹ .txt íŒŒì¼ë“¤ì„ ëª¨ë‘ ì½ì–´ í•˜ë‚˜ì˜ í° í…ìŠ¤íŠ¸ë¡œ í•©ì¹©ë‹ˆë‹¤."""
    print("ğŸ“š ë²•ë ¹ íŒŒì¼ë“¤ì„ ì½ì–´ì˜¤ëŠ” ì¤‘...")
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì™€ í˜„ì¬ ë””ë ‰í† ë¦¬ ëª¨ë‘ í™•ì¸
    law_files = glob.glob("law_text_*.txt") + glob.glob("../law_text_*.txt")

    if not law_files:
        print("âš ï¸ ë²•ë ¹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë²•ë¥  ê²€í†  ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return ""

    all_law_text = ""
    for file_path in law_files:
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                all_law_text += f"--- ë²•ë ¹ [{file_path}] ì‹œì‘ ---\n\n"
                all_law_text += f.read()
                all_law_text += f"\n\n--- ë²•ë ¹ [{file_path}] ë ---\n\n"
            print(f"âœ… ë²•ë ¹ íŒŒì¼ '{file_path}' ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ë²•ë ¹ íŒŒì¼ '{file_path}' ì½ê¸° ì‹¤íŒ¨: {e}")

    print(f"âœ… ëª¨ë“  ë²•ë ¹ íŒŒì¼ ë¡œë“œ ì™„ë£Œ (ì´ {len(all_law_text)}ì)")
    return all_law_text


ALL_LAW_TEXT = load_law_texts()

# --- í”„ë¡¬í”„íŠ¸ (ì§€ì‹œì‚¬í•­) ---

PROMPT_EXTRACT_INGREDIENT_INFO = """
ë‹¹ì‹ ì€ í•œêµ­ ì‹í’ˆ ë¼ë²¨ OCR ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì´ë¯¸ì§€ì—ì„œ ì›ë¶€ì¬ë£Œ í‘œì‹œì‚¬í•­ì„ **ì •í™•í•˜ê²Œ** ì¶”ì¶œí•˜ì„¸ìš”.
ì¶”ì¸¡í•˜ê±°ë‚˜ ì°½ì˜ì ìœ¼ë¡œ í•´ì„í•˜ì§€ ë§ê³ , ë³´ì´ëŠ” í…ìŠ¤íŠ¸ë§Œ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.

ğŸš¨ ì ˆëŒ€ ê·œì¹™ ğŸš¨
ğŸš¨ ì ˆëŒ€ ê·œì¹™ ğŸš¨
1. ì´ë¯¸ì§€ì— **ë³´ì´ëŠ” ê¸€ìë§Œ** ì¶”ì¶œ (ì¶”ë¡ /ë³´ì • ê¸ˆì§€)
2. **íŠ¹ìˆ˜ë¬¸ì(ì‰¼í‘œ, ì , ê´„í˜¸) ëˆ„ë½ë„ ê·¸ëŒ€ë¡œ** ì¶”ì¶œ
3. ì˜¤íƒ€, ë„ì–´ì“°ê¸°, íŠ¹ìˆ˜ë¬¸ì ëª¨ë‘ **ì •í™•íˆ ê·¸ëŒ€ë¡œ**
4. ë¬¸ë²•ì ìœ¼ë¡œ í‹€ë ¤ë„ **ì´ë¯¸ì§€ì™€ 100% ë™ì¼**í•˜ê²Œ



[ì¶”ì¶œí•´ì•¼ í•  ì •ë³´]
1. **ì›ì¬ë£Œëª…**: ì›ì¬ë£Œì˜ ì •í™•í•œ ëª…ì¹­ (ì˜¤íƒ€ ì—†ì´)
2. **ë³µí•©ì›ì¬ë£Œ ë‚´ì—­**: ê´„í˜¸ ì•ˆì˜ í•˜ìœ„ ì›ì¬ë£Œ ì •ë³´ (ì˜ˆ: (íƒˆì§€ëŒ€ë‘, ì†Œë§¥))
3. **ì›ì‚°ì§€ ì •ë³´**: ì›ì‚°ì§€ í‘œê¸° (ì˜ˆ: ì™¸êµ­ì‚°, êµ­ë‚´ì‚°, ì¸ë„ì‚° ë“±)
4. **í•¨ëŸ‰ ì •ë³´**: ë°±ë¶„ìœ¨(%) í‘œì‹œ
5. **ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ**: ì•Œë ˆë¥´ê¸° í‘œì‹œ ì •ë³´
6. **ì‹í’ˆì²¨ê°€ë¬¼**: ì²¨ê°€ë¬¼ëª…ê³¼ ìš©ë„ ë³‘ê¸° ì—¬ë¶€

[ì¶œë ¥ í˜•ì‹]
ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”:
{
  "ingredient_name": "ì›ì¬ë£Œëª…",
  "content_percentage": "í•¨ëŸ‰(%)",
  "sub_ingredients": "í•˜ìœ„ì›ì¬ë£Œ ë‚´ì—­ (ë³µí•©ì›ì¬ë£Œì¸ ê²½ìš°)",
  "origin": "ì›ì‚°ì§€ ì •ë³´",
  "allergens": ["ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ ëª©ë¡"],
  "additives": ["ì‹í’ˆì²¨ê°€ë¬¼ ëª©ë¡"],
  "raw_ocr_text": "ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œí•œ ì „ì²´ í…ìŠ¤íŠ¸ (ì›ë³¸ ê·¸ëŒ€ë¡œ)"
}
"""
PROMPT_EXTRACT_RAW_TEXT = """
ë‹¹ì‹ ì€ OCR ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ **ê¸°ê³„ì ìœ¼ë¡œ** ì¶”ì¶œí•˜ì„¸ìš”.

ğŸ¤– ê¸°ê³„ ëª¨ë“œ í™œì„±í™”:
- ì² ì êµì •ê¸° OFF
- ë¬¸ë²• ê²€ì‚¬ê¸° OFF
- ìë™ ì™„ì„± OFF
- ì¶”ë¡  ì—”ì§„ OFF

ì¶œë ¥ ê·œì¹™:
1. ë³´ì´ëŠ” ê¸€ì â†’ ê·¸ëŒ€ë¡œ ì¶œë ¥
2. í‹€ë¦° ê¸€ì â†’ í‹€ë¦° ëŒ€ë¡œ ì¶œë ¥
3. ë¹ ì§„ ì‰¼í‘œ â†’ ë¹ ì§„ ëŒ€ë¡œ ì¶œë ¥
4. ì´ìƒí•œ ìˆ«ì â†’ ì´ìƒí•œ ëŒ€ë¡œ ì¶œë ¥

ì˜ˆì‹œ:
- ì´ë¯¸ì§€: "ì „ë°˜ê°€ê³µí’ˆ" â†’ ì¶œë ¥: "ì „ë°˜ê°€ê³µí’ˆ" (ì „ë¶„ê°€ê³µí’ˆ ì•„ë‹˜!)
- ì´ë¯¸ì§€: "ëŒ€ë‘ ê²Œ" â†’ ì¶œë ¥: "ëŒ€ë‘ ê²Œ" (ëŒ€ë‘, ê²Œ ì•„ë‹˜!)
- ì´ë¯¸ì§€: "221%" â†’ ì¶œë ¥: "221%" (2.21% ì•„ë‹˜!)

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ:
{
  "raw_text": "ìˆëŠ” ê·¸ëŒ€ë¡œì˜ í…ìŠ¤íŠ¸"
}
"""

# 1. ê¸°ì¤€ ë°ì´í„° ìƒì„±ìš© (ì—‘ì…€ + ì›ì¬ë£Œ ì‚¬ì§„ë“¤ -> ì •ë‹µì§€ ìƒì„±)
PROMPT_CREATE_STANDARD = """
ë‹¹ì‹ ì€ ì‹í’ˆ ê·œì • ë° í‘œì‹œì‚¬í•­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ [ë°°í•©ë¹„ ë°ì´í„°(Excel)]ì™€ [ì›ì¬ë£Œ í‘œì‹œì‚¬í•­ ì‚¬ì§„ë“¤ì—ì„œ ì¶”ì¶œí•œ ì •ë³´]ë¥¼ ì¢…í•©í•˜ì—¬,
ë²•ì ìœ¼ë¡œ ì™„ë²½í•œ **'ì‹í’ˆí‘œì‹œì‚¬í•­ ê¸°ì¤€ ë°ì´í„°(Standard)'**ë¥¼ ì‹¤ì œ ë¼ë²¨ í˜•ì‹ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.

[ë¶„ì„ ë‹¨ê³„]
1. **Excel ë°ì´í„° ë¶„ì„**: ë°°í•©ë¹„ìœ¨(%)ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì›ì¬ë£Œ ë‚˜ì—´ ìˆœì„œë¥¼ ê²°ì •í•˜ì„¸ìš”. (ê°€ì¥ ì¤‘ìš”)
2. **ì´ë¯¸ì§€ ë°ì´í„° ë§¤í•‘**: Excelì— ì íŒ ì›ì¬ë£Œëª…(ì˜ˆ: 'ê°„ì¥')ì— í•´ë‹¹í•˜ëŠ” ì‚¬ì§„(ì›ì¬ë£Œ ë¼ë²¨)ì„ ì°¾ì•„ì„œ ìƒì„¸ ì •ë³´(ë³µí•©ì›ì¬ë£Œ ë‚´ì—­, ì•Œë ˆë¥´ê¸°, ì›ì‚°ì§€)ë¥¼ ë³´ê°•í•˜ì„¸ìš”.
    - ì˜ˆ: Excelì—” 'ê°„ì¥'ë§Œ ìˆì§€ë§Œ, ì‚¬ì§„ì— 'íƒˆì§€ëŒ€ë‘(ì¸ë„ì‚°), ì†Œë§¥(ë°€)'ì´ ìˆë‹¤ë©´ ì´ë¥¼ ë°˜ì˜í•´ì•¼ í•¨.
    - **ì¤‘ìš”**: ë³´ê´€ë°©ë²•, í¬ì¥ì¬ì§ˆ ë“±ì€ ë¬´ì‹œí•˜ê³  ì›ì¬ë£Œ ê´€ë ¨ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.
3. **ë²•ë¥  ê²€í† **: ì œê³µëœ ë²•ë ¹ì„ ì°¸ê³ í•˜ì—¬ í‘œì‹œì‚¬í•­ì´ ë²•ì ìœ¼ë¡œ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.
4. **ìµœì¢… ì¡°í•©**: í’ˆëª©ì œì¡°ë³´ê³ ì„œ ê¸°ë°˜ì˜ ë¹„ìœ¨ê³¼ ì›ì¬ë£Œ ë¼ë²¨ì˜ ìƒì„¸ ë‚´ìš©ì„ í•©ì³ ìµœì¢… í‘œì‹œ í…ìŠ¤íŠ¸ë¥¼ ë§Œë“œì„¸ìš”.

[ì¶œë ¥ ì–‘ì‹ - JSON]
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì‹¤ì œ ì‹í’ˆ ë¼ë²¨ í˜•ì‹ì²˜ëŸ¼ êµ¬ì¡°í™”í•˜ì„¸ìš”.
{
    "product_info": {
        "product_name": "ì œí’ˆëª…",
        "food_type": "ì‹í’ˆì˜ ìœ í˜• (ì˜ˆ: ì–´ë¬µ(ìœ íƒ•ì²˜ë¦¬ì œí’ˆ/ë¹„ì‚´ê· ))",
        "net_weight": "ë‚´ìš©ëŸ‰ (ì˜ˆ: 1kg)",
        "expiration_date": "ì†Œë¹„ê¸°í•œ (ì˜ˆ: ì „ë©´ ë³„ë„í‘œì‹œì¼ê¹Œì§€)",
        "storage_method": "ë³´ê´€ë°©ë²• (ì˜ˆ: 0~10â„ƒì´í•˜ ëƒ‰ì¥ë³´ê´€)",
        "packaging_material": "í¬ì¥ì¬ì§ˆ (ì˜ˆ: í´ë¦¬ì—í‹¸ë Œ(ë‚´ë©´))",
        "item_report_number": "í’ˆëª©ë³´ê³ ë²ˆí˜¸",
        "front_calories": "ì „ë©´ë¶€ ì´ì—´ëŸ‰/ë¬¸êµ¬ (ì˜ˆ: 1,291kcal / ì—°ìœ¡70.6%, ë‹¹ê·¼4.41%)"
    },
    "ingredients": {
        "structured_list": [
            "ëƒ‰ë™ì—°ìœ¡70.6%(ì™¸êµ­ì‚°/ì–´ìœ¡ì‚´, ì„¤íƒ•, D-ì†Œë¹„í†¨, ì‚°ë„ì¡°ì ˆì œ)",
            "ì „ë¶„ê°€ê³µí’ˆ1 [ì¹´ì‚¬ë°”ì „ë¶„(íƒœêµ­, ë² íŠ¸ë‚¨ì‚°), ê°ìì „ë¶„]",
            "í˜¼í•©ì œì œ[ì¸ì‚°ì´ì „ë¶„(íƒ€í”¼ì˜¤ì¹´), ë±ìŠ¤íŠ¸ë¦°]",
            "ë‹¹ê·¼(êµ­ë‚´ì‚°)",
            "..."
        ],
        "continuous_text": "ëƒ‰ë™ì—°ìœ¡70.6%(ì™¸êµ­ì‚°/ì–´ìœ¡ì‚´, ì„¤íƒ•, D-ì†Œë¹„í†¨, ì‚°ë„ì¡°ì ˆì œ), ì „ë¶„ê°€ê³µí’ˆ1 [ì¹´ì‚¬ë°”ì „ë¶„(íƒœêµ­, ë² íŠ¸ë‚¨ì‚°), ê°ìì „ë¶„], í˜¼í•©ì œì œ[ì¸ì‚°ì´ì „ë¶„(íƒ€í”¼ì˜¤ì¹´), ë±ìŠ¤íŠ¸ë¦°], ë‹¹ê·¼(êµ­ë‚´ì‚°), ..."
    },
    "allergens": {
        "contains": ["ëŒ€ë‘", "ê²Œ"],
        "manufacturing_facility": "ë³¸ ì œí’ˆì€ ë°€, ê³„ë€, ìƒˆìš°, ì˜¤ì§•ì–´, ê³ ë“±ì–´, ìš°ìœ , ì‡ ê³ ê¸°, í† ë§ˆí† , ì¡°ê°œë¥˜(êµ´â€¤ì „ë³µ,í™í•© í¬í•¨)ë¥¼ ì‚¬ìš©í•œ ì œí’ˆê³¼ ê°™ì€ ì œì¡°ì‹œì„¤ì—ì„œ ì œì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤."
    },
    "nutrition_info": {
        "total_content": "1000 g",
        "per_100g": {
            "calories": "130 Kcal",
            "sodium": {"amount": "530 mg", "daily_value": "27%"},
            "fat": {"amount": "1.5 g", "daily_value": "3%"},
            "cholesterol": {"amount": "17 mg", "daily_value": "6%"},
            "carbohydrates": {"amount": "19 g", "daily_value": "6%"},
            "sugars": {"amount": "5 g", "daily_value": "5%"},
            "trans_fat": {"amount": "0 g", "daily_value": "0%"},
            "saturated_fat": {"amount": "0.3 g", "daily_value": "2%"},
            "protein": {"amount": "10 g", "daily_value": "18%"}
        },
        "disclaimer": "1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)ì€ 2,000kcal ê¸°ì¤€ì´ë¯€ë¡œ ê°œì¸ì˜ í•„ìš” ì—´ëŸ‰ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    },
    "manufacturer": {
        "name": "ì‚¼ì§„ì‹í’ˆ(ì£¼)",
        "address": "ë¶€ì‚°ê´‘ì—­ì‹œ ì‚¬í•˜êµ¬ ë‹¤ëŒ€ë¡œ 1066ë²ˆê¸¸ 51(ì¥ë¦¼ë™)"
    },
    "precautions": [
        "ë°˜ë“œì‹œ ëƒ‰ì¥ë³´ê´€í•˜ì‹œê³  ê°œë´‰ í›„ì—ëŠ” ë¹ ë¥¸ì‹œì¼ ë‚´ ì„­ì·¨í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤.",
        "ê°„í˜¹ í‘ë§‰ì´ ë°œê²¬ë  ìˆ˜ ìˆìœ¼ë‚˜ ìƒì„  ë‚´ë¶€ë³µë§‰ì´ì˜¤ë‹ˆ ì•ˆì‹¬í•˜ê³  ë“œì‹œê¸° ë°”ëë‹ˆë‹¤.",
        "ë°˜í’ˆ ë° êµí™˜: ìœ í†µ ì¤‘ ë³€ì§ˆ íŒŒì†ëœ ì œí’ˆì€ ë³¸ì‚¬ ë° êµ¬ì…ì²˜ì—ì„œ êµí™˜í•´ë“œë¦½ë‹ˆë‹¤.",
        "ë³¸ ì œí’ˆì€ ê³µì •ê±°ë˜ìœ„ì›íšŒê³ ì‹œ ì†Œë¹„ì ë¶„ìŸí•´ê²°ê¸°ì¤€ì— ì˜ê±° êµí™˜ ë˜ëŠ” ë³´ìƒë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "ë¶€ì •, ë¶ˆëŸ‰ì‹í’ˆ ì‹ ê³ ëŠ” êµ­ë²ˆì—†ì´ 1399"
    ],
    "law_compliance": {
        "status": "compliant" | "needs_review",
        "issues": ["ë²•ë¥  ìœ„ë°˜ ì‚¬í•­ ëª©ë¡ (ìˆëŠ” ê²½ìš°)"]
    },
    "details": [
        {"name": "ì›ì¬ë£Œëª…", "ratio": "ë°°í•©ë¹„ìœ¨", "origin": "ì›ì‚°ì§€", "sub_ingredients": "í•˜ìœ„ì›ë£Œ"}
    ]
}

**ì¤‘ìš”**: 
- Excel ë°ì´í„°ì—ì„œ ì¶”ì¶œ ê°€ëŠ¥í•œ ëª¨ë“  ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”.
- ì˜ì–‘ì •ë³´ëŠ” Excelì— ìˆëŠ” ê²½ìš°ì—ë§Œ í¬í•¨í•˜ê³ , ì—†ìœ¼ë©´ ë¹ˆ ê°ì²´ë¡œ ë‘ì„¸ìš”.
- ì›ì¬ë£Œëª…ì€ ë°°í•©ë¹„ìœ¨ ìˆœì„œëŒ€ë¡œ ì •í™•íˆ ë‚˜ì—´í•˜ì„¸ìš”.
- ì‹¤ì œ ë¼ë²¨ì— í‘œì‹œë˜ëŠ” í˜•ì‹ ê·¸ëŒ€ë¡œ êµ¬ì¡°í™”í•˜ì„¸ìš”.
"""

# 2. ë””ìì¸ ê²€ì¦ìš© (ì •ë‹µì§€ vs ë””ìì¸PDF)

PROMPT_VERIFY_DESIGN = """
ë‹¹ì‹ ì€ ì‹í’ˆí‘œì‹œì‚¬í•­ ê°ì‚¬ AIì…ë‹ˆë‹¤.
ì œê³µëœ [Standard(ê¸°ì¤€ì„œ)]ì™€ [Design(ë””ìì¸)]ì„ 1:1 ì •ë°€ ëŒ€ì¡°í•˜ì—¬, ì•„ë˜ ê·œì¹™ì— ë”°ë¼ ëƒ‰ì² í•˜ê²Œ ì±„ì í•˜ì„¸ìš”.

=== ğŸš¨ ì´ˆì¤‘ìš”: OCR ê·œì¹™ ğŸš¨ ===
**ì ˆëŒ€ ê¸ˆì§€ ì‚¬í•­**:
âŒ ë§ì¶¤ë²• ìë™ ë³´ì • ê¸ˆì§€ (í‹€ë¦° ê¸€ìë„ ê·¸ëŒ€ë¡œ ì¶”ì¶œ)
âŒ ì˜¤íƒ€ ìˆ˜ì • ê¸ˆì§€ (ì „ë°˜ â†’ ì „ë¶„ ìˆ˜ì • ê¸ˆì§€)
âŒ ë„ì–´ì“°ê¸° ìë™ ë³´ì • ê¸ˆì§€
âŒ ìˆ«ì/ë‹¨ìœ„ ë³´ì • ê¸ˆì§€ (900gê³¼ 900 gì€ ë‹¤ë¦„)
âŒ ë¬¸ì¥ë¶€í˜¸ ë³´ì • ê¸ˆì§€ (ì , ì‰¼í‘œ ë¹ ì§„ ê²ƒë„ ê·¸ëŒ€ë¡œ)

... (ê¸°ì¡´ PROMPT_VERIFY_DESIGN ë‚´ìš© ê·¸ëŒ€ë¡œ, ìƒëµ ì—†ì´ ìœ ì§€) ...
"""


def check_image_quality(img):
    """ì´ë¯¸ì§€ í’ˆì§ˆì„ í™•ì¸í•˜ê³  ê²½ê³  ë°˜í™˜"""
    width, height = img.size
    warnings = []

    if width < 800 or height < 800:
        warnings.append(f"âš ï¸ ì´ë¯¸ì§€ í•´ìƒë„ê°€ ë‚®ìŠµë‹ˆë‹¤ ({width}x{height}). ì •í™•ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ë°ê±°ë‚˜ ì–´ë‘ìš´ì§€ í™•ì¸
    if img.mode in ('L', 'RGB'):
        if img.mode == 'RGB':
            img_gray = img.convert('L')
        else:
            img_gray = img
        pixels = list(img_gray.getdata())
        avg_brightness = sum(pixels) / len(pixels)
        if avg_brightness < 50:
            warnings.append("âš ï¸ ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ì–´ë‘¡ìŠµë‹ˆë‹¤.")
        elif avg_brightness > 200:
            warnings.append("âš ï¸ ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ë°ìŠµë‹ˆë‹¤.")

    return warnings


# --- íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ---

def process_file_to_part(file_storage):
    """íŒŒì¼ì„ Geminiê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” Part ê°ì²´ë¡œ ë³€í™˜"""
    mime_type = file_storage.mimetype
    file_data = file_storage.read()
    file_storage.seek(0)  # í¬ì¸í„° ì´ˆê¸°í™”

    # ì—‘ì…€ íŒŒì¼ì€ í…ìŠ¤íŠ¸(CSV)ë¡œ ë³€í™˜í•´ì„œ ì£¼ëŠ”ê²Œ AIê°€ ë” ì˜ ì´í•´í•¨
    if mime_type in ['application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'application/vnd.ms-excel']:
        try:
            df = pd.read_excel(io.BytesIO(file_data))
            csv_text = df.to_csv(index=False)
            return {"text": f"--- [Excel ë°°í•©ë¹„ ë°ì´í„°] ---\n{csv_text}"}
        except Exception as e:
            print(f"ì—‘ì…€ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None

    # ğŸ”¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ìµœì†Œí™” (ì•ˆì •ì„± í–¥ìƒ)
    if mime_type.startswith('image/'):
        try:
            img = PIL.Image.open(io.BytesIO(file_data))

            # âœ… ìµœì†Œí•œì˜ ì „ì²˜ë¦¬ë§Œ ìˆ˜í–‰
            # 1. íˆ¬ëª…ë„ ì œê±° (í•„ìˆ˜)
            if img.mode in ('RGBA', 'LA', 'P'):
                background = PIL.Image.new('RGB', img.size, (255, 255, 255))
                if img.mode == 'P':
                    img = img.convert('RGBA')
                background.paste(img, mask=img.split()[-1] if img.mode in ('RGBA', 'LA') else None)
                img = background

            # 2. RGB ìœ ì§€ (í‘ë°± ë³€í™˜ ì œê±°)
            if img.mode != 'RGB':
                img = img.convert('RGB')

            # 3. í•´ìƒë„ë§Œ ì¡°ì • (ë„ˆë¬´ ì‘ìœ¼ë©´)
            width, height = img.size
            if width < 1200 or height < 1200:
                scale = max(1200 / width, 1200 / height)
                new_size = (int(width * scale), int(height * scale))
                img = img.resize(new_size, PIL.Image.LANCZOS)

            # âŒ ëŒ€ë¹„, ì„ ëª…ë„, ë°ê¸° ì¡°ì • ì œê±° (ë¶ˆì•ˆì •ì„± ì›ì¸)

            byte_io = io.BytesIO()
            img.save(byte_io, format='PNG', dpi=(300, 300))
            byte_io.seek(0)

            return {"mime_type": "image/png", "data": byte_io.read()}
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ (ì›ë³¸ ì‚¬ìš©): {e}")
            return {"mime_type": mime_type, "data": file_data}

    return {"mime_type": mime_type, "data": file_data}


def extract_ingredient_info_from_image(image_file):
    """ì›ì¬ë£Œ í‘œì‹œì‚¬í•­ ì´ë¯¸ì§€ì—ì„œ í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ"""
    try:
        image_data = image_file.read()
        image_file.seek(0)

        img_pil = PIL.Image.open(io.BytesIO(image_data))

        generation_config = {
            "temperature": 0.0,
            "top_p": 1.0,
            "top_k": 1,
            "candidate_count": 1,
            "max_output_tokens": 4096,
            "response_mime_type": "application/json"
        }

        model = genai.GenerativeModel(MODEL_NAME)

        parts = [PROMPT_EXTRACT_INGREDIENT_INFO, img_pil]
        response = model.generate_content(parts)

        result_text = response.text.strip()
        # JSON íŒŒì‹±
        if result_text.startswith("```json"):
            result_text = result_text[7:-3]
        elif result_text.startswith("```"):
            result_text = result_text.split("```")[1].strip()
            if result_text.startswith("json"):
                result_text = result_text[4:].strip()

        return json.loads(result_text)
    except json.JSONDecodeError as e:
        print(f"ì›ì¬ë£Œ ì •ë³´ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        print(f"ì‘ë‹µ í…ìŠ¤íŠ¸: {result_text[:500]}...")
        return None
    except Exception as e:
        print(f"ì›ì¬ë£Œ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return None


def create_standard_excel(data):
    """ê¸°ì¤€ ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ìƒì„±"""
    output = io.BytesIO()

    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        # 1. ì œí’ˆ ì •ë³´ ì‹œíŠ¸
        if 'product_info' in data:
            product_df = pd.DataFrame([data['product_info']])
            product_df.to_excel(writer, sheet_name='ì œí’ˆì •ë³´', index=False)

        # 2. ì›ì¬ë£Œëª… ì‹œíŠ¸
        if 'ingredients' in data:
            ingredients_data = []
            if 'structured_list' in data['ingredients']:
                for idx, item in enumerate(data['ingredients']['structured_list'], 1):
                    ingredients_data.append({
                        'ìˆœë²ˆ': idx,
                        'ì›ì¬ë£Œëª…': item
                    })
            ingredients_df = pd.DataFrame(ingredients_data)
            if not ingredients_df.empty:
                ingredients_df.to_excel(writer, sheet_name='ì›ì¬ë£Œëª…', index=False)

            # ì—°ì† í…ìŠ¤íŠ¸ë„ ì¶”ê°€
            if 'continuous_text' in data['ingredients']:
                continuous_df = pd.DataFrame([{
                    'ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸': data['ingredients']['continuous_text']
                }])
                continuous_df.to_excel(writer, sheet_name='ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸', index=False)

        # 3. ì•Œë ˆë¥´ê¸° ì •ë³´ ì‹œíŠ¸
        if 'allergens' in data:
            allergens_data = []
            if 'contains' in data['allergens']:
                allergens_data.append({
                    'í•­ëª©': 'í•¨ìœ  ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ',
                    'ë‚´ìš©': ', '.join(data['allergens']['contains'])
                })
            if 'manufacturing_facility' in data['allergens']:
                allergens_data.append({
                    'í•­ëª©': 'ì œì¡°ì‹œì„¤ ì•ˆë‚´',
                    'ë‚´ìš©': data['allergens']['manufacturing_facility']
                })
            if allergens_data:
                allergens_df = pd.DataFrame(allergens_data)
                allergens_df.to_excel(writer, sheet_name='ì•Œë ˆë¥´ê¸°ì •ë³´', index=False)

        # 4. ì˜ì–‘ì •ë³´ ì‹œíŠ¸
        if 'nutrition_info' in data and 'per_100g' in data['nutrition_info']:
            nutrition_data = []
            nut = data['nutrition_info']['per_100g']
            if 'calories' in nut:
                nutrition_data.append({
                    'ì˜ì–‘ì„±ë¶„': 'ì´ ì—´ëŸ‰',
                    '100g ë‹¹': nut['calories'],
                    '1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)': '-'
                })
            for key, value in nut.items():
                if key != 'calories' and isinstance(value, dict):
                    nutrition_data.append({
                        'ì˜ì–‘ì„±ë¶„': key,
                        '100g ë‹¹': value.get('amount', ''),
                        '1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)': value.get('daily_value', '')
                    })
            if nutrition_data:
                nutrition_df = pd.DataFrame(nutrition_data)
                nutrition_df.to_excel(writer, sheet_name='ì˜ì–‘ì •ë³´', index=False)

        # 5. ì œì¡°ì› ì •ë³´ ì‹œíŠ¸
        if 'manufacturer' in data:
            manufacturer_df = pd.DataFrame([data['manufacturer']])
            manufacturer_df.to_excel(writer, sheet_name='ì œì¡°ì›ì •ë³´', index=False)

        # 6. ì£¼ì˜ì‚¬í•­ ì‹œíŠ¸
        if 'precautions' in data:
            precautions_df = pd.DataFrame([{'ì£¼ì˜ì‚¬í•­': item} for item in data['precautions']])
            precautions_df.to_excel(writer, sheet_name='ì£¼ì˜ì‚¬í•­', index=False)

        # 7. ìƒì„¸ ì •ë³´ ì‹œíŠ¸ (ì›ì¬ë£Œ ìƒì„¸)
        if 'details' in data and data['details']:
            details_df = pd.DataFrame(data['details'])
            details_df.to_excel(writer, sheet_name='ì›ì¬ë£Œìƒì„¸', index=False)

    output.seek(0)
    return output


# --- ë¼ìš°íŠ¸ ---

@app.route('/')
def index():
    return render_template('index.html')


# 1ë‹¨ê³„: ì •ë‹µì§€ ë§Œë“¤ê¸° (ì—‘ì…€ + ì›ì¬ë£Œ ì‚¬ì§„ë“¤ ëª½ë•…)
@app.route('/api/create-standard', methods=['POST'])
def create_standard():
    print("âš™ï¸ 1ë‹¨ê³„: ê¸°ì¤€ ë°ì´í„° ìƒì„± ì‹œì‘...")

    # 1. ì—‘ì…€ íŒŒì¼ (ë°°í•©ë¹„)
    excel_file = request.files.get('excel_file')

    # 2. ì›ì¬ë£Œ ì´ë¯¸ì§€ë“¤ (ì—¬ëŸ¬ ê°œ)
    raw_images = request.files.getlist('raw_images')

    if not excel_file:
        return jsonify({"error": "ë°°í•©ë¹„ ì—‘ì…€ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    # AIì—ê²Œ ë³´ë‚¼ ë°ì´í„° ê¾¸ëŸ¬ë¯¸ ë§Œë“¤ê¸°
    parts = []

    # (1) í”„ë¡¬í”„íŠ¸ + ë²•ë ¹ ì •ë³´
    enhanced_prompt = PROMPT_CREATE_STANDARD
    if ALL_LAW_TEXT:
        enhanced_prompt += f"\n\n--- [ì°¸ê³  ë²•ë ¹] ---\n{ALL_LAW_TEXT}\n--- [ë²•ë ¹ ë] ---\n"
    parts.append(enhanced_prompt)

    # (2) ì—‘ì…€ ë°ì´í„°
    excel_part = process_file_to_part(excel_file)
    if excel_part:
        parts.append(excel_part)

    # (3) ì›ì¬ë£Œ ì‚¬ì§„ë“¤ - í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ
    ingredient_info_list = []
    for img in raw_images[:15]:
        print(f"ğŸ“· ì›ì¬ë£Œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘: {img.filename}")
        ingredient_info = extract_ingredient_info_from_image(img)
        if ingredient_info:
            ingredient_info_list.append(ingredient_info)

    # ì¶”ì¶œëœ ì›ì¬ë£Œ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ê°€
    if ingredient_info_list:
        ingredients_text = "--- [ì›ì¬ë£Œ í‘œì‹œì‚¬í•­ì—ì„œ ì¶”ì¶œí•œ ì •ë³´] ---\n"
        for idx, info in enumerate(ingredient_info_list, 1):
            ingredients_text += f"\n[ì›ì¬ë£Œ {idx}]\n"
            ingredients_text += json.dumps(info, ensure_ascii=False, indent=2)
            ingredients_text += "\n"
        ingredients_text += "--- [ì›ì¬ë£Œ ì •ë³´ ë] ---\n"
        parts.append({"text": ingredients_text})

    print(f"ğŸ“‚ ì²˜ë¦¬ ì¤‘: ì—‘ì…€ 1ê°œ + ì›ì¬ë£Œ ì´ë¯¸ì§€ {len(raw_images)}ì¥ (ì •ë³´ ì¶”ì¶œ ì™„ë£Œ)")

    try:
        generation_config = {
            "temperature": 0.0,
            "top_p": 1.0,
            "top_k": 1,
            "candidate_count": 1,
            "max_output_tokens": 32768,
            "response_mime_type": "application/json"
        }

        model = genai.GenerativeModel(
            MODEL_NAME,
            generation_config=generation_config
        )

        response = model.generate_content(parts)

        # JSON íŒŒì‹±
        result_text = response.text.strip()

        # JSON ì½”ë“œ ë¸”ë¡ ì œê±°
        if result_text.startswith("```json"):
            result_text = result_text[7:]
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        elif result_text.startswith("```"):
            # ``` ... ``` í˜•ì‹ ì²˜ë¦¬
            lines = result_text.split("\n")
            if lines[0].startswith("```"):
                result_text = "\n".join(lines[1:])
            if result_text.endswith("```"):
                result_text = result_text[:-3]

        result_text = result_text.strip()

        # JSON íŒŒì‹± ì‹œë„
        try:
            result = json.loads(result_text)
        except json.JSONDecodeError as json_err:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {json_err}")
            print(f"ì‘ë‹µ í…ìŠ¤íŠ¸ (ì²˜ìŒ 1000ì): {result_text[:1000]}")
            print(f"ì˜¤ë¥˜ ìœ„ì¹˜: line {json_err.lineno}, column {json_err.colno}")
            # JSON ìˆ˜ì • ì‹œë„ (ë§ˆì§€ë§‰ ì‰¼í‘œ ì œê±° ë“±)
            try:
                result_text_fixed = result_text.replace(',\n}', '\n}').replace(',\n]', '\n]')
                result = json.loads(result_text_fixed)
                print("âœ… JSON ìˆ˜ì • í›„ íŒŒì‹± ì„±ê³µ")
            except Exception:
                return jsonify({"error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(json_err)}. ì‘ë‹µì˜ ì¼ë¶€: {result_text[:200]}..."}), 500

        return jsonify(result)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# ê¸°ì¤€ ë°ì´í„° ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
@app.route('/api/download-standard-excel', methods=['POST'])
def download_standard_excel():
    """ê¸°ì¤€ ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "ê¸°ì¤€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

        excel_buffer = create_standard_excel(data)
        product_name = data.get('product_info', {}).get('product_name', 'ê¸°ì¤€ë°ì´í„°') or data.get('product_name', 'ê¸°ì¤€ë°ì´í„°')
        filename = f"{product_name}_ê¸°ì¤€ë°ì´í„°.xlsx"

        return send_file(
            excel_buffer,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name=filename
        )
    except Exception as e:
        print(f"âŒ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# ì—‘ì…€ íŒŒì¼ì—ì„œ ê¸°ì¤€ ë°ì´í„° ì½ê¸°
@app.route('/api/read-standard-excel', methods=['POST'])
def read_standard_excel():
    """ì—‘ì…€ íŒŒì¼ì—ì„œ ê¸°ì¤€ ë°ì´í„°ë¥¼ ì½ì–´ì˜´"""
    try:
        excel_file = request.files.get('excel_file')
        if not excel_file:
            return jsonify({"error": "ì—‘ì…€ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        df_dict = pd.read_excel(
            io.BytesIO(excel_file.read()),
            sheet_name=None,
            engine='openpyxl',
            dtype=str,
            keep_default_na=False,
            na_filter=False
        )

        for sheet_name, df in df_dict.items():
            df_dict[sheet_name] = df.astype(str)

        result = {}

        if 'ì œí’ˆì •ë³´' in df_dict:
            product_info = df_dict['ì œí’ˆì •ë³´'].to_dict('records')[0]
            result['product_info'] = product_info

        first_sheet_name = list(df_dict.keys())[0]
        first_sheet_df = df_dict[first_sheet_name]

        if 'ì›ì¬ë£Œëª…' in df_dict:
            ingredients_list = df_dict['ì›ì¬ë£Œëª…']['ì›ì¬ë£Œëª…'].dropna().tolist()
            result['ingredients'] = {
                'structured_list': ingredients_list,
                'continuous_text': ', '.join(ingredients_list)
            }
        elif 'ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸' in df_dict:
            continuous_text = df_dict['ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸']['ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸'].iloc[0]
            result['ingredients'] = {
                'structured_list': continuous_text.split(', '),
                'continuous_text': continuous_text
            }
        elif not first_sheet_df.empty:
            first_column = first_sheet_df.columns[0]
            if 'ì›ì¬ë£Œëª…' in first_sheet_df.columns:
                ingredients_list = first_sheet_df['ì›ì¬ë£Œëª…'].dropna().tolist()
            else:
                ingredients_list = first_sheet_df[first_column].dropna().astype(str).tolist()

            if ingredients_list:
                result['ingredients'] = {
                    'structured_list': ingredients_list,
                    'continuous_text': ', '.join(ingredients_list)
                }

        if 'ì•Œë ˆë¥´ê¸°ì •ë³´' in df_dict:
            allergens_df = df_dict['ì•Œë ˆë¥´ê¸°ì •ë³´']
            result['allergens'] = {}
            for _, row in allergens_df.iterrows():
                if row['í•­ëª©'] == 'í•¨ìœ  ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ':
                    result['allergens']['contains'] = row['ë‚´ìš©'].split(', ')
                elif row['í•­ëª©'] == 'ì œì¡°ì‹œì„¤ ì•ˆë‚´':
                    result['allergens']['manufacturing_facility'] = row['ë‚´ìš©']

        if 'ì˜ì–‘ì •ë³´' in df_dict:
            nutrition_df = df_dict['ì˜ì–‘ì •ë³´']
            per_100g = {}
            for _, row in nutrition_df.iterrows():
                if row['ì˜ì–‘ì„±ë¶„'] == 'ì´ ì—´ëŸ‰':
                    per_100g['calories'] = row['100g ë‹¹']
                else:
                    per_100g[row['ì˜ì–‘ì„±ë¶„']] = {
                        'amount': row['100g ë‹¹'],
                        'daily_value': row['1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)']
                    }
            result['nutrition_info'] = {'per_100g': per_100g}

        if 'ì œì¡°ì›ì •ë³´' in df_dict:
            result['manufacturer'] = df_dict['ì œì¡°ì›ì •ë³´'].to_dict('records')[0]

        if 'ì£¼ì˜ì‚¬í•­' in df_dict:
            result['precautions'] = df_dict['ì£¼ì˜ì‚¬í•­']['ì£¼ì˜ì‚¬í•­'].tolist()

        if 'ì›ì¬ë£Œìƒì„¸' in df_dict:
            result['details'] = df_dict['ì›ì¬ë£Œìƒì„¸'].to_dict('records')

        return jsonify(result)
    except Exception as e:
        print(f"âŒ ì—‘ì…€ ì½ê¸° ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# 2ë‹¨ê³„: ê²€ì¦í•˜ê¸° (ì—‘ì…€ íŒŒì¼ ë˜ëŠ” JSON + ë””ìì¸ ì´ë¯¸ì§€)
@app.route('/api/verify-design', methods=['POST'])
def verify_design():
    print("ğŸ•µï¸â€â™‚ï¸ 2ë‹¨ê³„: ë””ìì¸ ê²€ì¦ ì‹œì‘...")

    try:
        # 1. íŒŒì¼ ë°›ê¸°
        design_file = request.files.get('design_file')
        standard_excel = request.files.get('standard_excel')
        standard_json = request.form.get('standard_data')

        if not design_file:
            return jsonify({"error": "ë””ìì¸ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        design_file.seek(0)
        if standard_excel:
            standard_excel.seek(0)

        # 2. ê¸°ì¤€ ë°ì´í„° ë¡œë”© (ì—‘ì…€ â†’ JSON)
        if standard_excel:
            try:
                df_dict = pd.read_excel(
                    io.BytesIO(standard_excel.read()),
                    sheet_name=None,
                    engine='openpyxl',
                    dtype=str,
                    keep_default_na=False
                )

                first_sheet_name = list(df_dict.keys())[0]
                first_sheet_df = df_dict[first_sheet_name]
                standard_data = {}

                if not first_sheet_df.empty:
                    col = first_sheet_df.columns[0]
                    if 'ì›ì¬ë£Œëª…' in first_sheet_df.columns:
                        col = 'ì›ì¬ë£Œëª…'

                    ingredients_list = first_sheet_df[col].dropna().astype(str).tolist()
                    standard_data = {
                        'ingredients': {
                            'structured_list': ingredients_list,
                            'continuous_text': ', '.join(ingredients_list)
                        }
                    }

                standard_json = json.dumps(standard_data, ensure_ascii=False)

            except Exception as e:
                return jsonify({"error": f"ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨: {str(e)}"}), 400

        # 3. âœ… ë²•ë ¹ í…ìŠ¤íŠ¸ ë¡œë”©
        law_text = ""
        all_law_files = glob.glob('law_*.txt')
        print(f"ğŸ“š ë²•ë ¹ íŒŒì¼ ë¡œë”© ì¤‘: {len(all_law_files)}ê°œ ë°œê²¬")

        for file_path in all_law_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    law_text += f"\n\n=== [ì°¸ê³  ë²•ë ¹: {file_path}] ===\n{content}\n==========================\n"
            except Exception as e:
                print(f"âš ï¸ ë²•ë ¹ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ ({file_path}): {e}")

        # 4. âœ… OCR ì•ˆì •í™” (3íšŒ ì¬ì‹œë„)
        forced_design_text = ""
        ocr_errors = []

        for attempt in range(1, 4):
            try:
                print(f"ğŸ”„ OCR ì‹œë„ {attempt}/3")

                design_file.seek(0)

                ocr_parts = [
                    PROMPT_EXTRACT_RAW_TEXT,
                    process_file_to_part(design_file)
                ]

                ocr_model = genai.GenerativeModel(
                    MODEL_NAME,
                    generation_config={
                        "temperature": 0.0,
                        "top_k": 1,
                        "top_p": 1.0,
                        "response_mime_type": "application/json",
                        "max_output_tokens": 8192
                    }
                )

                ocr_response = ocr_model.generate_content(ocr_parts)
                raw_text = ocr_response.text.strip()

                if raw_text.startswith("```"):
                    raw_text = raw_text.split("```")[1].strip()
                    if raw_text.startswith("json"):
                        raw_text = raw_text[4:].strip()

                ocr_json = json.loads(raw_text)
                forced_design_text = ocr_json.get("raw_text", "").strip()

                if forced_design_text:
                    print(f"âœ… OCR ì„±ê³µ ({attempt}íšŒ)")
                    break
                else:
                    raise ValueError("raw_text ë¹„ì–´ ìˆìŒ")

            except Exception as e:
                ocr_errors.append(str(e))

        if not forced_design_text:
            forced_design_text = "[OCR ì‹¤íŒ¨]"

        # 5. âœ… Gemini í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ğŸ“š ë²•ë ¹ ë°˜ë“œì‹œ í¬í•¨)
        parts = [f"""
ğŸš¨ğŸš¨ğŸš¨ ì ˆëŒ€ ê·œì¹™ ğŸš¨ğŸš¨ğŸš¨
- ë„ì–´ì“°ê¸° ì¤‘ìš”: "16 g" â‰  "16g"
- ìˆ«ì ê·¸ëŒ€ë¡œ: "221%" â†’ "221%"
- ì˜¤íƒ€ ê·¸ëŒ€ë¡œ ìœ ì§€
- ì ˆëŒ€ ì¶”ì¸¡ ê¸ˆì§€

{PROMPT_VERIFY_DESIGN}

[ì°¸ê³  ë²•ë ¹]
{law_text[:60000]}

[ê¸°ì¤€ ë°ì´í„°]
{standard_json}

[ë””ìì¸ OCR (ê°•ì œ ì¶”ì¶œ)]
{forced_design_text}
"""]

        parts.append(process_file_to_part(design_file))

        # 6. âœ… Gemini í˜¸ì¶œ
        model = genai.GenerativeModel(MODEL_NAME)
        response = model.generate_content(parts)

        result_text = response.text.strip()

        match = re.search(r"(\{.*\})", result_text, re.DOTALL)
        if not match:
            return jsonify({"error": "Gemini ì‘ë‹µì—ì„œ JSONì„ ì°¾ì§€ ëª»í•¨"}), 500

        json_obj = json.loads(match.group(1))

        # âœ… OCR ì›ë¬¸ ê°•ì œ ì‚½ì…
        json_obj["design_ocr_text"] = forced_design_text

        # 7. âœ… í•˜ì´ë¼ì´íŠ¸ ìœ„ì¹˜ ê³„ì‚° (ë‹¨ì–´ ì „ì²´ ê¸°ì¤€)
        design_text = forced_design_text
        issues = json_obj.get("issues", [])

        # position ì±„ìš°ê¸°
        issues = add_issue_positions(issues, design_text)
        json_obj["issues"] = issues

        # í•˜ì´ë¼ì´íŠ¸ HTML ìƒì„±
        highlight_html = design_text

        # ë’¤ì—ì„œ ì•ìœ¼ë¡œ ì²˜ë¦¬í•´ì„œ ì¸ë±ìŠ¤ ê¼¬ì„ ë°©ì§€
        for issue in sorted(issues, key=lambda x: x.get("position", -1), reverse=True):
            pos = issue.get("position")
            if not isinstance(pos, int) or pos < 0 or pos >= len(highlight_html):
                continue

            actual = (issue.get("actual") or "").strip()
            expected = (issue.get("expected") or "").strip()

            # ì‹¤ì œ í‘œì‹œ ë¬¸ìì—´ ì „ì²´ ê¸¸ì´ ê¸°ì¤€
            if actual:
                length = len(actual)
            else:
                # fallback: í•œ ê¸€ìë§Œ
                length = 1

            start = pos
            end = pos + length

            # ë²”ìœ„ ë°©ì–´
            if start < 0:
                start = 0
            if end > len(highlight_html):
                end = len(highlight_html)

            target_text = highlight_html[start:end]

            span = (
                "<span style='background:#ffe6e6; "
                "color:#d32f2f; font-weight:bold;' "
                f"title='ì •ë‹µ: {html_mod.escape(expected)}'>"
                f"{html_mod.escape(target_text)}</span>"
            )

            highlight_html = highlight_html[:start] + span + highlight_html[end:]

        # ì¤„ë°”ê¿ˆì„ <br>ë¡œ ë³€í™˜í•´ì„œ ë¸Œë¼ìš°ì €ì—ì„œ ê·¸ëŒ€ë¡œ ë³´ì´ë„ë¡
        highlight_html = highlight_html.replace("\n", "<br>")
        json_obj["design_ocr_highlighted_html"] = highlight_html

        return jsonify(json_obj)

    except Exception as e:
        print(f"âŒ ê²€ì¦ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


@app.route('/api/verify-design-strict', methods=['POST'])
def verify_design_strict():
    """Pythonìœ¼ë¡œ ì •í™•í•œ ë¹„êµ (AI ì—†ì´)"""
    try:
        design_file = request.files.get('design_file')
        standard_json = request.form.get('standard_data')

        if not design_file or not standard_json:
            return jsonify({"error": "íŒŒì¼ê³¼ ê¸°ì¤€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400

        # â­ íŒŒì¼ í¬ì¸í„° ì´ˆê¸°í™” (ë°˜ë“œì‹œ ì²˜ìŒìœ¼ë¡œ!)
        design_file.seek(0)

        standard_data = json.loads(standard_json)

        # 1. OCR ìˆ˜í–‰ (Gemini)
        parts = [
            PROMPT_EXTRACT_RAW_TEXT,
            process_file_to_part(design_file)
        ]

        model = genai.GenerativeModel(MODEL_NAME, generation_config={
            "temperature": 0.0,
            "top_k": 1,
            "response_mime_type": "application/json"
        })
        response = model.generate_content(parts)

        result_text = response.text.strip()
        if result_text.startswith("```json"):
            result_text = result_text[7:-3]
        elif result_text.startswith("```json"):
            result_text = result_text[3:-3]

        design_ocr = json.loads(result_text)

        # 2. Pythonìœ¼ë¡œ ì •í™•í•œ ë¹„êµ (AI ì—†ì´!)
        all_issues = []

        # ì›ì¬ë£Œëª… ë¹„êµ
        if 'ingredients' in standard_data:
            std_text = standard_data['ingredients']['continuous_text']
        else:
            std_text = ""
        des_text = design_ocr.get('raw_text', '')
        issues = compare_texts_strict(std_text, des_text)

        for issue in issues:
            all_issues.append({
                "type": "Critical" if issue['expected'] not in [' ', ',', '.'] else "Minor",
                "location": f"ì›ì¬ë£Œëª… (ìœ„ì¹˜: {issue['position']})",
                "issue": f"'{issue['expected']}' â†’ '{issue['actual']}'",
                "expected": std_text,
                "actual": des_text,
                "suggestion": f"ìœ„ì¹˜ {issue['position']}ì˜ '{issue['actual']}'ì„(ë¥¼) '{issue['expected']}'(ìœ¼)ë¡œ ìˆ˜ì •"
            })

        # ì ìˆ˜ ê³„ì‚°
        critical_count = sum(1 for i in all_issues if i['type'] == 'Critical')
        minor_count = sum(1 for i in all_issues if i['type'] == 'Minor')
        score = max(0, 100 - critical_count * 5 - minor_count * 2)

        return jsonify({
            "design_ocr_text": design_ocr.get('raw_text', ''),
            "score": score,
            "issues": all_issues,
            "law_compliance": {"status": "compliant", "violations": []}
        })

    except Exception as e:
        print(f"âŒ ê²€ì¦ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# QA ìë£Œ ì—…ë¡œë“œ ë° ì‹í’ˆí‘œì‹œì‚¬í•­ ì‘ì„± API
@app.route('/api/upload-qa', methods=['POST'])
def upload_qa():
    """QA ìë£Œë¥¼ ì—…ë¡œë“œí•˜ê³  ì‹í’ˆí‘œì‹œì‚¬í•­ì„ ì‘ì„±í•©ë‹ˆë‹¤."""
    print("ğŸ“‹ QA ìë£Œ ì—…ë¡œë“œ ë° ì‹í’ˆí‘œì‹œì‚¬í•­ ì‘ì„± ì‹œì‘...")

    qa_files = request.files.getlist('qa_files')

    if not qa_files or len(qa_files) == 0:
        return jsonify({"error": "QA ìë£Œ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    parts = []

    qa_prompt = """
ë‹¹ì‹ ì€ ì‹í’ˆí‘œì‹œì‚¬í•­ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ QA ìë£Œë¥¼ ë¶„ì„í•˜ì—¬ ë²•ë¥ ì„ ì¤€ìˆ˜í•˜ëŠ” ì‹í’ˆí‘œì‹œì‚¬í•­ì„ ì‘ì„±í•˜ì„¸ìš”.

[ì‘ì—… ë‹¨ê³„]
1. QA ìë£Œ ë¶„ì„: ì—‘ì…€, ì´ë¯¸ì§€ ë“± ëª¨ë“  QA ìë£Œë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.
2. ë²•ë¥  ê²€í† : ì œê³µëœ ë²•ë ¹ì„ ì°¸ê³ í•˜ì—¬ í•„ìˆ˜ í‘œì‹œì‚¬í•­ì´ ëª¨ë‘ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
3. ì‹í’ˆí‘œì‹œì‚¬í•­ ì‘ì„±: ë²•ë¥ ì„ ì¤€ìˆ˜í•˜ëŠ” ì™„ì „í•œ ì‹í’ˆí‘œì‹œì‚¬í•­ì„ ì‘ì„±í•˜ì„¸ìš”.

[ì¶œë ¥ ì–‘ì‹ - JSON]
{
    "product_name": "ì œí’ˆëª…",
    "label_text": "ì‘ì„±ëœ ì‹í’ˆí‘œì‹œì‚¬í•­ ì „ì²´ í…ìŠ¤íŠ¸",
    "law_compliance": {
        "status": "compliant" | "needs_review",
        "issues": ["ë²•ë¥  ê²€í†  ì‚¬í•­ ëª©ë¡"]
    },
    "sections": {
        "ingredients": "ì›ì¬ë£Œëª…",
        "nutrition": "ì˜ì–‘ì •ë³´",
        "allergens": "ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ",
        "storage": "ë³´ê´€ë°©ë²•",
        "manufacturer": "ì œì¡°ì‚¬ ì •ë³´"
    }
}
"""

    if ALL_LAW_TEXT:
        qa_prompt += f"\n\n--- [ì°¸ê³  ë²•ë ¹] ---\n{ALL_LAW_TEXT}\n--- [ë²•ë ¹ ë] ---\n"

    parts.append(qa_prompt)

    for qa_file in qa_files[:20]:
        file_part = process_file_to_part(qa_file)
        if file_part:
            parts.append(file_part)

    print(f"ğŸ“‚ QA ìë£Œ ì²˜ë¦¬ ì¤‘: {len(qa_files)}ê°œ íŒŒì¼")

    try:
        model = genai.GenerativeModel(MODEL_NAME)
        response = model.generate_content(parts)

        result_text = response.text.strip()

        if result_text.startswith("```json"):
            result_text = result_text[7:]
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        elif result_text.startswith("```"):
            lines = result_text.split("\n")
            if lines[0].startswith("```"):
                result_text = "\n".join(lines[1:])
            if result_text.endswith("```"):
                result_text = result_text[:-3]

        result_text = result_text.strip()

        try:
            result = json.loads(result_text)
        except json.JSONDecodeError as json_err:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {json_err}")
            print(f"ì‘ë‹µ í…ìŠ¤íŠ¸ (ì²˜ìŒ 1000ì): {result_text[:1000]}")
            print(f"ì˜¤ë¥˜ ìœ„ì¹˜: line {json_err.lineno}, column {json_err.colno}")
            try:
                result_text_fixed = result_text.replace(',\n}', '\n}').replace(',\n]', '\n]')
                result = json.loads(result_text_fixed)
                print("âœ… JSON ìˆ˜ì • í›„ íŒŒì‹± ì„±ê³µ")
            except Exception:
                return jsonify({"error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(json_err)}. ì‘ë‹µì˜ ì¼ë¶€: {result_text[:200]}..."}), 500

        return jsonify(result)

    except Exception as e:
        print(f"âŒ QA ìë£Œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


if __name__ == '__main__':
    print("ğŸš€ ì‚¼ì§„ì–´ë¬µ ì‹í’ˆí‘œì‹œì‚¬í•­ ì™„ì„± í”Œë«í¼ V3.0 ê°€ë™")
    print("   - ì›ë¶€ì¬ë£Œ í‘œì‹œì‚¬í•­ ìŠ¤ë§ˆíŠ¸ ì¶”ì¶œ")
    print("   - ë²•ë¥  ê²€í†  ê¸°ëŠ¥ í†µí•©")
    print("   - QA ìë£Œ ì—…ë¡œë“œ ì§€ì›")
    from waitress import serve

    serve(app, host='0.0.0.0', port=8080)
