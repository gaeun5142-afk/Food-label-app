import os

import json
import io
import glob
import pandas as pd
from flask import Flask, request, jsonify, send_file
from flask import Flask, request, jsonify, render_template, send_file
from flask_cors import CORS
from dotenv import load_dotenv
import google.generativeai as genai
import PIL.Image
import PIL.ImageEnhance
import re
from html import unescape

# --- ì„¤ì • ë° ì´ˆê¸°í™” ---
load_dotenv()
@@ -222,32 +222,46 @@ def load_law_texts() -> str:
"""

# 2. ë””ìì¸ ê²€ì¦ìš© (ì •ë‹µì§€ vs ë””ìì¸PDF)
# server.py ìˆ˜ì •ë³¸

PROMPT_VERIFY_DESIGN = """
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ [ì‹í’ˆí‘œì‹œì‚¬í•­ ì •ë°€ ê°ì‚¬ AI]ì´ì ê°ì • ì—†ëŠ” [ìë™ ì±„ì ê¸°]ì…ë‹ˆë‹¤.
ì œê³µëœ [Standard(ê¸°ì¤€ì„œ)]ì™€ [Design(ë””ìì¸)]ì„ 1:1 ì •ë°€ ëŒ€ì¡°í•˜ì—¬, ì•„ë˜ ê·œì¹™ì— ë”°ë¼ ëƒ‰ì² í•˜ê²Œ ì±„ì í•˜ì„¸ìš”.
ì œê³µëœ [Standard(ê¸°ì¤€ì„œ)]ì™€ [Design(ë””ìì¸ ì´ë¯¸ì§€ - ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ë§Œ í¬ë¡­ë¨)]ì„ 1:1 ì •ë°€ ëŒ€ì¡°í•˜ì—¬, ì•„ë˜ ê·œì¹™ì— ë”°ë¼ ëƒ‰ì² í•˜ê²Œ ì±„ì í•˜ì„¸ìš”.

**ì¤‘ìš”**: Design ì´ë¯¸ì§€ëŠ” ì´ë¯¸ ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ë§Œ í¬ë¡­ë˜ì–´ ì œê³µë©ë‹ˆë‹¤. 
ë¸Œëœë“œ ë¡œê³ , ì œí’ˆ ì‚¬ì§„, ì¡°ë¦¬ë²• ë“±ì€ ì´ë¯¸ ì œê±°ë˜ì—ˆìœ¼ë¯€ë¡œ, ì‹í’ˆí‘œì‹œì‚¬í•­ í…ìŠ¤íŠ¸ì—ë§Œ ì§‘ì¤‘í•˜ì„¸ìš”.

[ê°ì  ê¸°ì¤€í‘œ (ì´ì  100ì ì—ì„œ ì‹œì‘)]
ê¸°ë³¸ 100ì ì—ì„œ ì•„ë˜ ì˜¤ë¥˜ê°€ ë°œê²¬ë  ë•Œë§ˆë‹¤ ì ìˆ˜ë¥¼ ì°¨ê°í•˜ì„¸ìš”. (ìµœí•˜ 0ì )

1. **ì›ì¬ë£Œëª… ì˜¤ë¥˜ (-3ì /ê±´)**:
1. **ì›ì¬ë£Œëª… ì˜¤ë¥˜ (-5ì /ê±´)**:
  - Standard(ì—‘ì…€)ì— ìˆëŠ” ì›ì¬ë£Œê°€ Design(ì´ë¯¸ì§€)ì— ì—†ê±°ë‚˜ ìˆœì„œê°€ ë‹¤ë¦„.
  - í•¨ëŸ‰(%) ìˆ«ìê°€ 0.1%ë¼ë„ ë‹¤ë¦„. (ì˜ˆ: 70.6% vs 70.5%)
2. **ì˜ì–‘ì„±ë¶„ ì˜¤ë¥˜ (-3ì /ê±´)**:
2. **ì˜ì–‘ì„±ë¶„ ì˜¤ë¥˜ (-5ì /ê±´)**:
  - ë‚˜íŠ¸ë¥¨, íƒ„ìˆ˜í™”ë¬¼, ë‹¹ë¥˜ ë“±ì˜ ìˆ˜ì¹˜ ë˜ëŠ” ë‹¨ìœ„(g, mg) ë¶ˆì¼ì¹˜.
  - ë¹„ìœ¨(%) ìˆ«ìê°€ ë‹¤ë¦„.
3. **ë²•ì  ì˜ë¬´ ë¬¸êµ¬ ëˆ„ë½ (-5ì /ê±´)**:
3. **ë²•ì  ì˜ë¬´ ë¬¸êµ¬ ëˆ„ë½ (-10ì /ê±´)**:
  - "ì†Œë¹„ê¸°í•œ" (ìœ í†µê¸°í•œ ì•„ë‹˜) í‘œê¸° ì—¬ë¶€.
  - "ë¶€ì • ë¶ˆëŸ‰ì‹í’ˆ ì‹ ê³ ëŠ” êµ­ë²ˆì—†ì´ 1399" í‘œê¸° ì—¬ë¶€.
  - ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ ë³„ë„ í‘œì‹œë€ ìœ ë¬´.
  - í¬ì¥ì¬ì§ˆ ë° ë¶„ë¦¬ë°°ì¶œ ë§ˆí¬ ìœ ë¬´.
4. **ë‹¨ìˆœ ì˜¤íƒ€ (-1ì /ê±´)**:
   - ë„ì–´ì“°ê¸°, ê´„í˜¸ ìœ„ì¹˜ ë“± ê²½ë¯¸í•œ ì°¨ì´.
4. **ë¹„í˜„ì‹¤ì  ìˆ˜ì¹˜ ì˜¤ë¥˜ (-5ì /ê±´)**:
   - í•¨ëŸ‰ì´ 100%ë¥¼ ì´ˆê³¼í•˜ëŠ” ê²½ìš° (ì˜ˆ: "221%", "150%")
   - ë¹„í˜„ì‹¤ì ìœ¼ë¡œ í° ìˆ˜ì¹˜ (ì˜ˆ: "ë‚˜íŠ¸ë¥¨ 50000mg")
   - ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜ (ì˜ˆ: "13ì›”", "32ì¼")
5. **ë””ìì¸/í‘œê¸° ì˜¤íƒˆì (-3ì /ê±´)**:
   - ëª…ë°±í•œ ì² ì ì˜¤ë¥˜ (ì˜ˆ: "ì œì¡°ë²™ë²•" â†’ "ì œì¡°ë°©ë²•")
   - ë‹¨ìœ„ í‘œê¸° ì˜¤ë¥˜ (ì˜ˆ: "10Kg" â†’ "10 kg", ë‹¨ìœ„ ëˆ„ë½)
   - ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ê³µë°± (ì˜ˆ: "ë³´ê´€ë°© ë²•" â†’ "ë³´ê´€ë°©ë²•")
6. **ë‹¨ìˆœ ì˜¤íƒ€ (-2ì /ê±´)**:
   - ê´„í˜¸ ìœ„ì¹˜ ë“± ê²½ë¯¸í•œ ì°¨ì´.

[ë¶„ì„ í”„ë¡œì„¸ìŠ¤ - ë‹¨ê³„ë³„ ìˆ˜í–‰]

1. **êµ¬ì¡°í™” (Structuring)**:
  - Standard ë°ì´í„°(ì—‘ì…€)ë¥¼ [ì œí’ˆëª…, ì‹í’ˆìœ í˜•, ë‚´ìš©ëŸ‰, ì›ì¬ë£Œëª…, ì˜ì–‘ì •ë³´, ë³´ê´€ë°©ë²•, í¬ì¥ì¬ì§ˆ, í’ˆëª©ë³´ê³ ë²ˆí˜¸] í•­ëª©ë³„ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
   - Design ì´ë¯¸ì§€(OCR)ì—ì„œë„ ë™ì¼í•œ í•­ëª©ë“¤ì„ ì°¾ì•„ë‚´ì–´ 1:1 ë§¤ì¹­ ì¤€ë¹„ë¥¼ í•˜ì„¸ìš”.
   - Design ì´ë¯¸ì§€ëŠ” ì´ë¯¸ ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ë§Œ í¬ë¡­ë˜ì–´ ì œê³µë˜ë¯€ë¡œ, ì´ ì˜ì—­ì˜ í…ìŠ¤íŠ¸ë§Œ OCRí•˜ì—¬ ë™ì¼í•œ í•­ëª©ë“¤ì„ ì°¾ì•„ë‚´ì–´ 1:1 ë§¤ì¹­ ì¤€ë¹„ë¥¼ í•˜ì„¸ìš”.
   - **ë¬´ì‹œí•  ê²ƒ**: ë¸Œëœë“œ ë¡œê³ , ì œí’ˆ ì‚¬ì§„, ì¡°ë¦¬ë²•, í™ë³´ ë¬¸êµ¬ëŠ” ì´ë¯¸ ì œê±°ë˜ì—ˆìœ¼ë¯€ë¡œ ì‹ ê²½ì“°ì§€ ë§ˆì„¸ìš”.

2. **ì •ë°€ ëŒ€ì¡° (Cross-Checking)**:
  - **(1) ì›ì¬ë£Œëª… ê²€ì¦ (ê°€ì¥ ì¤‘ìš”)**: 
@@ -257,34 +271,107 @@ def load_law_texts() -> str:
    ë‚˜íŠ¸ë¥¨, íƒ„ìˆ˜í™”ë¬¼, ë‹¹ë¥˜ ë“± ëª¨ë“  ìˆ˜ì¹˜ì™€ ë‹¨ìœ„(g, mg, %)ê°€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
  - **(3) ë²•ì  ì˜ë¬´ì‚¬í•­ ê²€ì¦**: 
    ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ í‘œì‹œ, "ì†Œë¹„ê¸°í•œ" ë¬¸êµ¬, ë¶„ë¦¬ë°°ì¶œ ë§ˆí¬ ë“±ì´ ë²•ê·œëŒ€ë¡œ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

3. **í•€ì…‹ ì˜¤ë¥˜ ì§€ì  (Pinpoint Reporting)**:
     **ì¤‘ìš”**: ë²•ë¥  ìœ„ë°˜ ì‚¬í•­ì„ ë°œê²¬í•˜ë©´ ë°˜ë“œì‹œ ê´€ë ¨ ë²•ë ¹ ì¡°í•­ì„ ëª…ì‹œí•˜ì„¸ìš”.
     ì˜ˆ: "ì‹í’ˆë“±ì˜ í‘œì‹œÂ·ê´‘ê³ ì— ê´€í•œ ë²•ë¥  ì œ5ì¡° ì œ1í•­", "ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ ì œ3ì¡° ì œ2í•­" ë“±

3. **Step 3: Verdict (íŒë‹¨) - 3ê°€ì§€ ì˜¤ë¥˜ ìœ í˜• ëª¨ë‘ ì ê·¹ ê°ì§€**:
   
   **3-1. ë²•ë ¹ ìœ„ë°˜ ê°ì§€ (Legal Compliance)**
   - ë²•ë ¹ì— ëª…ì‹œëœ í•„ìˆ˜ í‘œê¸°ì‚¬í•­ ëˆ„ë½ ë° ìœ„ë°˜ ì—¬ë¶€ë¥¼ ì² ì €íˆ ê²€ì¦í•˜ì„¸ìš”.
   - ê´€ë ¨ ë²•ë ¹ ì¡°í•­ì„ ë°˜ë“œì‹œ ëª…ì‹œí•˜ì„¸ìš”.
   - **ë²•ë ¹ ìœ„ë°˜ ë³´ê³  í˜•ì‹**: "ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ [ë³„ì§€1] 1.ë°”.1)ê°€) ì›ì¬ë£Œëª…ì€ ë§ì´ ì‚¬ìš©í•œ ìˆœì„œì— ë”°ë¼ í‘œì‹œí•´ì•¼ í•˜ë©°, ì¤‘ë³µ í‘œê¸°ëŠ” ì •í™•ì„±ì„ ì €í•´í•©ë‹ˆë‹¤." í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
   - ë²•ë ¹ ì¡°í•­ ë²ˆí˜¸ì™€ ìœ„ë°˜ ë‚´ìš©ì„ í•¨ê»˜ í¬í•¨í•œ ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
   
   **3-2. ë¹„í˜„ì‹¤ì  ìˆ˜ì¹˜ ë° ë…¼ë¦¬ ì˜¤ë¥˜ ê°ì§€ (Logical Error) - ì ê·¹ ë³´ê³ **
   - **í•¨ëŸ‰ ì˜¤ë¥˜**: ì›ì¬ë£Œ í•¨ëŸ‰ì´ 100%ë¥¼ ì´ˆê³¼í•˜ê±°ë‚˜ ë¹„í˜„ì‹¤ì ì¸ ìˆ˜ì¹˜ì¸ ê²½ìš°ë¥¼ **ë°˜ë“œì‹œ** ì°¾ìœ¼ì„¸ìš”.
     * ì˜ˆ: "ì–´ë¬µ 221%" â†’ "2.21%" ë˜ëŠ” "22.1%"ì˜ ì˜¤íƒ€ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ â†’ 'violation' ë˜ëŠ” 'typo'ë¡œ ë³´ê³ 
     * ì˜ˆ: "ë‚˜íŠ¸ë¥¨ 50000mg" â†’ ë‹¨ìœ„ ì˜¤íƒ€ ë˜ëŠ” ì†Œìˆ˜ì  ëˆ„ë½ ê°€ëŠ¥ì„± â†’ 'typo'ë¡œ ë³´ê³ 
   - **ë‚ ì§œ ì˜¤ë¥˜**: ìœ í†µê¸°í•œì´ë‚˜ ì œì¡°ì¼ìê°€ ì¡´ì¬í•  ìˆ˜ ì—†ëŠ” ë‚ ì§œ(ì˜ˆ: 13ì›”, 32ì¼)ì´ê±°ë‚˜ í˜•ì‹ì´ ì˜ëª»ëœ ê²½ìš°ë¥¼ ì°¾ìœ¼ì„¸ìš”.
   - **ë…¼ë¦¬ì  ëª¨ìˆœ**: ì˜ì–‘ì •ë³´ ê³„ì‚°ì´ ë§ì§€ ì•Šê±°ë‚˜, í•¨ëŸ‰ í•©ê³„ê°€ ë¹„ì •ìƒì ì¸ ê²½ìš°ë¥¼ ì°¾ìœ¼ì„¸ìš”.
   
   **3-3. ë””ìì¸/í‘œê¸° ì˜¤íƒˆì ê°ì§€ (Design & Spelling Error) - ì ê·¹ ë³´ê³ **
   - **ëª…ë°±í•œ ì² ì ì˜¤ë¥˜**: ë¬¸ë§¥ìƒ ëª…í™•í•œ ë‹¨ì–´ì˜ ì˜¤íƒ€ë¥¼ **ë°˜ë“œì‹œ** ìˆ˜ì • ì œì•ˆí•˜ì„¸ìš”.
     * ì˜ˆ: "ì œì¡°ë²™ë²•" â†’ "ì œì¡°ë°©ë²•" (ëª…ë°±í•œ ì˜¤íƒ€)
     * ì˜ˆ: "ë³´ê´€ë°© ë²•" â†’ "ë³´ê´€ë°©ë²•" (ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ê³µë°±)
     * ì˜ˆ: "ìœ í†µê¸°í•œã„´" â†’ "ìœ í†µê¸°í•œ" (ì¤‘ë³µ ë¬¸ì)
     * ì˜ˆ: "ì„­ì·¨í•˜ì‹­ì‹œìš”" â†’ "ì„­ì·¨í•˜ì‹­ì‹œì˜¤" (í‘œì¤€ì–´ ê·œì • ìœ„ë°˜)
   - **ë‹¨ìœ„ í‘œê¸° ì˜¤ë¥˜**: ë²•ì • ê³„ëŸ‰ ë‹¨ìœ„ë‚˜ í‘œì¤€ í‘œê¸°ë²•ê³¼ ë‹¤ë¥¸ ê²½ìš°ë¥¼ ì°¾ìœ¼ì„¸ìš”.
     * ì˜ˆ: "10Kg" â†’ "10 kg" (ë„ì–´ì“°ê¸° ë° ì†Œë¬¸ì ê¶Œì¥)
     * ì˜ˆ: "ë‚˜íŠ¸ë¥¨ 530" â†’ "ë‚˜íŠ¸ë¥¨ 530 mg" (ë‹¨ìœ„ ëˆ„ë½)
   - **ì¼ê´€ì„± ê²€ì¦**: ê°™ì€ ì´ë¯¸ì§€ ë‚´ì—ì„œ ë™ì¼í•œ ë‹¨ì–´ê°€ ë‹¤ë¥´ê²Œ í‘œê¸°ëœ ê²½ìš°ë¥¼ ì°¾ìœ¼ì„¸ìš”.
     * ì˜ˆ: í•œ ê³³ì—ì„œëŠ” "ëƒ‰ì¥ë³´ê´€", ë‹¤ë¥¸ ê³³ì—ì„œëŠ” "ëƒ‰ì¥ ë³´ê´€"ìœ¼ë¡œ í‘œê¸°ëœ ê²½ìš°

4. **í•€ì…‹ ì˜¤ë¥˜ ì§€ì  (Pinpoint Reporting)**:
  - "ì›ì¬ë£Œëª…ì´ ë‹¤ë¦…ë‹ˆë‹¤" ê°™ì´ ë­‰ëš±ê·¸ë¦¬ì§€ ë§ˆì„¸ìš”.
  - **ì˜¤ë¥˜ê°€ ìˆëŠ” 'ë‹¨ì–´' ë˜ëŠ” 'ìˆ«ì'ë§Œ ì •í™•íˆ ì˜ë¼ë‚´ì–´ `actual` í•„ë“œì— ë„£ìœ¼ì„¸ìš”.**
  - ì˜ˆ: "L-ê¸€ë£¨íƒì‚°ë‚˜íŠ¸ë¥¨"ì´ ë¹ ì¡Œë‹¤ë©´, ê·¸ ìœ„ì¹˜ ì£¼ë³€ í…ìŠ¤íŠ¸ë¥¼ `actual`ë¡œ ì¡ì•„ í•˜ì´ë¼ì´íŠ¸ í•˜ì„¸ìš”.

[ë²•ë ¹ ìœ„ë°˜ ë³´ê³  í˜•ì‹]

**ë²•ë ¹ ìœ„ë°˜ ì‚¬í•­ì„ ë³´ê³ í•  ë•ŒëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¥´ì„¸ìš”:**
- ê´€ë ¨ ë²•ë ¹ ì¡°í•­ì„ ë¨¼ì € ëª…ì‹œí•˜ì„¸ìš”.
- ì˜ˆ: "ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ [ë³„ì§€1] 1.ë°”.1)ê°€) ì›ì¬ë£Œëª…ì€ ë§ì´ ì‚¬ìš©í•œ ìˆœì„œì— ë”°ë¼ í‘œì‹œí•´ì•¼ í•˜ë©°, ì¤‘ë³µ í‘œê¸°ëŠ” ì •í™•ì„±ì„ ì €í•´í•©ë‹ˆë‹¤."
- ì˜ˆ: "ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ [ë³„ì§€1] 1.ì•„.1)ê°€) ë° 1.ì•„.2)ê°€)(5)(ê°€) ì˜ì–‘ì„±ë¶„ í•¨ëŸ‰ì€ ì´ë‚´ìš©ëŸ‰ ë˜ëŠ” 100g(ml)ë‹¹ìœ¼ë¡œ ì •í™•íˆ í‘œì‹œë˜ì–´ì•¼ í•˜ë©°, ë‹¨ìœ„ ë° ìˆ˜ì¹˜ ì˜¤ë¥˜ëŠ” í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
- ì˜ˆ: "ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ [ë„2] í‘œì‹œì‚¬í•­í‘œì‹œì„œì‹ë„ì•ˆì— ë”°ë¼ ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆì€ ë³„ë„ì˜ í‘œì‹œë€ìœ¼ë¡œ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ í‘œê¸°í•´ì•¼ í•©ë‹ˆë‹¤."

**violations ë°°ì—´ í˜•ì‹:**
ê° ìœ„ë°˜ ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì¡°í™”í•˜ì„¸ìš”:
{
  "violation": "ìœ„ë°˜ ë‚´ìš© ì„¤ëª… (ë²•ë ¹ ì¡°í•­ í¬í•¨)",
  "law_reference": "ê´€ë ¨ ë²•ë ¹ ì¡°í•­ (ì˜ˆ: ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ [ë³„ì§€1] 1.ë°”.1)ê°€))"
}

[ì˜¤íƒˆì(Typo) ë³´ê³  ê·œì¹™ - ì ê·¹ì  ê°ì§€]

**ë³´ê³  ëŒ€ìƒ (ì ê·¹ì  ë³´ê³  - ë°˜ë“œì‹œ ì¡ì•„ë‚´ì„¸ìš”):**
- "ì œì¡°ë²™ë²•", "ë‚´ìš©ëƒ¥", "ìœ í†µê¸°í•œã„´" ê°™ì€ ëª…ë°±í•œ ì² ì ì˜¤ë¥˜
- "ì–´ë¬µ 221%", "ë‚˜íŠ¸ë¥¨ 50000mg" ê°™ì€ ë¹„í˜„ì‹¤ì ì¸ ìˆ˜ì¹˜ ì˜¤ë¥˜ (ë‹¨ìœ„ ë˜ëŠ” ì†Œìˆ˜ì  ì˜¤íƒ€ ìœ ë ¥)
- "ë³´ê´€ë°© ë²•"ê³¼ ê°™ì´ ë‹¨ì–´ ì¤‘ê°„ì˜ ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ê³µë°±
- ë¬¸ë§¥ìƒ ì˜¤íƒ€ê°€ í™•ì‹¤í•œ ê²½ìš° (ì˜ˆ: "ì„­ì·¨í•˜ì‹­ì‹œì˜¤" â†’ "ì„­ì·¨í•˜ì‹­ì‹œìš”" ë“± í‘œì¤€ì–´ ê·œì • ìœ„ë°˜ í¬í•¨)
- í•¨ëŸ‰ì´ 100%ë¥¼ ì´ˆê³¼í•˜ëŠ” ê²½ìš° (ì˜ˆ: "221%", "150%")
- ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜ (ì˜ˆ: "13ì›”", "32ì¼", "2024-13-01")

**ë³´ê³  ì œì™¸ ëŒ€ìƒ (ì‹ ì¤‘í•˜ê²Œ íŒë‹¨):**
- "ì¹´ ìì „ë¶„" ê°™ì´ ì „ë¬¸ì ì¸ ì›ì¬ë£Œëª…ì˜ ë„ì–´ì“°ê¸°ëŠ” ì‹ ì¤‘í•˜ê²Œ íŒë‹¨ (í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ ì œì™¸)
- ë””ìì¸ì  ìš”ì†Œë¡œ ì¸í•´ ì˜ë„ì ìœ¼ë¡œ ì¤„ë°”ê¿ˆëœ ê²½ìš°

[ì¶œë ¥ ì–‘ì‹ - JSON Only]
- Markdown í¬ë§· ì—†ì´ ì˜¤ì§ JSON ë°ì´í„°ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
{
 "design_ocr_text": "ë””ìì¸ ì „ì²´ í…ìŠ¤íŠ¸...",
 "score": (100ì ì—ì„œ ì°¨ê°ëœ ìµœì¢… ì ìˆ˜),
 "law_compliance": {
   "status": "compliant" | "violation",
    "violations": ["ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ ì œXì¡° ìœ„ë°˜..."]
    "violations": [
      {
        "violation": "ìœ„ë°˜ ë‚´ìš© ìƒì„¸ ì„¤ëª… (ë²•ë ¹ ì¡°í•­ ë²ˆí˜¸ì™€ ìœ„ë°˜ ë‚´ìš©ì„ í•¨ê»˜ í¬í•¨í•œ ì „ì²´ ë¬¸ì¥, ì˜ˆ: 'ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ [ë³„ì§€1] 1.ë°”.1)ê°€) ì›ì¬ë£Œëª…ì€ ë§ì´ ì‚¬ìš©í•œ ìˆœì„œì— ë”°ë¼ í‘œì‹œí•´ì•¼ í•˜ë©°, ì¤‘ë³µ í‘œê¸°ëŠ” ì •í™•ì„±ì„ ì €í•´í•©ë‹ˆë‹¤.')",
        "law_reference": "ê´€ë ¨ ë²•ë ¹ ì¡°í•­ ë²ˆí˜¸ë§Œ (ì˜ˆ: 'ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ [ë³„ì§€1] 1.ë°”.1)ê°€)', 'ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ [ë³„ì§€1] 1.ì•„.1)ê°€) ë° 1.ì•„.2)ê°€)(5)(ê°€)' ë“±)"
      }
    ]
 },
  
  **ì¤‘ìš”**: 
  - violations ë°°ì—´ì´ ë¹„ì–´ìˆê±°ë‚˜ statusê°€ "compliant"ì´ë©´ ë²•ë ¹ ìœ„ë°˜ì´ ì—†ëŠ” ê²ƒì…ë‹ˆë‹¤.
  - violation í•„ë“œì—ëŠ” ë²•ë ¹ ì¡°í•­ê³¼ ìœ„ë°˜ ë‚´ìš©ì„ í•¨ê»˜ í¬í•¨í•œ ì „ì²´ ë¬¸ì¥ì„ ì‘ì„±í•˜ì„¸ìš”.
  - ì˜ˆ: "ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ [ë³„ì§€1] 1.ë°”.1)ê°€) ì›ì¬ë£Œëª…ì€ ë§ì´ ì‚¬ìš©í•œ ìˆœì„œì— ë”°ë¼ í‘œì‹œí•´ì•¼ í•˜ë©°, ì¤‘ë³µ í‘œê¸°ëŠ” ì •í™•ì„±ì„ ì €í•´í•©ë‹ˆë‹¤."
 "issues": [
   {
      "type": "Critical" (ë‚´ìš© ë¶ˆì¼ì¹˜) | "Minor" (ë‹¨ìˆœ ì˜¤íƒ€) | "Law_Violation",
      "type": "Critical" (ë‚´ìš© ë¶ˆì¼ì¹˜) | "Minor" (ë‹¨ìˆœ ì˜¤íƒ€) | "Law_Violation" (ë²•ë¥  ìœ„ë°˜) | "Logical_Error" (ë¹„í˜„ì‹¤ì  ìˆ˜ì¹˜/ë…¼ë¦¬ ì˜¤ë¥˜) | "Spelling_Error" (ëª…ë°±í•œ ì² ì ì˜¤ë¥˜),
     "location": "í•­ëª©ëª… (ì˜ˆ: ì˜ì–‘ì •ë³´)",
     "issue": "ì˜¤ë¥˜ ìƒì„¸ ì„¤ëª…",
     "expected": "ê¸°ì¤€ì„œ ë°ì´í„°",
     "actual": "ë””ìì¸ì—ì„œ ë°œê²¬ëœ í‹€ë¦° í…ìŠ¤íŠ¸ (í•˜ì´ë¼ì´íŠ¸ìš©)",
      "suggestion": "ìˆ˜ì • ì œì•ˆ"
      "suggestion": "ìˆ˜ì • ì œì•ˆ",
      "law_reference": "ê´€ë ¨ ë²•ë ¹ ì¡°í•­ (ì˜ˆ: ì‹í’ˆë“±ì˜ í‘œì‹œÂ·ê´‘ê³ ì— ê´€í•œ ë²•ë¥  ì œ5ì¡°, ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ ì œ3ì¡° ì œ1í•­ ë“±) - ë²•ë¥  ìœ„ë°˜ì¸ ê²½ìš° í•„ìˆ˜"
   }
 ]
}
"""





# --- íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ---

def process_file_to_part(file_storage):
@@ -303,10 +390,198 @@ def process_file_to_part(file_storage):
print(f"ì—‘ì…€ ë³€í™˜ ì‹¤íŒ¨: {e}")
return None

    # ì´ë¯¸ì§€ë‚˜ PDFëŠ” ê·¸ëŒ€ë¡œ ì „ë‹¬
    # GeminiëŠ” image/jpeg, image/png, application/pdf ë“±ì„ ì§€ì›í•¨
    # [NEW] ì´ë¯¸ì§€ íŒŒì¼ì¸ ê²½ìš°: ì„ ëª…ë„ ë³´ì • (OCR ì •í™•ë„ UP)
    if mime_type.startswith('image/'):
        try:
            img = PIL.Image.open(io.BytesIO(file_data))

            # 1. í‘ë°± ë³€í™˜ (ê¸€ì ìœ¤ê³½ ê°•ì¡°)
            img = img.convert('L')

            # 2. ëŒ€ë¹„(Contrast) 2ë°° ì¦ê°€
            enhancer = PIL.ImageEnhance.Contrast(img)
            img = enhancer.enhance(2.0)

            # 3. ì„ ëª…ë„(Sharpness) 1.5ë°° ì¦ê°€
            enhancer = PIL.ImageEnhance.Sharpness(img)
            img = enhancer.enhance(1.5)

            # ë³´ì •ëœ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ë°”ì´íŠ¸ë¡œ ë³€í™˜
            byte_io = io.BytesIO()
            # ì›ë³¸ í¬ë§· ìœ ì§€í•˜ë˜, ì—†ìœ¼ë©´ JPEG ì‚¬ìš©
            fmt = img.format if img.format else 'JPEG'
            img.save(byte_io, format=fmt)
            byte_io.seek(0)

            return {"mime_type": mime_type, "data": byte_io.read()}

        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ë³´ì • ì‹¤íŒ¨ (ì›ë³¸ ì‚¬ìš©): {e}")
            # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            return {"mime_type": mime_type, "data": file_data}

    # PDF ë“± ê¸°íƒ€ íŒŒì¼ì€ ê·¸ëŒ€ë¡œ ì „ë‹¬
return {"mime_type": mime_type, "data": file_data}


def clean_html_text(text):
    """HTML íƒœê·¸ì™€ HTML ì½”ë“œë¥¼ ì™„ì „íˆ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ ë‚´ìš©(ë²•ë ¹ ë¬¸êµ¬ í¬í•¨)ë§Œ ìœ ì§€"""
    if not isinstance(text, str):
        return text
    
    # HTML ì—”í‹°í‹° ë””ì½”ë”© ë¨¼ì € ìˆ˜í–‰ (ì˜ˆ: &lt; â†’ <, &gt; â†’ >, &amp; â†’ &)
    text = unescape(text)
    
    # HTML íƒœê·¸ ì™„ì „íˆ ì œê±° (ë‚´ìš©ì€ ìœ ì§€)
    # ì˜ˆ: "<div>ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ ì œXì¡° ìœ„ë°˜</div>" â†’ "ì‹í’ˆë“±ì˜ í‘œì‹œê¸°ì¤€ ì œXì¡° ìœ„ë°˜"
    text = re.sub(r'<[^>]+>', '', text)
    
    # HTML ì½”ë“œ íŒ¨í„´ ì œê±° (ì˜ˆ: "<div style=...>", "<ul style=...>" ë“±)
    text = re.sub(r'<div[^>]*>', '', text, flags=re.IGNORECASE)
    text = re.sub(r'</div>', '', text, flags=re.IGNORECASE)
    text = re.sub(r'<ul[^>]*>', '', text, flags=re.IGNORECASE)
    text = re.sub(r'</ul>', '', text, flags=re.IGNORECASE)
    text = re.sub(r'<li[^>]*>', '', text, flags=re.IGNORECASE)
    text = re.sub(r'</li>', '', text, flags=re.IGNORECASE)
    text = re.sub(r'<[^>]+>', '', text)  # ë‚¨ì€ ëª¨ë“  HTML íƒœê·¸ ì œê±°
    
    # ì—°ì†ëœ ê³µë°±ë§Œ ì •ë¦¬ (ì¤„ë°”ê¿ˆê³¼ ë‚´ìš©ì€ ë³´ì¡´)
    text = re.sub(r'[ \t]+', ' ', text)  # íƒ­ê³¼ ê³µë°±ë§Œ ì •ë¦¬
    text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)  # 3ê°œ ì´ìƒì˜ ì—°ì† ì¤„ë°”ê¿ˆë§Œ 2ê°œë¡œ
    
    return text.strip()

def detect_label_area(image_file):
    """ì´ë¯¸ì§€ì—ì„œ ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  í¬ë¡­"""
    try:
        image_data = image_file.read()
        image_file.seek(0)
        
        img_pil = PIL.Image.open(io.BytesIO(image_data))
        original_size = img_pil.size
        
        # AIì—ê²Œ ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ ì°¾ê¸° ìš”ì²­
        model = genai.GenerativeModel(MODEL_NAME)
        
        detection_prompt = """
ì´ ì´ë¯¸ì§€ëŠ” ì‹í’ˆ í¬ì¥ì§€ ë””ìì¸ì…ë‹ˆë‹¤.
ì´ë¯¸ì§€ì—ì„œ **ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­**ë§Œ ì°¾ì•„ì£¼ì„¸ìš”.

ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ì€ ë‹¤ìŒ ì •ë³´ê°€ í¬í•¨ëœ ì‚¬ê°í˜• ì˜ì—­ì…ë‹ˆë‹¤:
- ì œí’ˆëª…, ì‹í’ˆìœ í˜•, ë‚´ìš©ëŸ‰
- ì›ì¬ë£Œëª…
- ì˜ì–‘ì •ë³´
- ì•Œë ˆë¥´ê¸° ì •ë³´
- ì œì¡°ì› ì •ë³´
- ì£¼ì˜ì‚¬í•­

**ë¬´ì‹œí•  ì˜ì—­:**
- ë¸Œëœë“œ ë¡œê³ 
- ì œí’ˆ ì‚¬ì§„
- ì¡°ë¦¬ë²•/ë ˆì‹œí”¼
- í™ë³´ ë¬¸êµ¬
- ì¥ì‹ ìš”ì†Œ

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{
    "found": true/false,
    "bbox": {
        "x1": ì™¼ìª½ ìƒë‹¨ X ì¢Œí‘œ (í”½ì…€),
        "y1": ì™¼ìª½ ìƒë‹¨ Y ì¢Œí‘œ (í”½ì…€),
        "x2": ì˜¤ë¥¸ìª½ í•˜ë‹¨ X ì¢Œí‘œ (í”½ì…€),
        "y2": ì˜¤ë¥¸ìª½ í•˜ë‹¨ Y ì¢Œí‘œ (í”½ì…€)
    },
    "description": "ì°¾ì€ ì˜ì—­ ì„¤ëª…"
}

ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ "found": falseë¡œ ì‘ë‹µí•˜ì„¸ìš”.
"""
        
        response = model.generate_content([detection_prompt, img_pil])
        result_text = response.text.strip()
        
        # JSON íŒŒì‹±
        if result_text.startswith("```json"):
            result_text = result_text[7:-3]
        elif result_text.startswith("```"):
            lines = result_text.split("\n")
            if lines[0].startswith("```"):
                result_text = "\n".join(lines[1:-1])
        
        detection_result = json.loads(result_text)
        
        if detection_result.get("found", False) and "bbox" in detection_result:
            bbox = detection_result["bbox"]
            x1 = max(0, int(bbox.get("x1", 0)))
            y1 = max(0, int(bbox.get("y1", 0)))
            x2 = min(original_size[0], int(bbox.get("x2", original_size[0])))
            y2 = min(original_size[1], int(bbox.get("y2", original_size[1])))
            
            # ì˜ì—­ í¬ë¡­
            cropped_img = img_pil.crop((x1, y1, x2, y2))
            print(f"âœ… ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ ê°ì§€: ({x1}, {y1}) ~ ({x2}, {y2}), í¬ê¸°: {cropped_img.size}")
            
            # í¬ë¡­ëœ ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
            output = io.BytesIO()
            cropped_img.save(output, format='PNG')
            output.seek(0)
            
            return output, True
        else:
            print("âš ï¸ ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì „ì²´ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            image_file.seek(0)
            return image_file, False
            
    except Exception as e:
        print(f"âŒ ì˜ì—­ ê°ì§€ ì‹¤íŒ¨: {e}, ì „ì²´ ì´ë¯¸ì§€ ì‚¬ìš©")
        image_file.seek(0)
        return image_file, False

def clean_ai_response(data):
    """AI ì‘ë‹µì—ì„œ HTML íƒœê·¸ë¥¼ ì œê±°í•˜ê³  ì •ë¦¬"""
    if isinstance(data, dict):
        cleaned = {}
        for key, value in data.items():
            if key == 'violations' and isinstance(value, list):
                # violations ë°°ì—´ì˜ ê° í•­ëª©ì—ì„œ HTML ì œê±°
                cleaned_violations = []
                for item in value:
                    if isinstance(item, dict):
                        # ê°ì²´ì¸ ê²½ìš°
                        cleaned_item = {}
                        for k, v in item.items():
                            if isinstance(v, str):
                                cleaned_item[k] = clean_html_text(v)
                            else:
                                cleaned_item[k] = v
                        cleaned_violations.append(cleaned_item)
                    else:
                        # ë¬¸ìì—´ì¸ ê²½ìš°
                        cleaned_violations.append(clean_html_text(item))
                cleaned[key] = cleaned_violations
            elif key == 'issues' and isinstance(value, list):
                # issues ë°°ì—´ì˜ ê° í•­ëª© ì²˜ë¦¬
                cleaned[key] = []
                for item in value:
                    if isinstance(item, dict):
                        cleaned_item = {}
                        for k, v in item.items():
                            cleaned_item[k] = clean_html_text(v) if isinstance(v, str) else v
                        cleaned[key].append(cleaned_item)
                    else:
                        cleaned[key].append(clean_html_text(item) if isinstance(item, str) else item)
            elif isinstance(value, str):
                cleaned[key] = clean_html_text(value)
            elif isinstance(value, (dict, list)):
                cleaned[key] = clean_ai_response(value)
            else:
                cleaned[key] = value
        return cleaned
    elif isinstance(data, list):
        return [clean_ai_response(item) for item in data]
    else:
        return clean_html_text(data) if isinstance(data, str) else data

def extract_ingredient_info_from_image(image_file):
"""ì›ì¬ë£Œ í‘œì‹œì‚¬í•­ ì´ë¯¸ì§€ì—ì„œ í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ"""
try:
@@ -382,7 +657,7 @@ def create_standard_excel(data):
})
if allergens_data:
allergens_df = pd.DataFrame(allergens_data)
                allergens_df.to_excel(writer, sheet_name='ì•Œë ˆë¥´ë¦¬ì •ë³´', index=False)
                allergens_df.to_excel(writer, sheet_name='ì•Œë ˆë¥´ê¸°ì •ë³´', index=False)

# 4. ì˜ì–‘ì •ë³´ ì‹œíŠ¸
if 'nutrition_info' in data and 'per_100g' in data['nutrition_info']:
@@ -423,75 +698,13 @@ def create_standard_excel(data):
output.seek(0)
return output

# ğŸ”´ í•˜ì´ë¼ì´íŠ¸ HTML ìƒì„± í—¬í¼ í•¨ìˆ˜ ì¶”ê°€
def make_highlighted_html(design_text: str, issues: list) -> str:
    """
    ë””ìì¸ ì „ì²´ í…ìŠ¤íŠ¸(design_text) ì•ˆì—ì„œ
    issues[*]["actual"] ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ë§Œ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í•˜ì´ë¼ì´íŠ¸í•´ì„œ
    HTML ë¬¸ìì—´ë¡œ ëŒë ¤ì¤€ë‹¤.
    """
    if not design_text:
        return ""

    highlight_ranges = []

    # 1) ê° ì´ìŠˆì˜ actual ë¬¸ìì—´ ìœ„ì¹˜ ì°¾ê¸°
    for issue in issues or []:
        actual = (issue or {}).get("actual")
        if not actual:
            continue

        idx = design_text.find(actual)
        if idx == -1:
            continue  # ëª» ì°¾ìœ¼ë©´ ìŠ¤í‚µ

        highlight_ranges.append((idx, idx + len(actual)))

    if not highlight_ranges:
        # í•˜ì´ë¼ì´íŠ¸í•  ê²Œ ì—†ìœ¼ë©´ ê·¸ëƒ¥ <br> ë§Œ ë°”ê¿”ì„œ ë°˜í™˜
        return design_text.replace("\n", "<br>")

    # 2) ê²¹ì¹˜ëŠ” êµ¬ê°„ ì •ë¦¬
    highlight_ranges.sort()
    merged = []
    cur_start, cur_end = highlight_ranges[0]
    for start, end in highlight_ranges[1:]:
        if start <= cur_end:
            cur_end = max(cur_end, end)
        else:
            merged.append((cur_start, cur_end))
            cur_start, cur_end = start, end
    merged.append((cur_start, cur_end))

    # 3) HTML ì¡°ë¦½
    parts = []
    last_idx = 0
    for start, end in merged:
        # ì¼ë°˜ í…ìŠ¤íŠ¸
        if start > last_idx:
            parts.append(design_text[last_idx:start])
        # í•˜ì´ë¼ì´íŠ¸ í…ìŠ¤íŠ¸
        highlight_text = design_text[start:end]
        parts.append(
            f'<span style="color:#e53935; font-weight:bold;">{highlight_text}</span>'
        )
        last_idx = end

    # ë§ˆì§€ë§‰ ê¼¬ë¦¬ ë¶€ë¶„
    if last_idx < len(design_text):
        parts.append(design_text[last_idx:])

    html = "".join(parts)
    # ì¤„ë°”ê¿ˆì„ <br> ë¡œ ë³€í™˜
    html = html.replace("\n", "<br>")
    # ì „ì²´ ë¸”ë¡ ìŠ¤íƒ€ì¼
    return f'<div style="line-height:1.6; font-size:14px;">{html}</div>'

# --- ë¼ìš°íŠ¸ ---

@app.route('/')
def index():
    return "Food Label API is running"
    return render_template('index.html')


# 1ë‹¨ê³„: ì •ë‹µì§€ ë§Œë“¤ê¸° (ì—‘ì…€ + ì›ì¬ë£Œ ì‚¬ì§„ë“¤ ëª½ë•…)
@app.route('/api/create-standard', methods=['POST'])
@@ -541,7 +754,7 @@ def create_standard():
print(f"ğŸ“‚ ì²˜ë¦¬ ì¤‘: ì—‘ì…€ 1ê°œ + ì›ì¬ë£Œ ì´ë¯¸ì§€ {len(raw_images)}ì¥ (ì •ë³´ ì¶”ì¶œ ì™„ë£Œ)")

try:
        # ì°½ì˜ì„±(Temperature) 0ìœ¼ë¡œ ì„¤ì •í•´ì„œ ë¡œë´‡ì²˜ëŸ¼ ë§Œë“¤ê¸°
        # [ìˆ˜ì •í•  ë¶€ë¶„] ì°½ì˜ì„±(Temperature) 0ìœ¼ë¡œ ì„¤ì •í•´ì„œ ë¡œë´‡ì²˜ëŸ¼ ë§Œë“¤ê¸°
generation_config = {"temperature": 0.0}
model = genai.GenerativeModel(MODEL_NAME, generation_config=generation_config)

@@ -589,6 +802,7 @@ def create_standard():
traceback.print_exc()
return jsonify({"error": str(e)}), 500


# ê¸°ì¤€ ë°ì´í„° ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
@app.route('/api/download-standard-excel', methods=['POST'])
def download_standard_excel():
@@ -614,162 +828,208 @@ def download_standard_excel():
traceback.print_exc()
return jsonify({"error": str(e)}), 500

# ì—‘ì…€ íŒŒì¼ì—ì„œ ê¸°ì¤€ ë°ì´í„° ì½ê¸°
@app.route('/api/read-standard-excel', methods=['POST'])
def read_standard_excel():
    """ì—‘ì…€ íŒŒì¼ì—ì„œ ê¸°ì¤€ ë°ì´í„°ë¥¼ ì½ì–´ì˜´"""
    try:
        excel_file = request.files.get('excel_file')
        if not excel_file:
            return jsonify({"error": "ì—‘ì…€ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        df_dict = pd.read_excel(io.BytesIO(excel_file.read()), sheet_name=None, engine='openpyxl')
        
        # ì—‘ì…€ ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        result = {}
        
        if 'ì œí’ˆì •ë³´' in df_dict:
            product_info = df_dict['ì œí’ˆì •ë³´'].to_dict('records')[0]
            result['product_info'] = product_info
        
        # ì²« ë²ˆì§¸ ì‹œíŠ¸ë¥¼ ìš°ì„  ì‚¬ìš©
        first_sheet_name = list(df_dict.keys())[0]
        first_sheet_df = df_dict[first_sheet_name]
        
        # ì›ì¬ë£Œëª… ì²˜ë¦¬ (ì‹œíŠ¸ ì´ë¦„ì— ê´€ê³„ì—†ì´ ì²« ë²ˆì§¸ ì‹œíŠ¸ ì‚¬ìš©)
        if 'ì›ì¬ë£Œëª…' in df_dict:
            ingredients_list = df_dict['ì›ì¬ë£Œëª…']['ì›ì¬ë£Œëª…'].dropna().tolist()
            result['ingredients'] = {
                'structured_list': ingredients_list,
                'continuous_text': ', '.join(ingredients_list)
            }
        elif 'ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸' in df_dict:
            continuous_text = df_dict['ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸']['ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸'].iloc[0]
            result['ingredients'] = {
                'structured_list': continuous_text.split(', '),
                'continuous_text': continuous_text
            }
        elif not first_sheet_df.empty:
            # ì²« ë²ˆì§¸ ì‹œíŠ¸ì˜ ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ ì›ì¬ë£Œëª…ìœ¼ë¡œ ì‚¬ìš©
            first_column = first_sheet_df.columns[0]
            if 'ì›ì¬ë£Œëª…' in first_sheet_df.columns:
                ingredients_list = first_sheet_df['ì›ì¬ë£Œëª…'].dropna().tolist()
            else:
                ingredients_list = first_sheet_df[first_column].dropna().astype(str).tolist()
            
            if ingredients_list:
                result['ingredients'] = {
                    'structured_list': ingredients_list,
                    'continuous_text': ', '.join(ingredients_list)
                }
        
        if 'ì•Œë ˆë¥´ê¸°ì •ë³´' in df_dict:
            allergens_df = df_dict['ì•Œë ˆë¥´ê¸°ì •ë³´']
            result['allergens'] = {}
            for _, row in allergens_df.iterrows():
                if row['í•­ëª©'] == 'í•¨ìœ  ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ':
                    result['allergens']['contains'] = row['ë‚´ìš©'].split(', ')
                elif row['í•­ëª©'] == 'ì œì¡°ì‹œì„¤ ì•ˆë‚´':
                    result['allergens']['manufacturing_facility'] = row['ë‚´ìš©']
        
        if 'ì˜ì–‘ì •ë³´' in df_dict:
            nutrition_df = df_dict['ì˜ì–‘ì •ë³´']
            per_100g = {}
            for _, row in nutrition_df.iterrows():
                if row['ì˜ì–‘ì„±ë¶„'] == 'ì´ ì—´ëŸ‰':
                    per_100g['calories'] = row['100g ë‹¹']
                else:
                    per_100g[row['ì˜ì–‘ì„±ë¶„']] = {
                        'amount': row['100g ë‹¹'],
                        'daily_value': row['1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)']
                    }
            result['nutrition_info'] = {'per_100g': per_100g}
        
        if 'ì œì¡°ì›ì •ë³´' in df_dict:
            result['manufacturer'] = df_dict['ì œì¡°ì›ì •ë³´'].to_dict('records')[0]
        
        if 'ì£¼ì˜ì‚¬í•­' in df_dict:
            result['precautions'] = df_dict['ì£¼ì˜ì‚¬í•­']['ì£¼ì˜ì‚¬í•­'].tolist()
        
        if 'ì›ì¬ë£Œìƒì„¸' in df_dict:
            result['details'] = df_dict['ì›ì¬ë£Œìƒì„¸'].to_dict('records')
        
        return jsonify(result)
    except Exception as e:
        print(f"âŒ ì—‘ì…€ ì½ê¸° ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

# 2ë‹¨ê³„: ê²€ì¦í•˜ê¸° (ì—‘ì…€ íŒŒì¼ ë˜ëŠ” JSON + ë””ìì¸ ì´ë¯¸ì§€)
@app.route('/api/verify-design', methods=['POST'])
def verify_design():
print("ğŸ•µï¸â€â™‚ï¸ 2ë‹¨ê³„: ë””ìì¸ ê²€ì¦ ì‹œì‘...")

    try:
        # -----------------------------
        # 1. íŒŒì¼ ë°›ê¸°
        # -----------------------------
        design_file = request.files.get('design_file')
        standard_excel = request.files.get('standard_excel')
        standard_json = request.form.get('standard_data')

        if not design_file:
            return jsonify({"error": "ë””ìì¸ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤. (design_file)"}), 400

        # -----------------------------
        # 2. ê¸°ì¤€ ë°ì´í„° ë¡œë”© (ì—‘ì…€ -> JSON)
        # -----------------------------
        if standard_excel:
            try:
                df_dict = pd.read_excel(
                    io.BytesIO(standard_excel.read()),
                    sheet_name=None,
                    engine='openpyxl'
                )

                first_sheet_name = list(df_dict.keys())[0]
                first_sheet_df = df_dict[first_sheet_name]

                standard_data = {}
                if not first_sheet_df.empty:
                    col = first_sheet_df.columns[0]
                    if 'ì›ì¬ë£Œëª…' in first_sheet_df.columns:
                        col = 'ì›ì¬ë£Œëª…'

                    ingredients_list = (
                        first_sheet_df[col]
                        .dropna()
                        .astype(str)
                        .tolist()
                    )

                    standard_data = {
                        'ingredients': {
                            'structured_list': ingredients_list,
                            'continuous_text': ', '.join(ingredients_list)
                        }
                    }
    # 1. íŒŒì¼ ë°›ê¸°
    design_file = request.files.get('design_file')
    standard_excel = request.files.get('standard_excel')
    standard_json = request.form.get('standard_data')

                standard_json = json.dumps(
                    standard_data,
                    ensure_ascii=False
                )

            except Exception as e:
                # ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨í•´ë„ ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ ì£¼ê¸°
                print("âŒ ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨:", e)
                return jsonify({
                    "error": f"ì—‘ì…€ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                }), 400

        # -----------------------------
        # 3. ë²•ë ¹ í…ìŠ¤íŠ¸ ì½ê¸°
        # -----------------------------
        law_text = ""
        # law_text_*.txt íŒŒì¼ë“¤
        for fpath in glob.glob('law_text_*.txt'):
            try:
                with open(fpath, 'r', encoding='utf-8') as f:
                    law_text += f.read() + "\n"
            except Exception as e:
                print(f"âš ï¸ ë²•ë ¹ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ ({fpath}):", e)
    if not design_file:
        return jsonify({"error": "ë””ìì¸ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # law_context.txt (ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê·¸ëƒ¥ ë„˜ì–´ê°)
    # 2. ê¸°ì¤€ ë°ì´í„° ë¡œë”© (ì—‘ì…€ -> JSON)
    if standard_excel:
try:
            with open('law_context.txt', 'r', encoding='utf-8') as f:
                law_text = f.read() + "\n" + law_text
        except FileNotFoundError:
            print("âš ï¸ law_context.txt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. (ë¬´ì‹œí•˜ê³  ì§„í–‰)")
            df_dict = pd.read_excel(io.BytesIO(standard_excel.read()), sheet_name=None, engine='openpyxl')
            first_sheet_name = list(df_dict.keys())[0]
            first_sheet_df = df_dict[first_sheet_name]

            standard_data = {}
            if not first_sheet_df.empty:
                # ì›ì¬ë£Œëª… ì»¬ëŸ¼ ì°¾ê¸° (ë‹¨ìˆœí™”)
                col = first_sheet_df.columns[0]
                if 'ì›ì¬ë£Œëª…' in first_sheet_df.columns: col = 'ì›ì¬ë£Œëª…'

                ingredients_list = first_sheet_df[col].dropna().astype(str).tolist()
                standard_data = {'ingredients': {'structured_list': ingredients_list,
                                                 'continuous_text': ', '.join(ingredients_list)}}

            standard_json = json.dumps(standard_data, ensure_ascii=False)
except Exception as e:
            print("âš ï¸ law_context.txt ì½ê¸° ì‹¤íŒ¨:", e)
            return jsonify({"error": f"ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨: {str(e)}"}), 400

    # 3. ë²•ë ¹ íŒŒì¼ ì½ê¸° (ìˆ˜ì •ë¨: ëª¨ë“  ë²•ë ¹ íŒŒì¼ ë™ë“±í•˜ê²Œ ë¡œë”©)
    law_text = ""

    # (1) í˜„ì¬ í´ë”ì˜ ëª¨ë“  'law_'ë¡œ ì‹œì‘í•˜ëŠ” txt íŒŒì¼ ì°¾ê¸°
    # law_context.txt, law_text_ì‹í’ˆìœ„ìƒë²•.txt ë“± ëª¨ë‘ í¬í•¨ë¨
    all_law_files = glob.glob('law_*.txt')

    print(f"ğŸ“š ë²•ë ¹ íŒŒì¼ ë¡œë”© ì¤‘: {len(all_law_files)}ê°œ ë°œê²¬")

        # -----------------------------
        # 4. í”„ë¡¬í”„íŠ¸ ì¡°í•©
        # -----------------------------
        full_prompt = f"""
        {PROMPT_VERIFY_DESIGN}
    for file_path in all_law_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                # ê° ë²•ë ¹ íŒŒì¼ ë‚´ìš©ì„ ëª…í™•íˆ êµ¬ë¶„í•´ì„œ í•©ì¹˜ê¸°
                law_text += f"\n\n=== [ì°¸ê³  ë²•ë ¹: {file_path}] ===\n{content}\n==========================\n"
        except Exception as e:
            print(f"âš ï¸ ë²•ë ¹ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ ({file_path}): {e}")

        [ì°¸ê³  ë²•ë ¹]
        {law_text[:60000]}
    # 4. AI í”„ë¡¬í”„íŠ¸ ì¡°ë¦½
    parts = [f"""
    {PROMPT_VERIFY_DESIGN}

        [ê¸°ì¤€ ë°ì´í„°(JSON)]
        {standard_json}
        """
    [ì°¸ê³  ë²•ë ¹]
    {law_text[:60000]}

        parts = [full_prompt]
    [ê¸°ì¤€ ë°ì´í„°]
    {standard_json}
    """]

        # ë””ìì¸ íŒŒì¼ì„ Geminiê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” Partë¡œ ë³€í™˜
        design_file.stream.seek(0)
        design_part = process_file_to_part(design_file)
        if design_part:
            parts.append(design_part)
    if design_file:
        # ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ë§Œ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  í¬ë¡­
        print("ğŸ” ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ ìë™ ê°ì§€ ì¤‘...")
        cropped_image, is_cropped = detect_label_area(design_file)
        
        if is_cropped:
            print("âœ‚ï¸ ì‹í’ˆí‘œì‹œì‚¬í•­ ì˜ì—­ë§Œ í¬ë¡­í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            # í¬ë¡­ëœ ì´ë¯¸ì§€ë¥¼ PIL Imageë¡œ ë³€í™˜
            cropped_image.seek(0)
            cropped_pil = PIL.Image.open(cropped_image)
            parts.append(cropped_pil)
else:
            return jsonify({"error": "ë””ìì¸ íŒŒì¼ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400
            print("ğŸ“„ ì „ì²´ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            parts.append(process_file_to_part(design_file))

        # -----------------------------
        # 5. Gemini í˜¸ì¶œ
        # -----------------------------
        if not GOOGLE_API_KEY:
            return jsonify({
                "error": "GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
            }), 500
    # 5. AI í˜¸ì¶œ ë° ê²°ê³¼ ì²˜ë¦¬ (ì—¬ê¸°ê°€ ì¤‘ìš”)
    try:
        # ì°½ì˜ì„± 0.0 ì„¤ì • (ì •ê·œì„± í™•ë³´)
        model = genai.GenerativeModel(
            MODEL_NAME,
            generation_config={"temperature": 0.0}
        )

        try:
            model = genai.GenerativeModel(
                MODEL_NAME,
                generation_config={"temperature": 0.0}
            )
            response = model.generate_content(parts)
            result_text = response.text.strip()

            # JSON ì¶”ì¶œ
            json_match = re.search(r"(\{.*\})", result_text, re.DOTALL)
            if json_match:
                clean_json = json_match.group(1)
                clean_json = clean_json.replace(",\n}", "\n}").replace(",\n]", "\n]")
                result = json.loads(clean_json)
            else:
                # JSON íŒ¨í„´ì´ ì—†ìœ¼ë©´ ê·¸ëƒ¥ íŒŒì‹± ì‹œë„
                clean_json = result_text.replace("```", "").strip()
                result = json.loads(clean_json)
        response = model.generate_content(parts)
        result_text = response.text.strip()

            # ğŸ”´ ì—¬ê¸°ì„œ í•˜ì´ë¼ì´íŠ¸ HTML ìƒì„±í•´ì„œ resultì— ì¶”ê°€
            design_text = result.get("design_ocr_text", "")
            issues = result.get("issues", [])
            highlighted_html = make_highlighted_html(design_text, issues)
            result["design_ocr_highlighted_html"] = highlighted_html
        # [ê°•ë ¥í•œ JSON íŒŒì‹± ë¡œì§] ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ JSONë§Œ ì¶”ì¶œ
        json_match = re.search(r"(\{.*\})", result_text, re.DOTALL)

        if json_match:
            clean_json = json_match.group(1)
            # ê°„ë‹¨í•œ ì‰¼í‘œ ë³´ì •
            clean_json = clean_json.replace(",\n}", "\n}").replace(",\n]", "\n]")
            result = json.loads(clean_json)
            # HTML íƒœê·¸ ì œê±°
            result = clean_ai_response(result)
            return jsonify(result)
        else:
            # JSON íŒ¨í„´ ëª» ì°¾ìœ¼ë©´ ì›ë³¸ì—ì„œ ì‹œë„ (í˜¹ì‹œ ëª¨ë¥´ë‹ˆ)
            clean_json = result_text.replace("``````", "").strip()
            result = json.loads(clean_json)
            # HTML íƒœê·¸ ì œê±°
            result = clean_ai_response(result)
return jsonify(result)

        except Exception as e:
            import traceback
            traceback.print_exc()
            print("âŒ Gemini í˜¸ì¶œ/íŒŒì‹± ì¤‘ ì˜¤ë¥˜:", e)
            return jsonify({
                "error": f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }), 500

except Exception as e:
        # ìœ„ì—ì„œ ì˜ˆìƒ ëª» í•œ ëª¨ë“  ì˜ˆì™¸ëŠ” ì—¬ê¸°ë¡œ
        print(f"âŒ ê²€ì¦ ì˜¤ë¥˜: {e}")
        # ìƒì„¸ ì—ëŸ¬ ë¡œê·¸ ì¶œë ¥
import traceback
traceback.print_exc()
        return jsonify({
            "error": f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        }), 500
        return jsonify({"error": str(e)}), 500


# QA ìë£Œ ì—…ë¡œë“œ ë° ì‹í’ˆí‘œì‹œì‚¬í•­ ì‘ì„± API
@app.route('/api/upload-qa', methods=['POST'])
@@ -845,9 +1105,29 @@ def upload_qa():
result_text = "\n".join(lines[1:])
if result_text.endswith("```"):
result_text = result_text[:-3]

        
result_text = result_text.strip()

        
        # JSON íŒŒì‹± ì‹œë„
        try:
            result = json.loads(result_text)
        except json.JSONDecodeError as json_err:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {json_err}")
            print(f"ì‘ë‹µ í…ìŠ¤íŠ¸ (ì²˜ìŒ 1000ì): {result_text[:1000]}")
            print(f"ì˜¤ë¥˜ ìœ„ì¹˜: line {json_err.lineno}, column {json_err.colno}")
            # JSON ìˆ˜ì • ì‹œë„
            try:
                result_text_fixed = result_text.replace(',\n}', '\n}').replace(',\n]', '\n]')
                result = json.loads(result_text_fixed)
                print("âœ… JSON ìˆ˜ì • í›„ íŒŒì‹± ì„±ê³µ")
            except:
                return jsonify({"error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(json_err)}. ì‘ë‹µì˜ ì¼ë¶€: {result_text[:200]}..."}), 500
        
        return jsonify(result)
        
    except Exception as e:
        print(f"âŒ QA ìë£Œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        import traceback
traceback.print_exc()
return jsonify({"error": str(e)}), 500
