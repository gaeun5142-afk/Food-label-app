import os
import json
import io
import glob
import traceback
import base64
import re
import unicodedata
import html

import pandas as pd
from flask import Flask, request, jsonify, render_template, send_file
from flask_cors import CORS
from dotenv import load_dotenv
from openai import OpenAI
import PIL.Image

# Optional PDF->Image (if installed)
try:
    from pdf2image import convert_from_bytes
    PDF2IMAGE_AVAILABLE = True
except Exception:
    PDF2IMAGE_AVAILABLE = False

# ==============================
# ê¸°ë³¸ ì„¤ì •
# ==============================
load_dotenv()

app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False  # í•œê¸€ ê¹¨ì§ ë°©ì§€
CORS(app)

# OpenAI ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    print("ğŸš¨ ê²½ê³ : .env íŒŒì¼ì— OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤!")
    client = None
else:
    client = OpenAI(api_key=OPENAI_API_KEY)

# ChatGPT ë©€í‹°ëª¨ë‹¬ ëª¨ë¸
MODEL_NAME = "gpt-4.1-mini"   # í…ìŠ¤íŠ¸+ì´ë¯¸ì§€ ëª¨ë‘ ì§€ì›


# ==============================
# ê³µí†µ ìœ í‹¸ í•¨ìˆ˜
# ==============================

def normalize_text_strict(text):
    """ì—„ê²©í•œ ë¹„êµìš© ì •ê·œí™” (ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ìœ ì§€)"""
    if not isinstance(text, str):
        text = str(text)
    # ìœ ë‹ˆì½”ë“œ ì •ê·œí™”ë§Œ, ê³µë°±/íŠ¹ìˆ˜ë¬¸ìëŠ” ê·¸ëŒ€ë¡œ
    return unicodedata.normalize('NFKC', text)


def compare_texts_strict(standard_text, design_text):
    """ë¬¸ì ë‹¨ìœ„ ì •í™• ë¹„êµ (AI ì—†ì´)"""
    std_norm = normalize_text_strict(standard_text)
    des_norm = normalize_text_strict(design_text)

    issues = []
    max_len = max(len(std_norm), len(des_norm))

    for i in range(max_len):
        std_char = std_norm[i] if i < len(std_norm) else '(ì—†ìŒ)'
        des_char = des_norm[i] if i < len(des_norm) else '(ì—†ìŒ)'

        if std_char != des_char:
            issues.append({
                "position": i,
                "expected": std_char,
                "actual": des_char,
                "context_before": std_norm[max(0, i - 5):i],
                "context_after": std_norm[i + 1:min(len(std_norm), i + 6)]
            })

    return issues


def to_image_data_url(img_bytes: bytes, mime_type: str = "image/png") -> str:
    """ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ë¥¼ data URL(base64)ë¡œ ë³€í™˜"""
    b64 = base64.b64encode(img_bytes).decode("utf-8")
    return f"data:{mime_type};base64,{b64}"


def call_openai_from_parts(parts, json_mode: bool = True) -> str:
    """
    OpenAI Responses API í˜¸ì¶œ.
    - parts: ë¬¸ìì—´(str), PIL.Image.Image ì„ì—¬ ìˆëŠ” ë¦¬ìŠ¤íŠ¸
    - json_mode: Trueë©´ "JSONë§Œ ì¶œë ¥" ì‹œìŠ¤í…œ ì§€ì‹œ ì¶”ê°€
    - ë°˜í™˜ê°’: ChatGPTê°€ ë°˜í™˜í•œ í…ìŠ¤íŠ¸ ì „ì²´ (string)
    """
    if client is None:
        raise RuntimeError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

    content = []

    if json_mode:
        # JSON ê°•ì œ ì§€ì‹œ
        content.append({
            "type": "input_text",
            "text": (
                "í•­ìƒ ìœ íš¨í•œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. "
                "ë§ˆí¬ë‹¤ìš´, ì½”ë“œë¸”ë¡, ì„¤ëª… ë¬¸ì¥ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
            ),
        })

    for p in parts:
        if isinstance(p, str):
            content.append({"type": "input_text", "text": p})
        elif isinstance(p, PIL.Image.Image):
            buf = io.BytesIO()
            fmt = p.format if p.format else "PNG"
            p.save(buf, format=fmt)
            buf.seek(0)
            data_url = to_image_data_url(buf.getvalue(), mime_type=f"image/{fmt.lower()}")
            content.append({
                "type": "input_image",
                "image_url": {"url": data_url},
            })
        else:
            # ê¸°íƒ€ íƒ€ì…ì€ í˜„ì¬ ë¬´ì‹œ (í•„ìš”ì‹œ í™•ì¥)
            pass

    resp = client.responses.create(
        model=MODEL_NAME,
        input=[{"role": "user", "content": content}],
        temperature=0.0,
        max_output_tokens=32768,
    )

    # text ê²°ê³¼ë§Œ ëª¨ìœ¼ê¸°
    result_chunks = []
    for out in getattr(resp, "output", []):
        for c in getattr(out, "content", []):
            if getattr(c, "type", None) == "output_text" and getattr(c, "text", None):
                result_chunks.append(c.text)
    result_text = "".join(result_chunks).strip()
    return result_text


# ==============================
# ë²•ë ¹ í…ìŠ¤íŠ¸ ë¡œë“œ
# ==============================

def load_law_texts() -> str:
    """ë²•ë ¹ .txt íŒŒì¼ë“¤ì„ ëª¨ë‘ ì½ì–´ í•˜ë‚˜ì˜ í° í…ìŠ¤íŠ¸ë¡œ í•©ì¹©ë‹ˆë‹¤."""
    print("ğŸ“š ë²•ë ¹ íŒŒì¼ë“¤ì„ ì½ì–´ì˜¤ëŠ” ì¤‘...")
    law_files = glob.glob("law_text_*.txt") + glob.glob("../law_text_*.txt")
    if not law_files:
        print("âš ï¸ ë²•ë ¹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë²•ë¥  ê²€í†  ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return ""
    all_law_text = ""
    for file_path in law_files:
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                all_law_text += f"--- ë²•ë ¹ [{file_path}] ì‹œì‘ ---\n\n"
                all_law_text += f.read()
                all_law_text += f"\n\n--- ë²•ë ¹ [{file_path}] ë ---\n\n"
            print(f"âœ… ë²•ë ¹ íŒŒì¼ '{file_path}' ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ë²•ë ¹ íŒŒì¼ '{file_path}' ì½ê¸° ì‹¤íŒ¨: {e}")
    print(f"âœ… ëª¨ë“  ë²•ë ¹ íŒŒì¼ ë¡œë“œ ì™„ë£Œ (ì´ {len(all_law_text)}ì)")
    return all_law_text


ALL_LAW_TEXT = load_law_texts()


# ==============================
# í”„ë¡¬í”„íŠ¸ ì •ì˜
# ==============================

PROMPT_EXTRACT_INGREDIENT_INFO = """
ë‹¹ì‹ ì€ í•œêµ­ ì‹í’ˆ ë¼ë²¨ OCR ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì´ë¯¸ì§€ì—ì„œ ì›ë¶€ì¬ë£Œ í‘œì‹œì‚¬í•­ì„ **ì •í™•í•˜ê²Œ** ì¶”ì¶œí•˜ì„¸ìš”.
ì¶”ì¸¡í•˜ê±°ë‚˜ ì°½ì˜ì ìœ¼ë¡œ í•´ì„í•˜ì§€ ë§ê³ , ë³´ì´ëŠ” í…ìŠ¤íŠ¸ë§Œ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.

ğŸš¨ ì ˆëŒ€ ê·œì¹™ ğŸš¨
1. ì´ë¯¸ì§€ì— **ë³´ì´ëŠ” ê¸€ìë§Œ** ì¶”ì¶œ (ì¶”ë¡ /ë³´ì • ê¸ˆì§€)
2. **íŠ¹ìˆ˜ë¬¸ì(ì‰¼í‘œ, ì , ê´„í˜¸) ëˆ„ë½ë„ ê·¸ëŒ€ë¡œ** ì¶”ì¶œ
3. ì˜¤íƒ€, ë„ì–´ì“°ê¸°, íŠ¹ìˆ˜ë¬¸ì ëª¨ë‘ **ì •í™•íˆ ê·¸ëŒ€ë¡œ**
4. ë¬¸ë²•ì ìœ¼ë¡œ í‹€ë ¤ë„ **ì´ë¯¸ì§€ì™€ 100% ë™ì¼**í•˜ê²Œ

[ì¶”ì¶œí•´ì•¼ í•  ì •ë³´]
1. **ì›ì¬ë£Œëª…**: ì›ì¬ë£Œì˜ ì •í™•í•œ ëª…ì¹­ (ì˜¤íƒ€ ì—†ì´)
2. **ë³µí•©ì›ì¬ë£Œ ë‚´ì—­**: ê´„í˜¸ ì•ˆì˜ í•˜ìœ„ ì›ì¬ë£Œ ì •ë³´ (ì˜ˆ: (íƒˆì§€ëŒ€ë‘, ì†Œë§¥))
3. **ì›ì‚°ì§€ ì •ë³´**: ì›ì‚°ì§€ í‘œê¸° (ì˜ˆ: ì™¸êµ­ì‚°, êµ­ë‚´ì‚°, ì¸ë„ì‚° ë“±)
4. **í•¨ëŸ‰ ì •ë³´**: ë°±ë¶„ìœ¨(%) í‘œì‹œ
5. **ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ**: ì•Œë ˆë¥´ê¸° í‘œì‹œ ì •ë³´
6. **ì‹í’ˆì²¨ê°€ë¬¼**: ì²¨ê°€ë¬¼ëª…ê³¼ ìš©ë„ ë³‘ê¸° ì—¬ë¶€

[ì¶œë ¥ í˜•ì‹]
ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”:
{
  "ingredient_name": "ì›ì¬ë£Œëª…",
  "content_percentage": "í•¨ëŸ‰(%)",
  "sub_ingredients": "í•˜ìœ„ì›ì¬ë£Œ ë‚´ì—­ (ë³µí•©ì›ì¬ë£Œì¸ ê²½ìš°)",
  "origin": "ì›ì‚°ì§€ ì •ë³´",
  "allergens": ["ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ ëª©ë¡"],
  "additives": ["ì‹í’ˆì²¨ê°€ë¬¼ ëª©ë¡"],
  "raw_ocr_text": "ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œí•œ ì „ì²´ í…ìŠ¤íŠ¸ (ì›ë³¸ ê·¸ëŒ€ë¡œ)"
}
"""

PROMPT_EXTRACT_RAW_TEXT = """
ë‹¹ì‹ ì€ OCR ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ **ê¸°ê³„ì ìœ¼ë¡œ** ì¶”ì¶œí•˜ì„¸ìš”.

ğŸ¤– ê¸°ê³„ ëª¨ë“œ í™œì„±í™”:
- ì² ì êµì •ê¸° OFF
- ë¬¸ë²• ê²€ì‚¬ê¸° OFF
- ìë™ ì™„ì„± OFF
- ì¶”ë¡  ì—”ì§„ OFF

ì¶œë ¥ ê·œì¹™:
1. ë³´ì´ëŠ” ê¸€ì â†’ ê·¸ëŒ€ë¡œ ì¶œë ¥
2. í‹€ë¦° ê¸€ì â†’ í‹€ë¦° ëŒ€ë¡œ ì¶œë ¥
3. ë¹ ì§„ ì‰¼í‘œ â†’ ë¹ ì§„ ëŒ€ë¡œ ì¶œë ¥
4. ì´ìƒí•œ ìˆ«ì â†’ ì´ìƒí•œ ëŒ€ë¡œ ì¶œë ¥

ì˜ˆì‹œ:
- ì´ë¯¸ì§€: "ì „ë°˜ê°€ê³µí’ˆ" â†’ ì¶œë ¥: "ì „ë°˜ê°€ê³µí’ˆ" (ì „ë¶„ê°€ê³µí’ˆ ì•„ë‹˜!)
- ì´ë¯¸ì§€: "ëŒ€ë‘ ê²Œ" â†’ ì¶œë ¥: "ëŒ€ë‘ ê²Œ" (ëŒ€ë‘, ê²Œ ì•„ë‹˜!)
- ì´ë¯¸ì§€: "221%" â†’ ì¶œë ¥: "221%" (2.21% ì•„ë‹˜!)

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ:
{
  "raw_text": "ìˆëŠ” ê·¸ëŒ€ë¡œì˜ í…ìŠ¤íŠ¸"
}
"""

PROMPT_CREATE_STANDARD = """
ë‹¹ì‹ ì€ ì‹í’ˆ ê·œì • ë° í‘œì‹œì‚¬í•­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ [ë°°í•©ë¹„ ë°ì´í„°(Excel)]ì™€ [ì›ì¬ë£Œ í‘œì‹œì‚¬í•­ ì‚¬ì§„ë“¤ì—ì„œ ì¶”ì¶œí•œ ì •ë³´]ë¥¼ ì¢…í•©í•˜ì—¬,
ë²•ì ìœ¼ë¡œ ì™„ë²½í•œ **'ì‹í’ˆí‘œì‹œì‚¬í•­ ê¸°ì¤€ ë°ì´í„°(Standard)'**ë¥¼ ì‹¤ì œ ë¼ë²¨ í˜•ì‹ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.

[ë¶„ì„ ë‹¨ê³„]
1. **Excel ë°ì´í„° ë¶„ì„**: ë°°í•©ë¹„ìœ¨(%)ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì›ì¬ë£Œ ë‚˜ì—´ ìˆœì„œë¥¼ ê²°ì •í•˜ì„¸ìš”. (ê°€ì¥ ì¤‘ìš”)
2. **ì´ë¯¸ì§€ ë°ì´í„° ë§¤í•‘**: Excelì— ì íŒ ì›ì¬ë£Œëª…(ì˜ˆ: 'ê°„ì¥')ì— í•´ë‹¹í•˜ëŠ” ì‚¬ì§„(ì›ì¬ë£Œ ë¼ë²¨)ì„ ì°¾ì•„ì„œ ìƒì„¸ ì •ë³´(ë³µí•©ì›ì¬ë£Œ ë‚´ì—­, ì•Œë ˆë¥´ê¸°, ì›ì‚°ì§€)ë¥¼ ë³´ê°•í•˜ì„¸ìš”.
3. **ë²•ë¥  ê²€í† **: ì œê³µëœ ë²•ë ¹ì„ ì°¸ê³ í•˜ì—¬ í‘œì‹œì‚¬í•­ì´ ë²•ì ìœ¼ë¡œ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.
4. **ìµœì¢… ì¡°í•©**: í’ˆëª©ì œì¡°ë³´ê³ ì„œ ê¸°ë°˜ì˜ ë¹„ìœ¨ê³¼ ì›ì¬ë£Œ ë¼ë²¨ì˜ ìƒì„¸ ë‚´ìš©ì„ í•©ì³ ìµœì¢… í‘œì‹œ í…ìŠ¤íŠ¸ë¥¼ ë§Œë“œì„¸ìš”.

[ì¶œë ¥ ì–‘ì‹ - JSON]
(ìƒëµ)  # ì‹¤ì œ ë‚´ìš©ì€ ë„ˆë¬´ ê¸¸ì–´ì„œ ì—¬ê¸°ì„œëŠ” ìƒëµí•˜ì§€ë§Œ, ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
"""

PROMPT_VERIFY_DESIGN = """
ë‹¹ì‹ ì€ ì‹í’ˆí‘œì‹œì‚¬í•­ ê°ì‚¬ AIì…ë‹ˆë‹¤.
ì œê³µëœ [Standard(ê¸°ì¤€ì„œ)]ì™€ [Design(ë””ìì¸)]ì„ 1:1 ì •ë°€ ëŒ€ì¡°í•˜ì—¬, ì•„ë˜ ê·œì¹™ì— ë”°ë¼ ëƒ‰ì² í•˜ê²Œ ì±„ì í•˜ì„¸ìš”.

(ì¤‘ëµ - ê¸°ì¡´ PROMPT_VERIFY_DESIGN ì „ì²´ ë‚´ìš© ê·¸ëŒ€ë¡œ)
ìœ„ ì„¤ëª…ì„ ëª¨ë‘ ë”°ë¥¸ ë’¤, ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš” (ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€):

{
  "design_ocr_text": "ë””ìì¸ì—ì„œ ì¶”ì¶œí•œ ì „ì²´ í…ìŠ¤íŠ¸",
  "score": 100,
  "law_compliance": {
    "status": "compliant",
    "violations": []
  },
  "issues": [
    {
      "type": "Critical" | "Minor" | "Law_Violation",
      "location": "í•­ëª©ëª… (ì˜ˆ: ì›ì¬ë£Œëª…, ì˜ì–‘ì •ë³´)",
      "issue": "ë¬´ì—‡ì´ ì˜ëª»ë˜ì—ˆëŠ”ì§€",
      "expected": "Standardì— ìˆëŠ” ì •í™•í•œ ê°’",
      "actual": "Designì—ì„œ ë°œê²¬ëœ ì˜¤ë¥˜ í…ìŠ¤íŠ¸ (í•˜ì´ë¼ì´íŠ¸í•  í…ìŠ¤íŠ¸)",
      "suggestion": "ìˆ˜ì • ë°©ë²•"
    }
  ]
}
"""


# ==============================
# OCR & í•˜ì´ë¼ì´íŠ¸ í•¨ìˆ˜
# ==============================

def ocr_bytes_with_openai(image_bytes: bytes) -> str:
    """ì´ë¯¸ì§€ ë°”ì´íŠ¸ë¥¼ OpenAI Visionìœ¼ë¡œ OCR -> raw_text ë°˜í™˜"""
    try:
        img = PIL.Image.open(io.BytesIO(image_bytes)).convert("RGB")
        parts = [PROMPT_EXTRACT_RAW_TEXT, img]
        result_text = call_openai_from_parts(parts, json_mode=True).strip()

        # ì½”ë“œë¸”ë¡ ì œê±°
        if result_text.startswith("```json"):
            result_text = result_text[7:]
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        elif result_text.startswith("```"):
            lines = result_text.split("\n")
            if lines and lines[0].startswith("```"):
                lines = lines[1:]
            if lines and lines[-1].strip().startswith("```"):
                lines = lines[:-1]
            result_text = "\n".join(lines).strip()

        try:
            obj = json.loads(result_text)
            raw_text = obj.get("raw_text", "").strip()
            return raw_text or result_text
        except json.JSONDecodeError:
            # JSON ì•„ë‹ˆë©´ ê·¸ëƒ¥ ì „ì²´ í…ìŠ¤íŠ¸
            return result_text
    except Exception as e:
        print("âŒ OpenAI OCR ì‹¤íŒ¨:", e)
        traceback.print_exc()
        return ""


def extract_ingredient_info_from_image(image_file):
    """ì›ì¬ë£Œ í‘œì‹œì‚¬í•­ ì´ë¯¸ì§€ì—ì„œ í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ (OpenAI Vision)"""
    try:
        image_data = image_file.read()
        image_file.seek(0)
        img_pil = PIL.Image.open(io.BytesIO(image_data)).convert("RGB")

        parts = [PROMPT_EXTRACT_INGREDIENT_INFO, img_pil]
        result_text = call_openai_from_parts(parts, json_mode=True).strip()

        # ì½”ë“œë¸”ë¡ ì œê±°
        if result_text.startswith("```json"):
            result_text = result_text[7:]
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        elif result_text.startswith("```"):
            lines = result_text.split("\n")
            if lines and lines[0].startswith("```"):
                lines = lines[1:]
            if lines and lines[-1].strip().startswith("```"):
                lines = lines[:-1]
            result_text = "\n".join(lines).strip()

        return json.loads(result_text)
    except json.JSONDecodeError as e:
        print(f"ì›ì¬ë£Œ ì •ë³´ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        print(f"ì‘ë‹µ í…ìŠ¤íŠ¸: {result_text[:500]}...")
        return None
    except Exception as e:
        print(f"ì›ì¬ë£Œ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return None


def highlight_ocr_errors(ocr_text: str, issues: list) -> str:
    """
    OCR í…ìŠ¤íŠ¸ì—ì„œ issue.actual ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ì„ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í•˜ì´ë¼ì´íŠ¸.
    ë°˜í™˜ê°’: HTML ë¬¸ìì—´
    """
    if not ocr_text:
        return ""

    import html as html_mod
    import re as re_mod

    highlighted_text = str(ocr_text)

    if not issues:
        highlighted_text = html_mod.escape(highlighted_text)
        highlighted_text = highlighted_text.replace("\n", "<br>")
        return highlighted_text

    # í•˜ì´ë¼ì´íŠ¸ ëŒ€ìƒ ë¬¸ìì—´ ìˆ˜ì§‘
    highlight_texts = []
    seen = set()
    for issue in issues:
        actual = issue.get("actual", "")
        if actual:
            actual_clean = str(actual).strip()
            if actual_clean and actual_clean not in seen:
                highlight_texts.append(actual_clean)
                seen.add(actual_clean)
                print(f"ğŸ”´ í•˜ì´ë¼ì´íŠ¸ ëŒ€ìƒ: '{actual_clean}'")

    if not highlight_texts:
        highlighted_text = html_mod.escape(highlighted_text)
        highlighted_text = highlighted_text.replace("\n", "<br>")
        return highlighted_text

    # ê¸´ ë¬¸ìì—´ë¶€í„° ì²˜ë¦¬
    highlight_texts.sort(key=len, reverse=True)

    # ìœ„ì¹˜ ê³„ì‚°
    highlight_positions = []
    for highlight_text in highlight_texts:
        start = 0
        while True:
            pos = highlighted_text.find(highlight_text, start)
            if pos == -1:
                break
            # ê²¹ì¹¨ ë°©ì§€
            overlap = False
            for existing_pos in highlight_positions:
                if not (pos + len(highlight_text) <= existing_pos[0] or pos >= existing_pos[1]):
                    overlap = True
                    break
            if not overlap:
                highlight_positions.append((pos, pos + len(highlight_text), highlight_text))
            start = pos + 1

    # ë’¤ì—ì„œë¶€í„° ì ìš©
    highlight_positions.sort(reverse=True)

    for start, end, highlight_text in highlight_positions:
        escaped_text = html_mod.escape(highlight_text)
        highlighted = (
            '<span style="background-color:#ffcccc;'
            ' color:#cc0000; font-weight:bold; padding:2px 4px;'
            ' border-radius:3px;">'
            f'{escaped_text}</span>'
        )
        highlighted_text = highlighted_text[:start] + highlighted + highlighted_text[end:]
        print(f"âœ… í•˜ì´ë¼ì´íŠ¸ ì ìš©: '{highlight_text}' (ìœ„ì¹˜: {start}-{end})")

    # í•˜ì´ë¼ì´íŠ¸ íƒœê·¸ ì™¸ë¶€ í…ìŠ¤íŠ¸ ì´ìŠ¤ì¼€ì´í”„
    parts = re_mod.split(r'(<span[^>]*>.*?</span>)', highlighted_text)
    result_parts = []
    for part in parts:
        if part.startswith('<span'):
            result_parts.append(part)
        else:
            result_parts.append(html_mod.escape(part))
    highlighted_text = ''.join(result_parts)

    highlighted_text = highlighted_text.replace("\n", "<br>")
    return highlighted_text


# ==============================
# ì—‘ì…€ â†’ ê¸°ì¤€ë°ì´í„° ì—‘ì…€ ìƒì„±
# ==============================

def create_standard_excel(data):
    """ê¸°ì¤€ ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ìƒì„±"""
    output = io.BytesIO()

    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        # 1. ì œí’ˆ ì •ë³´ ì‹œíŠ¸
        if 'product_info' in data:
            product_df = pd.DataFrame([data['product_info']])
            product_df.to_excel(writer, sheet_name='ì œí’ˆì •ë³´', index=False)

        # 2. ì›ì¬ë£Œëª… ì‹œíŠ¸
        if 'ingredients' in data:
            ingredients_data = []
            if 'structured_list' in data['ingredients']:
                for idx, item in enumerate(data['ingredients']['structured_list'], 1):
                    ingredients_data.append({
                        'ìˆœë²ˆ': idx,
                        'ì›ì¬ë£Œëª…': item
                    })
            ingredients_df = pd.DataFrame(ingredients_data)
            if not ingredients_df.empty:
                ingredients_df.to_excel(writer, sheet_name='ì›ì¬ë£Œëª…', index=False)

            if 'continuous_text' in data['ingredients']:
                continuous_df = pd.DataFrame([{
                    'ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸': data['ingredients']['continuous_text']
                }])
                continuous_df.to_excel(writer, sheet_name='ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸', index=False)

        # 3. ì•Œë ˆë¥´ê¸° ì •ë³´ ì‹œíŠ¸
        if 'allergens' in data:
            allergens_data = []
            if 'contains' in data['allergens']:
                allergens_data.append({
                    'í•­ëª©': 'í•¨ìœ  ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ',
                    'ë‚´ìš©': ', '.join(data['allergens']['contains'])
                })
            if 'manufacturing_facility' in data['allergens']:
                allergens_data.append({
                    'í•­ëª©': 'ì œì¡°ì‹œì„¤ ì•ˆë‚´',
                    'ë‚´ìš©': data['allergens']['manufacturing_facility']
                })
            if allergens_data:
                allergens_df = pd.DataFrame(allergens_data)
                allergens_df.to_excel(writer, sheet_name='ì•Œë ˆë¥´ê¸°ì •ë³´', index=False)

        # 4. ì˜ì–‘ì •ë³´ ì‹œíŠ¸
        if 'nutrition_info' in data and 'per_100g' in data['nutrition_info']:
            nutrition_data = []
            nut = data['nutrition_info']['per_100g']
            if 'calories' in nut:
                nutrition_data.append({
                    'ì˜ì–‘ì„±ë¶„': 'ì´ ì—´ëŸ‰',
                    '100g ë‹¹': nut['calories'],
                    '1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)': '-'
                })
            for key, value in nut.items():
                if key != 'calories' and isinstance(value, dict):
                    nutrition_data.append({
                        'ì˜ì–‘ì„±ë¶„': key,
                        '100g ë‹¹': value.get('amount', ''),
                        '1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)': value.get('daily_value', '')
                    })
            if nutrition_data:
                nutrition_df = pd.DataFrame(nutrition_data)
                nutrition_df.to_excel(writer, sheet_name='ì˜ì–‘ì •ë³´', index=False)

        # 5. ì œì¡°ì› ì •ë³´ ì‹œíŠ¸
        if 'manufacturer' in data:
            manufacturer_df = pd.DataFrame([data['manufacturer']])
            manufacturer_df.to_excel(writer, sheet_name='ì œì¡°ì›ì •ë³´', index=False)

        # 6. ì£¼ì˜ì‚¬í•­ ì‹œíŠ¸
        if 'precautions' in data:
            precautions_df = pd.DataFrame([{'ì£¼ì˜ì‚¬í•­': item} for item in data['precautions']])
            precautions_df.to_excel(writer, sheet_name='ì£¼ì˜ì‚¬í•­', index=False)

        # 7. ìƒì„¸ ì •ë³´ ì‹œíŠ¸
        if 'details' in data and data['details']:
            details_df = pd.DataFrame(data['details'])
            details_df.to_excel(writer, sheet_name='ì›ì¬ë£Œìƒì„¸', index=False)

    output.seek(0)
    return output


# ==============================
# íŒŒì¼ â†’ OpenAI íŒŒíŠ¸ ë³€í™˜
# ==============================

def process_file_to_text_or_image(file_storage):
    """
    íŒŒì¼ì„ OpenAIì— ë„˜ê¸¸ ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜
    - ì—‘ì…€: CSV í…ìŠ¤íŠ¸
    - ì´ë¯¸ì§€: PIL.Image
    - PDF: ì²« í˜ì´ì§€ ì´ë¯¸ì§€
    """
    mime_type = file_storage.mimetype
    file_data = file_storage.read()
    file_storage.seek(0)

    # ì—‘ì…€
    if mime_type in [
        'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
        'application/vnd.ms-excel',
    ]:
        try:
            df = pd.read_excel(io.BytesIO(file_data))
            csv_text = df.to_csv(index=False)
            return f"--- [Excel ë°°í•©ë¹„ ë°ì´í„°] ---\n{csv_text}"
        except Exception as e:
            print(f"ì—‘ì…€ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None

    # PDF
    if mime_type == 'application/pdf' and PDF2IMAGE_AVAILABLE:
        try:
            images = convert_from_bytes(file_data, dpi=200)
            if images:
                return images[0].convert("RGB")
        except Exception as e:
            print("PDF->ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨:", e)
            return None

    # ì´ë¯¸ì§€
    if mime_type.startswith("image/"):
        try:
            img = PIL.Image.open(io.BytesIO(file_data)).convert("RGB")
            return img
        except Exception as e:
            print("ì´ë¯¸ì§€ ì½ê¸° ì‹¤íŒ¨:", e)
            return None

    return None


# ==============================
# ë¼ìš°íŠ¸
# ==============================

@app.route("/")
def index():
    return render_template("index.html")


# 1ë‹¨ê³„: ê¸°ì¤€ ë°ì´í„° ìƒì„±
@app.route("/api/create-standard", methods=["POST"])
def create_standard():
    print("âš™ï¸ 1ë‹¨ê³„: ê¸°ì¤€ ë°ì´í„° ìƒì„± ì‹œì‘...")

    excel_file = request.files.get("excel_file")
    raw_images = request.files.getlist("raw_images")

    if not excel_file:
        return jsonify({"error": "ë°°í•©ë¹„ ì—‘ì…€ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    parts = []

    # í”„ë¡¬í”„íŠ¸ + ë²•ë ¹
    enhanced_prompt = PROMPT_CREATE_STANDARD
    if ALL_LAW_TEXT:
        enhanced_prompt += f"\n\n--- [ì°¸ê³  ë²•ë ¹] ---\n{ALL_LAW_TEXT}\n--- [ë²•ë ¹ ë] ---\n"
    parts.append(enhanced_prompt)

    # ì—‘ì…€ í…ìŠ¤íŠ¸
    excel_text = process_file_to_text_or_image(excel_file)
    if isinstance(excel_text, str):
        parts.append(excel_text)

    # ì›ì¬ë£Œ ì´ë¯¸ì§€ë“¤ì—ì„œ ì •ë³´ ì¶”ì¶œ
    ingredient_info_list = []
    for img_file in raw_images[:15]:
        print(f"ğŸ“· ì›ì¬ë£Œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘: {img_file.filename}")
        info = extract_ingredient_info_from_image(img_file)
        if info:
            ingredient_info_list.append(info)

    if ingredient_info_list:
        ingredients_text = "--- [ì›ì¬ë£Œ í‘œì‹œì‚¬í•­ì—ì„œ ì¶”ì¶œí•œ ì •ë³´] ---\n"
        for idx, info in enumerate(ingredient_info_list, 1):
            ingredients_text += f"\n[ì›ì¬ë£Œ {idx}]\n"
            ingredients_text += json.dumps(info, ensure_ascii=False, indent=2)
            ingredients_text += "\n"
        ingredients_text += "--- [ì›ì¬ë£Œ ì •ë³´ ë] ---\n"
        parts.append(ingredients_text)

    try:
        result_text = call_openai_from_parts(parts, json_mode=True).strip()

        # ì½”ë“œë¸”ë¡ ì œê±°
        if result_text.startswith("```json"):
            result_text = result_text[7:]
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        elif result_text.startswith("```"):
            lines = result_text.split("\n")
            if lines and lines[0].startswith("```"):
                result_text = "\n".join(lines[1:])
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        result_text = result_text.strip()

        try:
            result = json.loads(result_text)
        except json.JSONDecodeError as json_err:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {json_err}")
            print(f"ì‘ë‹µ í…ìŠ¤íŠ¸ (ì²˜ìŒ 1000ì): {result_text[:1000]}")
            try:
                result_text_fixed = result_text.replace(",\n}", "\n}").replace(",\n]", "\n]")
                result = json.loads(result_text_fixed)
                print("âœ… JSON ìˆ˜ì • í›„ íŒŒì‹± ì„±ê³µ")
            except:
                return jsonify({"error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(json_err)}"}), 500

        return jsonify(result)

    except Exception as e:
        print("âŒ ê¸°ì¤€ ë°ì´í„° ìƒì„± ì˜¤ë¥˜:", e)
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


@app.route("/api/download-standard-excel", methods=["POST"])
def download_standard_excel():
    """ê¸°ì¤€ ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "ê¸°ì¤€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

        excel_buffer = create_standard_excel(data)
        product_name = data.get("product_info", {}).get("product_name", "ê¸°ì¤€ë°ì´í„°") or data.get("product_name", "ê¸°ì¤€ë°ì´í„°")
        filename = f"{product_name}_ê¸°ì¤€ë°ì´í„°.xlsx"

        return send_file(
            excel_buffer,
            mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            as_attachment=True,
            download_name=filename,
        )
    except Exception as e:
        print("âŒ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜:", e)
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


@app.route("/api/read-standard-excel", methods=["POST"])
def read_standard_excel():
    """ì—‘ì…€ íŒŒì¼ì—ì„œ ê¸°ì¤€ ë°ì´í„°ë¥¼ ì½ì–´ì˜´"""
    try:
        excel_file = request.files.get("excel_file")
        if not excel_file:
            return jsonify({"error": "ì—‘ì…€ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        df_dict = pd.read_excel(
            io.BytesIO(excel_file.read()),
            sheet_name=None,
            engine="openpyxl",
            dtype=str,
            keep_default_na=False,
            na_filter=False,
        )

        for sheet_name, df in df_dict.items():
            df_dict[sheet_name] = df.astype(str)

        result = {}

        if "ì œí’ˆì •ë³´" in df_dict:
            product_info = df_dict["ì œí’ˆì •ë³´"].to_dict("records")[0]
            result["product_info"] = product_info

        first_sheet_name = list(df_dict.keys())[0]
        first_sheet_df = df_dict[first_sheet_name]

        if "ì›ì¬ë£Œëª…" in df_dict:
            ingredients_list = df_dict["ì›ì¬ë£Œëª…"]["ì›ì¬ë£Œëª…"].dropna().tolist()
            result["ingredients"] = {
                "structured_list": ingredients_list,
                "continuous_text": ", ".join(ingredients_list),
            }
        elif "ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸" in df_dict:
            continuous_text = df_dict["ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸"]["ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸"].iloc[0]
            result["ingredients"] = {
                "structured_list": continuous_text.split(", "),
                "continuous_text": continuous_text,
            }
        elif not first_sheet_df.empty:
            first_column = first_sheet_df.columns[0]
            if "ì›ì¬ë£Œëª…" in first_sheet_df.columns:
                ingredients_list = first_sheet_df["ì›ì¬ë£Œëª…"].dropna().tolist()
            else:
                ingredients_list = first_sheet_df[first_column].dropna().astype(str).tolist()
            if ingredients_list:
                result["ingredients"] = {
                    "structured_list": ingredients_list,
                    "continuous_text": ", ".join(ingredients_list),
                }

        if "ì•Œë ˆë¥´ê¸°ì •ë³´" in df_dict:
            allergens_df = df_dict["ì•Œë ˆë¥´ê¸°ì •ë³´"]
            result["allergens"] = {}
            for _, row in allergens_df.iterrows():
                if row["í•­ëª©"] == "í•¨ìœ  ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ":
                    result["allergens"]["contains"] = row["ë‚´ìš©"].split(", ")
                elif row["í•­ëª©"] == "ì œì¡°ì‹œì„¤ ì•ˆë‚´":
                    result["allergens"]["manufacturing_facility"] = row["ë‚´ìš©"]

        if "ì˜ì–‘ì •ë³´" in df_dict:
            nutrition_df = df_dict["ì˜ì–‘ì •ë³´"]
            per_100g = {}
            for _, row in nutrition_df.iterrows():
                if row["ì˜ì–‘ì„±ë¶„"] == "ì´ ì—´ëŸ‰":
                    per_100g["calories"] = row["100g ë‹¹"]
                else:
                    per_100g[row["ì˜ì–‘ì„±ë¶„"]] = {
                        "amount": row["100g ë‹¹"],
                        "daily_value": row["1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)"],
                    }
            result["nutrition_info"] = {"per_100g": per_100g}

        if "ì œì¡°ì›ì •ë³´" in df_dict:
            result["manufacturer"] = df_dict["ì œì¡°ì›ì •ë³´"].to_dict("records")[0]

        if "ì£¼ì˜ì‚¬í•­" in df_dict:
            result["precautions"] = df_dict["ì£¼ì˜ì‚¬í•­"]["ì£¼ì˜ì‚¬í•­"].tolist()

        if "ì›ì¬ë£Œìƒì„¸" in df_dict:
            result["details"] = df_dict["ì›ì¬ë£Œìƒì„¸"].to_dict("records")

        return jsonify(result)
    except Exception as e:
        print("âŒ ì—‘ì…€ ì½ê¸° ì˜¤ë¥˜:", e)
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# 2ë‹¨ê³„: ë””ìì¸ ê²€ì¦ (OpenAI + í•˜ì´ë¼ì´íŠ¸)
@app.route("/api/verify-design", methods=["POST"])
def verify_design():
    print("ğŸ•µï¸â€â™‚ï¸ 2ë‹¨ê³„: ë””ìì¸ ê²€ì¦ ì‹œì‘...")

    design_file = request.files.get("design_file")
    standard_excel = request.files.get("standard_excel")
    standard_json = request.form.get("standard_data")

    if not design_file:
        return jsonify({"error": "ë””ìì¸ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    # ê¸°ì¤€ ë°ì´í„°: ì—‘ì…€ â†’ JSON
    if standard_excel:
        try:
            df_dict = pd.read_excel(
                io.BytesIO(standard_excel.read()),
                sheet_name=None,
                engine="openpyxl",
                dtype=str,
                keep_default_na=False,
            )
            first_sheet_name = list(df_dict.keys())[0]
            first_sheet_df = df_dict[first_sheet_name]
            standard_data = {}
            if not first_sheet_df.empty:
                col = first_sheet_df.columns[0]
                if "ì›ì¬ë£Œëª…" in first_sheet_df.columns:
                    col = "ì›ì¬ë£Œëª…"
                ingredients_list = first_sheet_df[col].dropna().astype(str).tolist()
                standard_data = {
                    "ingredients": {
                        "structured_list": ingredients_list,
                        "continuous_text": ", ".join(ingredients_list),
                    }
                }
            standard_json = json.dumps(standard_data, ensure_ascii=False)
        except Exception as e:
            return jsonify({"error": f"ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨: {str(e)}"}), 400

    if not standard_json:
        return jsonify({"error": "ê¸°ì¤€ ë°ì´í„°(standard_json)ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    try:
        design_bytes = design_file.read()
        design_file.seek(0)

        # PDFë©´ ì²« í˜ì´ì§€ ì´ë¯¸ì§€ë¡œ
        if design_file.mimetype == "application/pdf" and PDF2IMAGE_AVAILABLE:
            images = convert_from_bytes(design_bytes, dpi=200)
            if not images:
                return jsonify({"error": "PDFì—ì„œ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400
            img_io = io.BytesIO()
            images[0].save(img_io, format="PNG")
            design_image_bytes = img_io.getvalue()
        else:
            design_image_bytes = design_bytes

        # 1) OpenAI OCR
        ocr_text = ocr_bytes_with_openai(design_image_bytes)
        if not ocr_text:
            return jsonify({"error": "OCR ì‹¤íŒ¨"}), 500

        # 2) ê²€ì¦ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (í…ìŠ¤íŠ¸ ê¸°ë°˜)
        law_text = ""
        all_law_files = glob.glob("law_*.txt")
        for file_path in all_law_files:
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                    law_text += f"\n\n=== [ì°¸ê³  ë²•ë ¹: {file_path}] ===\n{content}\n==========================\n"
            except Exception as e:
                print(f"âš ï¸ ë²•ë ¹ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ ({file_path}): {e}")

        verify_prompt = f"""
ğŸš¨ğŸš¨ğŸš¨ ì ˆëŒ€ ê·œì¹™ ğŸš¨ğŸš¨ğŸš¨
- ë„ì–´ì“°ê¸° ì¤‘ìš”: "16 g" â‰  "16g"
- ìˆ«ì ê·¸ëŒ€ë¡œ: "221%" â†’ "221%"
- ì˜¤íƒ€ ê·¸ëŒ€ë¡œ: "ì „ë°˜ê°€ê³µí’ˆ" â†’ "ì „ë°˜ê°€ê³µí’ˆ"
- ì¶”ì¸¡ ê¸ˆì§€

{PROMPT_VERIFY_DESIGN}

[ì°¸ê³  ë²•ë ¹]
{law_text[:60000]}

[ê¸°ì¤€ ë°ì´í„°(Standard)]
{standard_json}

[ë””ìì¸ OCR í…ìŠ¤íŠ¸]
{ocr_text}
"""

        result_text = call_openai_from_parts([verify_prompt], json_mode=True).strip()

        # JSON ë¸”ë¡ ì œê±°
        if result_text.startswith("```json"):
            result_text = result_text[7:]
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        elif result_text.startswith("```"):
            lines = result_text.split("\n")
            if lines and lines[0].startswith("```"):
                lines = lines[1:]
            if lines and lines[-1].strip().startswith("```"):
                lines = lines[:-1]
            result_text = "\n".join(lines).strip()

        try:
            result = json.loads(result_text)
        except json.JSONDecodeError:
            # JSON íŒ¨í„´ë§Œ ë‹¤ì‹œ ì¶”ì¶œ ì‹œë„
            m = re.search(r"(\{.*\})", result_text, re.DOTALL)
            if m:
                clean_json = m.group(1)
                clean_json = clean_json.replace(",\n}", "\n}").replace(",\n]", "\n]")
                result = json.loads(clean_json)
            else:
                raise

        design_ocr_text = result.get("design_ocr_text") or ocr_text
        issues = result.get("issues", []) or []

        # í•˜ì´ë¼ì´íŠ¸ HTML ìƒì„±
        highlighted_html = highlight_ocr_errors(design_ocr_text, issues)

        # ì ìˆ˜ê°€ ì—†ìœ¼ë©´ ê°„ë‹¨íˆ ê³„ì‚°
        if "score" not in result:
            critical_count = sum(1 for i in issues if i.get("type") == "Critical")
            minor_count = sum(1 for i in issues if i.get("type") == "Minor")
            score = max(0, 100 - critical_count * 5 - minor_count * 2)
            result["score"] = score

        result["design_ocr_text"] = design_ocr_text
        result["design_ocr_highlighted_html"] = highlighted_html

        if "law_compliance" not in result:
            result["law_compliance"] = {
                "status": "compliant" if not issues else "violation",
                "violations": [],
            }

        return jsonify(result)

    except Exception as e:
        print("âŒ ê²€ì¦ ì˜¤ë¥˜:", e)
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# Python strict ë¹„êµ + í•˜ì´ë¼ì´íŠ¸
@app.route("/api/verify-design-strict", methods=["POST"])
def verify_design_strict():
    """Pythonìœ¼ë¡œ ê¸€ì ë‹¨ìœ„ ì •í™• ë¹„êµ (AIëŠ” OCRì—ë§Œ ì‚¬ìš©)"""
    try:
        design_file = request.files.get("design_file")
        standard_json = request.form.get("standard_data")

        if not design_file or not standard_json:
            return jsonify({"error": "íŒŒì¼ê³¼ ê¸°ì¤€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400

        design_bytes = design_file.read()
        design_file.seek(0)

        # PDF ì²˜ë¦¬
        if design_file.mimetype == "application/pdf" and PDF2IMAGE_AVAILABLE:
            images = convert_from_bytes(design_bytes, dpi=200)
            if not images:
                return jsonify({"error": "PDFì—ì„œ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400
            img_io = io.BytesIO()
            images[0].save(img_io, format="PNG")
            design_image_bytes = img_io.getvalue()
        else:
            design_image_bytes = design_bytes

        # 1) OCR (OpenAI)
        ocr_text = ocr_bytes_with_openai(design_image_bytes)
        if not ocr_text:
            return jsonify({"error": "OCR ì‹¤íŒ¨"}), 500

        # 2) Python strict ë¹„êµ
        standard_data = json.loads(standard_json)
        all_issues = []

        if "ingredients" in standard_data:
            std_text = standard_data["ingredients"].get("continuous_text", "")
        else:
            std_text = ""

        issues = compare_texts_strict(std_text, ocr_text)

        for issue in issues:
            all_issues.append({
                "type": "Critical" if issue["expected"] not in [" ", ",", "."] else "Minor",
                "location": f"ì›ì¬ë£Œëª… (ìœ„ì¹˜: {issue['position']})",
                "issue": f"'{issue['expected']}' â†’ '{issue['actual']}'",
                "expected": std_text,
                "actual": ocr_text,
                "suggestion": f"ìœ„ì¹˜ {issue['position']}ì˜ '{issue['actual']}'ì„(ë¥¼) '{issue['expected']}'(ìœ¼)ë¡œ ìˆ˜ì •",
            })

        critical_count = sum(1 for i in all_issues if i["type"] == "Critical")
        minor_count = sum(1 for i in all_issues if i["type"] == "Minor")
        score = max(0, 100 - critical_count * 5 - minor_count * 2)

        highlighted_html = highlight_ocr_errors(ocr_text, all_issues)

        return jsonify({
            "design_ocr_text": ocr_text,
            "design_ocr_highlighted_html": highlighted_html,
            "score": score,
            "issues": all_issues,
            "law_compliance": {"status": "compliant", "violations": []},
        })

    except Exception as e:
        print("âŒ verify_design_strict ì˜¤ë¥˜:", e)
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# QA ìë£Œ ì—…ë¡œë“œ + í‘œì‹œì‚¬í•­ ìƒì„±
@app.route("/api/upload-qa", methods=["POST"])
def upload_qa():
    print("ğŸ“‹ QA ìë£Œ ì—…ë¡œë“œ ë° ì‹í’ˆí‘œì‹œì‚¬í•­ ì‘ì„± ì‹œì‘...")

    qa_files = request.files.getlist("qa_files")
    if not qa_files:
        return jsonify({"error": "QA ìë£Œ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    qa_prompt = """
ë‹¹ì‹ ì€ ì‹í’ˆí‘œì‹œì‚¬í•­ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ QA ìë£Œë¥¼ ë¶„ì„í•˜ì—¬ ë²•ë¥ ì„ ì¤€ìˆ˜í•˜ëŠ” ì‹í’ˆí‘œì‹œì‚¬í•­ì„ ì‘ì„±í•˜ì„¸ìš”.

[ì¶œë ¥ ì–‘ì‹ - JSON]
{
    "product_name": "ì œí’ˆëª…",
    "label_text": "ì‘ì„±ëœ ì‹í’ˆí‘œì‹œì‚¬í•­ ì „ì²´ í…ìŠ¤íŠ¸",
    "law_compliance": {
        "status": "compliant" | "needs_review",
        "issues": ["ë²•ë¥  ê²€í†  ì‚¬í•­ ëª©ë¡"]
    },
    "sections": {
        "ingredients": "ì›ì¬ë£Œëª…",
        "nutrition": "ì˜ì–‘ì •ë³´",
        "allergens": "ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ",
        "storage": "ë³´ê´€ë°©ë²•",
        "manufacturer": "ì œì¡°ì‚¬ ì •ë³´"
    }
}
"""

    if ALL_LAW_TEXT:
        qa_prompt += f"\n\n--- [ì°¸ê³  ë²•ë ¹] ---\n{ALL_LAW_TEXT}\n--- [ë²•ë ¹ ë] ---\n"

    parts = [qa_prompt]

    for qa_file in qa_files[:20]:
        part = process_file_to_text_or_image(qa_file)
        if part is not None:
            parts.append(part)

    try:
        result_text = call_openai_from_parts(parts, json_mode=True).strip()

        if result_text.startswith("```json"):
            result_text = result_text[7:]
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        elif result_text.startswith("```"):
            lines = result_text.split("\n")
            if lines and lines[0].startswith("```"):
                lines = lines[1:]
            if lines and lines[-1].strip().startswith("```"):
                lines = lines[:-1]
            result_text = "\n".join(lines).strip()

        try:
            result = json.loads(result_text)
        except json.JSONDecodeError as json_err:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {json_err}")
            print(f"ì‘ë‹µ í…ìŠ¤íŠ¸ (ì²˜ìŒ 1000ì): {result_text[:1000]}")
            try:
                result_text_fixed = result_text.replace(",\n}", "\n}").replace(",\n]", "\n]")
                result = json.loads(result_text_fixed)
                print("âœ… JSON ìˆ˜ì • í›„ íŒŒì‹± ì„±ê³µ")
            except:
                return jsonify({"error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(json_err)}"}), 500

        return jsonify(result)

    except Exception as e:
        print("âŒ QA ì²˜ë¦¬ ì˜¤ë¥˜:", e)
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# ==============================
# ë©”ì¸ ì‹¤í–‰
# ==============================

if __name__ == "__main__":
    print("ğŸš€ ì‚¼ì§„ì–´ë¬µ ì‹í’ˆí‘œì‹œì‚¬í•­ ì™„ì„± í”Œë«í¼ (OpenAI í†µí•© ë²„ì „) ê°€ë™")
    print("   - OpenAI Vision OCR")
    print("   - ê¸°ì¤€ë°ì´í„° ìƒì„± + ê²€ì¦ + í•˜ì´ë¼ì´íŠ¸")
    from waitress import serve

    serve(app, host="0.0.0.0", port=8080)
