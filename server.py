import os
import json
import io
import glob
import pandas as pd
from flask import Flask, request, jsonify, render_template, send_file
from flask_cors import CORS
from dotenv import load_dotenv
import google.generativeai as genai
import PIL.Image
import re
import unicodedata

# --- ì„¤ì • ë° ì´ˆê¸°í™” ---
load_dotenv()

app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False
CORS(app)

# =========================
# ê³µí†µ ìœ í‹¸ & ì„¤ì •
# =========================

GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
if not GOOGLE_API_KEY:
    print("ğŸš¨ ê²½ê³ : .env íŒŒì¼ì— GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤!")
else:
    genai.configure(api_key=GOOGLE_API_KEY)

MODEL_NAME = 'gemini-1.5-flash'

# ëª¨ë“  í˜¸ì¶œì— ì‚¬ìš©í•  ê²°ì •ì  ì„¤ì •
STABLE_GENERATION_CONFIG = {
    "temperature": 0.0,
    "top_p": 0.0,          # 0ìœ¼ë¡œ ë‘ë©´ ì™„ì „ greedy
    "top_k": 1,
    "candidate_count": 1,
    "max_output_tokens": 32768,
    "response_mime_type": "application/json"
}


def get_model(extra_config: dict | None = None, system_instruction: str | None = None):
    """ê²°ì •ì  ì„¤ì •ìœ¼ë¡œ ëª¨ë¸ ìƒì„± (í•„ìš”ì‹œ config override ê°€ëŠ¥)"""
    gen_conf = STABLE_GENERATION_CONFIG.copy()
    if extra_config:
        gen_conf.update(extra_config)
    return genai.GenerativeModel(
        MODEL_NAME,
        generation_config=gen_conf,
        system_instruction=system_instruction
    )


def normalize_text_strict(text):
    """ì—„ê²©í•œ ë¹„êµìš© ì •ê·œí™” (ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ìœ ì§€)"""
    if not isinstance(text, str):
        text = str(text)
    return unicodedata.normalize('NFKC', text)


def compare_texts_strict(standard_text, design_text):
    """ë¬¸ì ë‹¨ìœ„ ì •í™• ë¹„êµ (AI ì—†ì´)"""
    std_norm = normalize_text_strict(standard_text)
    des_norm = normalize_text_strict(design_text)

    issues = []
    max_len = max(len(std_norm), len(des_norm))

    for i in range(max_len):
        std_char = std_norm[i] if i < len(std_norm) else '(ì—†ìŒ)'
        des_char = des_norm[i] if i < len(des_norm) else '(ì—†ìŒ)'

        if std_char != des_char:
            issues.append({
                "position": i,
                "expected": std_char,
                "actual": des_char,
                "context_before": std_norm[max(0, i - 5):i],
                "context_after": std_norm[i + 1:min(len(std_norm), i + 6)]
            })

    return issues


def safe_extract_json(text: str) -> str:
    """
    ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON ë¶€ë¶„ë§Œ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ.
    - ì²« ë²ˆì§¸ '{' ë¶€í„° ë§ˆì§€ë§‰ '}' ê¹Œì§€
    - í”í•œ trailing comma ë³´ì •
    """
    if not text:
        raise ValueError("ë¹ˆ ì‘ë‹µì…ë‹ˆë‹¤.")

    start = text.find('{')
    end = text.rfind('}')
    if start == -1 or end == -1 or end <= start:
        # JSON í˜•ì‹ì´ ì•„ë‹ˆë¼ê³  íŒë‹¨
        raise ValueError("JSON êµ¬ê°„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    candidate = text[start:end + 1]
    # ë‹¨ìˆœ ì‰¼í‘œ ë³´ì •
    candidate = candidate.replace(',\n}', '\n}').replace(',\n]', '\n]')
    candidate = candidate.replace(', }', ' }').replace(', ]', ' ]')
    return candidate.strip()


# =========================
# ë²•ë ¹ í…ìŠ¤íŠ¸ ë¡œë“œ
# =========================

def load_law_texts() -> str:
    """ë²•ë ¹ .txt íŒŒì¼ë“¤ì„ ëª¨ë‘ ì½ì–´ í•˜ë‚˜ì˜ í° í…ìŠ¤íŠ¸ë¡œ í•©ì¹©ë‹ˆë‹¤."""
    print("ğŸ“š ë²•ë ¹ íŒŒì¼ë“¤ì„ ì½ì–´ì˜¤ëŠ” ì¤‘...")
    law_files = glob.glob("law_text_*.txt") + glob.glob("../law_text_*.txt") + glob.glob("law_*.txt")

    if not law_files:
        print("âš ï¸ ë²•ë ¹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë²•ë¥  ê²€í†  ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return ""

    all_law_text = ""
    for file_path in law_files:
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                all_law_text += f"\n\n=== [ë²•ë ¹: {file_path}] ===\n"
                all_law_text += f.read()
    except Exception as e:
            print(f"âŒ ë²•ë ¹ íŒŒì¼ '{file_path}' ì½ê¸° ì‹¤íŒ¨: {e}")

    print(f"âœ… ëª¨ë“  ë²•ë ¹ íŒŒì¼ ë¡œë“œ ì™„ë£Œ (ì´ {len(all_law_text)}ì)")
    return all_law_text


ALL_LAW_TEXT = load_law_texts()[:60000]  # ê³¼ë„í•˜ê²Œ í¬ë©´ ì˜ë¼ì„œ ì‚¬ìš©


# =========================
# í”„ë¡¬í”„íŠ¸ ì •ì˜
# =========================

PROMPT_EXTRACT_INGREDIENT_INFO = """
ë‹¹ì‹ ì€ í•œêµ­ ì‹í’ˆ ë¼ë²¨ OCR ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì´ë¯¸ì§€ì—ì„œ ì›ë¶€ì¬ë£Œ í‘œì‹œì‚¬í•­ì„ **ì •í™•í•˜ê²Œ** ì¶”ì¶œí•˜ì„¸ìš”.
ì¶”ì¸¡í•˜ê±°ë‚˜ ì°½ì˜ì ìœ¼ë¡œ í•´ì„í•˜ì§€ ë§ê³ , ë³´ì´ëŠ” í…ìŠ¤íŠ¸ë§Œ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.

ğŸš¨ ì ˆëŒ€ ê·œì¹™ ğŸš¨
1. ì´ë¯¸ì§€ì— **ë³´ì´ëŠ” ê¸€ìë§Œ** ì¶”ì¶œ (ì¶”ë¡ /ë³´ì • ê¸ˆì§€)
2. **íŠ¹ìˆ˜ë¬¸ì(ì‰¼í‘œ, ì , ê´„í˜¸) ëˆ„ë½ë„ ê·¸ëŒ€ë¡œ** ì¶”ì¶œ
3. ì˜¤íƒ€, ë„ì–´ì“°ê¸°, íŠ¹ìˆ˜ë¬¸ì ëª¨ë‘ **ì •í™•íˆ ê·¸ëŒ€ë¡œ**
4. ë¬¸ë²•ì ìœ¼ë¡œ í‹€ë ¤ë„ **ì´ë¯¸ì§€ì™€ 100% ë™ì¼**í•˜ê²Œ

ë°˜ë“œì‹œ **JSONë§Œ** ì¶œë ¥í•˜ì„¸ìš”.
ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡(````), HTML íƒœê·¸, ì„¤ëª… ë¬¸êµ¬ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.

[ì¶œë ¥ í˜•ì‹]
{
  "ingredient_name": "ì›ì¬ë£Œëª…",
  "content_percentage": "í•¨ëŸ‰(%)",
  "sub_ingredients": "í•˜ìœ„ì›ì¬ë£Œ ë‚´ì—­ (ë³µí•©ì›ì¬ë£Œì¸ ê²½ìš°)",
  "origin": "ì›ì‚°ì§€ ì •ë³´",
  "allergens": ["ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ ëª©ë¡"],
  "additives": ["ì‹í’ˆì²¨ê°€ë¬¼ ëª©ë¡"],
  "raw_ocr_text": "ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œí•œ ì „ì²´ í…ìŠ¤íŠ¸ (ì›ë³¸ ê·¸ëŒ€ë¡œ)"
}
"""

PROMPT_EXTRACT_RAW_TEXT = """
ë‹¹ì‹ ì€ OCR ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ **ê¸°ê³„ì ìœ¼ë¡œ** ì¶”ì¶œí•˜ì„¸ìš”.

ğŸ¤– ê¸°ê³„ ëª¨ë“œ:
- ì² ì êµì •ê¸° OFF
- ë¬¸ë²• ê²€ì‚¬ê¸° OFF
- ìë™ ì™„ì„± OFF
- ì¶”ë¡  ì—”ì§„ OFF

ì¶œë ¥ ê·œì¹™:
1. ë³´ì´ëŠ” ê¸€ì â†’ ê·¸ëŒ€ë¡œ ì¶œë ¥
2. í‹€ë¦° ê¸€ì â†’ í‹€ë¦° ëŒ€ë¡œ ì¶œë ¥
3. ë¹ ì§„ ì‰¼í‘œ â†’ ë¹ ì§„ ëŒ€ë¡œ ì¶œë ¥
4. ì´ìƒí•œ ìˆ«ì â†’ ì´ìƒí•œ ëŒ€ë¡œ ì¶œë ¥

ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡, ì„¤ëª… ê¸ˆì§€.

ì˜ˆì‹œ:
- ì´ë¯¸ì§€: "ì „ë°˜ê°€ê³µí’ˆ" â†’ ì¶œë ¥: "ì „ë°˜ê°€ê³µí’ˆ"
- ì´ë¯¸ì§€: "ëŒ€ë‘ ê²Œ" â†’ ì¶œë ¥: "ëŒ€ë‘ ê²Œ"
- ì´ë¯¸ì§€: "221%" â†’ ì¶œë ¥: "221%"

JSON í˜•ì‹:
{
  "raw_text": "ìˆëŠ” ê·¸ëŒ€ë¡œì˜ í…ìŠ¤íŠ¸"
}
"""

PROMPT_CREATE_STANDARD = """
ë‹¹ì‹ ì€ ì‹í’ˆ ê·œì • ë° í‘œì‹œì‚¬í•­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ [ë°°í•©ë¹„ ë°ì´í„°(Excel)]ì™€ [ì›ì¬ë£Œ í‘œì‹œì‚¬í•­ ì‚¬ì§„ë“¤ì—ì„œ ì¶”ì¶œí•œ ì •ë³´]ë¥¼ ì¢…í•©í•˜ì—¬,
ë²•ì ìœ¼ë¡œ ì™„ë²½í•œ **'ì‹í’ˆí‘œì‹œì‚¬í•­ ê¸°ì¤€ ë°ì´í„°(Standard)'**ë¥¼ ì‹¤ì œ ë¼ë²¨ í˜•ì‹ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.

ë°˜ë“œì‹œ **JSONë§Œ** ì¶œë ¥í•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´/HTML/ì„¤ëª… ê¸ˆì§€.

[ë¶„ì„ ë‹¨ê³„]
1. Excelì˜ ë°°í•©ë¹„ìœ¨(%)ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì›ì¬ë£Œ ë‚˜ì—´.
2. Excel ì›ì¬ë£Œëª…ê³¼ ì´ë¯¸ì§€ ì›ì¬ë£Œ ë¼ë²¨ì„ ë§¤ì¹­í•´ ìƒì„¸ ì •ë³´ ë³´ê°•.
3. ì œê³µëœ ë²•ë ¹ì„ ì°¸ê³ í•´ ë²•ì  í•„ìˆ˜ í•­ëª©ì´ ëª¨ë‘ í¬í•¨ë˜ë„ë¡ êµ¬ì„±.
4. ì‹¤ì œ ë¼ë²¨ì— ì‚¬ìš©ë  ìˆ˜ ìˆëŠ” ì™„ì „í•œ êµ¬ì¡°ë¡œ ì •ë¦¬.

[ì¶œë ¥ í˜•ì‹ ìƒëµ, (í˜„ì¬ ì½”ë“œì™€ ë™ì¼)]
"""  # ì›ë˜ ê¸´ í¬ë§· ê·¸ëŒ€ë¡œ ì‚¬ìš© (ìƒëµ)

PROMPT_VERIFY_DESIGN = """
ë‹¹ì‹ ì€ ì‹í’ˆí‘œì‹œì‚¬í•­ ê°ì‚¬ AIì…ë‹ˆë‹¤.
Standard(ê¸°ì¤€ì„œ)ì™€ Design(ë””ìì¸ ì´ë¯¸ì§€/PDF)ì„ 1:1ë¡œ ì—„ê²©íˆ ë¹„êµí•˜ì—¬
ì ìˆ˜(score)ì™€ issuesë¥¼ JSONìœ¼ë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”.

ğŸš¨ ì¶œë ¥ ê·œì¹™ (ë§¤ìš° ì¤‘ìš”) ğŸš¨
- **ë°˜ë“œì‹œ JSONë§Œ** ì¶œë ¥
- ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡(````), HTML íƒœê·¸(<div> ë“±), ì„¤ëª… ë¬¸êµ¬ ì ˆëŒ€ ì¶œë ¥ ê¸ˆì§€
- JSON ì•ë’¤ì— ì–´ë–¤ í…ìŠ¤íŠ¸ë„ ë¶™ì´ì§€ ë§ ê²ƒ

[JSON ìŠ¤í‚¤ë§ˆ]
{
  "design_ocr_text": "ë””ìì¸ì—ì„œ ì¶”ì¶œí•œ ì „ì²´ í…ìŠ¤íŠ¸",
  "score": 0~100,
  "law_compliance": {
    "status": "compliant" | "violation",
    "violations": ["ë²•ë¥  ìœ„ë°˜ ì‚¬í•­ ëª©ë¡"]
  },
  "issues": [
    {
      "type": "Critical" | "Minor" | "Law_Violation",
      "location": "ìœ„ì¹˜ ì„¤ëª…",
      "issue": "ì˜¤ë¥˜ ì„¤ëª…",
      "expected": "ê¸°ì¤€ ë°ì´í„° ê°’",
      "actual": "ë””ìì¸ì—ì„œ ë°œê²¬ëœ ê°’",
      "suggestion": "ìˆ˜ì • ì œì•ˆ"
    }
  ]
}

ë¹„êµ ê¸°ì¤€, ê°ì  ê·œì¹™ ë“±ì€ ê¸°ì¡´ ì„¤ëª…ëŒ€ë¡œ ë”°ë¥´ë˜
**ì¶”ì¸¡/ë³´ì • ì—†ì´ Standardì™€ Designì˜ í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì ë‹¨ìœ„ë¡œ ë¹„êµ**í•˜ì„¸ìš”.
"""

QA_PROMPT = """
ë‹¹ì‹ ì€ ì‹í’ˆí‘œì‹œì‚¬í•­ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ QA ìë£Œë¥¼ ë¶„ì„í•˜ì—¬ ë²•ë¥ ì„ ì¤€ìˆ˜í•˜ëŠ” ì‹í’ˆí‘œì‹œì‚¬í•­ì„ ì‘ì„±í•˜ì„¸ìš”.

ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡/HTML/ì„¤ëª… ê¸ˆì§€.

[ì¶œë ¥ ì–‘ì‹ - JSON]
{
    "product_name": "ì œí’ˆëª…",
    "label_text": "ì‘ì„±ëœ ì‹í’ˆí‘œì‹œì‚¬í•­ ì „ì²´ í…ìŠ¤íŠ¸",
    "law_compliance": {
        "status": "compliant" | "needs_review",
        "issues": ["ë²•ë¥  ê²€í†  ì‚¬í•­ ëª©ë¡"]
    },
    "sections": {
        "ingredients": "ì›ì¬ë£Œëª…",
        "nutrition": "ì˜ì–‘ì •ë³´",
        "allergens": "ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ",
        "storage": "ë³´ê´€ë°©ë²•",
        "manufacturer": "ì œì¡°ì‚¬ ì •ë³´"
    }
}
"""


# =========================
# íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜
# =========================

def process_file_to_part(file_storage):
    """íŒŒì¼ì„ Geminiê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” Part ê°ì²´ë¡œ ë³€í™˜"""
    mime_type = file_storage.mimetype
    file_data = file_storage.read()
    file_storage.seek(0)

    # ì—‘ì…€ â†’ CSV í…ìŠ¤íŠ¸
    if mime_type in [
        'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
        'application/vnd.ms-excel'
    ]:
        try:
            df = pd.read_excel(io.BytesIO(file_data))
            csv_text = df.to_csv(index=False)
            return {"text": f"--- [Excel ë°°í•©ë¹„ ë°ì´í„°] ---\n{csv_text}"}
        except Exception as e:
            print(f"ì—‘ì…€ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None

    # ì´ë¯¸ì§€ â†’ PNG, ìµœì†Œ ì „ì²˜ë¦¬
    if mime_type.startswith('image/'):
        try:
            img = PIL.Image.open(io.BytesIO(file_data))

            # íˆ¬ëª… ë°°ê²½ ì œê±°
            if img.mode in ('RGBA', 'LA', 'P'):
                bg = PIL.Image.new('RGB', img.size, (255, 255, 255))
                if img.mode == 'P':
                    img = img.convert('RGBA')
                bg.paste(img, mask=img.split()[-1] if img.mode in ('RGBA', 'LA') else None)
                img = bg

            if img.mode != 'RGB':
                img = img.convert('RGB')

            w, h = img.size
            if w < 1200 or h < 1200:
                scale = max(1200 / w, 1200 / h)
                new_size = (int(w * scale), int(h * scale))
                img = img.resize(new_size, PIL.Image.LANCZOS)

            byte_io = io.BytesIO()
            img.save(byte_io, format="PNG", dpi=(300, 300))
            byte_io.seek(0)
            return {"mime_type": "image/png", "data": byte_io.read()}
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ (ì›ë³¸ ì‚¬ìš©): {e}")
            return {"mime_type": mime_type, "data": file_data}

    # ê·¸ ì™¸ ë°”ì´ë„ˆë¦¬ ê·¸ëŒ€ë¡œ
    return {"mime_type": mime_type, "data": file_data}


def extract_ingredient_info_from_image(image_file):
    """ì›ì¬ë£Œ í‘œì‹œì‚¬í•­ ì´ë¯¸ì§€ì—ì„œ í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ"""
    try:
        part = process_file_to_part(image_file)
        if not part:
            return None

        model = get_model(extra_config={"max_output_tokens": 4096})
        parts = [PROMPT_EXTRACT_INGREDIENT_INFO, part]

        response = model.generate_content(parts)
        raw_text = response.text.strip()
        json_str = safe_extract_json(raw_text)
        return json.loads(json_str)
    except Exception as e:
        print(f"ì›ì¬ë£Œ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return None


# =========================
# ì—‘ì…€ ìƒì„±/ì½ê¸°
# =========================

def create_standard_excel(data):
    """ê¸°ì¤€ ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ìƒì„±"""
    output = io.BytesIO()

    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        if 'product_info' in data:
            product_df = pd.DataFrame([data['product_info']])
            product_df.to_excel(writer, sheet_name='ì œí’ˆì •ë³´', index=False)

        if 'ingredients' in data:
            ingredients_data = []
            if 'structured_list' in data['ingredients']:
                for idx, item in enumerate(data['ingredients']['structured_list'], 1):
                    ingredients_data.append({'ìˆœë²ˆ': idx, 'ì›ì¬ë£Œëª…': item})
            if ingredients_data:
                pd.DataFrame(ingredients_data).to_excel(writer, sheet_name='ì›ì¬ë£Œëª…', index=False)

            if 'continuous_text' in data['ingredients']:
                pd.DataFrame([{
                    'ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸': data['ingredients']['continuous_text']
                }]).to_excel(writer, sheet_name='ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸', index=False)

        if 'allergens' in data:
            allergens_rows = []
            if 'contains' in data['allergens']:
                allergens_rows.append({
                    'í•­ëª©': 'í•¨ìœ  ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ',
                    'ë‚´ìš©': ', '.join(data['allergens']['contains'])
                })
            if 'manufacturing_facility' in data['allergens']:
                allergens_rows.append({
                    'í•­ëª©': 'ì œì¡°ì‹œì„¤ ì•ˆë‚´',
                    'ë‚´ìš©': data['allergens']['manufacturing_facility']
                })
            if allergens_rows:
                pd.DataFrame(allergens_rows).to_excel(writer, sheet_name='ì•Œë ˆë¥´ê¸°ì •ë³´', index=False)

        if 'nutrition_info' in data and 'per_100g' in data['nutrition_info']:
            nut = data['nutrition_info']['per_100g']
            rows = []
            if 'calories' in nut:
                rows.append({
                    'ì˜ì–‘ì„±ë¶„': 'ì´ ì—´ëŸ‰',
                    '100g ë‹¹': nut['calories'],
                    '1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)': '-'
                })
            for k, v in nut.items():
                if k == 'calories' or not isinstance(v, dict):
                    continue
                rows.append({
                    'ì˜ì–‘ì„±ë¶„': k,
                    '100g ë‹¹': v.get('amount', ''),
                    '1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)': v.get('daily_value', '')
                })
            if rows:
                pd.DataFrame(rows).to_excel(writer, sheet_name='ì˜ì–‘ì •ë³´', index=False)

        if 'manufacturer' in data:
            pd.DataFrame([data['manufacturer']]).to_excel(writer, sheet_name='ì œì¡°ì›ì •ë³´', index=False)

        if 'precautions' in data:
            pd.DataFrame([{'ì£¼ì˜ì‚¬í•­': t} for t in data['precautions']]).to_excel(
                writer, sheet_name='ì£¼ì˜ì‚¬í•­', index=False
            )

        if 'details' in data and data['details']:
            pd.DataFrame(data['details']).to_excel(writer, sheet_name='ì›ì¬ë£Œìƒì„¸', index=False)

    output.seek(0)
    return output


# =========================
# ë¼ìš°íŠ¸
# =========================

@app.route('/')
def index():
    return render_template('index.html')


# 1ë‹¨ê³„: ê¸°ì¤€ ë°ì´í„° ìƒì„±
@app.route('/api/create-standard', methods=['POST'])
def create_standard():
    print("âš™ï¸ 1ë‹¨ê³„: ê¸°ì¤€ ë°ì´í„° ìƒì„± ì‹œì‘...")

    excel_file = request.files.get('excel_file')
    raw_images = request.files.getlist('raw_images')

    if not excel_file:
        return jsonify({"error": "ë°°í•©ë¹„ ì—‘ì…€ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    parts = []

    prompt = PROMPT_CREATE_STANDARD
    if ALL_LAW_TEXT:
        prompt += f"\n\n--- [ì°¸ê³  ë²•ë ¹] ---\n{ALL_LAW_TEXT}\n--- [ë²•ë ¹ ë] ---\n"
    parts.append(prompt)

    excel_part = process_file_to_part(excel_file)
    if excel_part:
        parts.append(excel_part)

    ingredient_info_list = []
    # íŒŒì¼ëª… ê¸°ì¤€ ì •ë ¬ â†’ í•­ìƒ ê°™ì€ ìˆœì„œ
    for img in sorted(raw_images, key=lambda x: x.filename)[:15]:
        print(f"ğŸ“· ì›ì¬ë£Œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘: {img.filename}")
        info = extract_ingredient_info_from_image(img)
        if info:
            ingredient_info_list.append(info)

    if ingredient_info_list:
        text = "--- [ì›ì¬ë£Œ í‘œì‹œì‚¬í•­ì—ì„œ ì¶”ì¶œí•œ ì •ë³´] ---\n"
        for idx, info in enumerate(ingredient_info_list, 1):
            text += f"\n[ì›ì¬ë£Œ {idx}]\n"
            text += json.dumps(info, ensure_ascii=False, indent=2)
            text += "\n"
        text += "--- [ì›ì¬ë£Œ ì •ë³´ ë] ---\n"
        parts.append({"text": text})

    try:
        model = get_model()
        response = model.generate_content(parts)
        raw = response.text.strip()
        json_str = safe_extract_json(raw)
        result = json.loads(json_str)
        return jsonify(result)
    except Exception as e:
        print(f"âŒ ê¸°ì¤€ ë°ì´í„° ìƒì„± ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


@app.route('/api/download-standard-excel', methods=['POST'])
def download_standard_excel():
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "ê¸°ì¤€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

        excel_buffer = create_standard_excel(data)
        product_name = data.get('product_info', {}).get('product_name', 'ê¸°ì¤€ë°ì´í„°') or data.get('product_name', 'ê¸°ì¤€ë°ì´í„°')
        filename = f"{product_name}_ê¸°ì¤€ë°ì´í„°.xlsx"

        return send_file(
            excel_buffer,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name=filename
        )
    except Exception as e:
        print(f"âŒ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


@app.route('/api/read-standard-excel', methods=['POST'])
def read_standard_excel():
    try:
        excel_file = request.files.get('excel_file')
        if not excel_file:
            return jsonify({"error": "ì—‘ì…€ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        df_dict = pd.read_excel(
            io.BytesIO(excel_file.read()),
            sheet_name=None,
            engine='openpyxl',
            dtype=str,
            keep_default_na=False,
            na_filter=False
        )

        result = {}

        if 'ì œí’ˆì •ë³´' in df_dict:
            result['product_info'] = df_dict['ì œí’ˆì •ë³´'].to_dict('records')[0]

        first_sheet_name = list(df_dict.keys())[0]
        first_sheet_df = df_dict[first_sheet_name]

        if 'ì›ì¬ë£Œëª…' in df_dict:
            lst = df_dict['ì›ì¬ë£Œëª…']['ì›ì¬ë£Œëª…'].tolist()
            result['ingredients'] = {
                'structured_list': lst,
                'continuous_text': ', '.join(lst)
            }
        elif 'ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸' in df_dict:
            cont = df_dict['ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸']['ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸'].iloc[0]
            result['ingredients'] = {
                'structured_list': cont.split(', '),
                'continuous_text': cont
            }
        elif not first_sheet_df.empty:
            col = 'ì›ì¬ë£Œëª…' if 'ì›ì¬ë£Œëª…' in first_sheet_df.columns else first_sheet_df.columns[0]
            lst = first_sheet_df[col].astype(str).tolist()
            result['ingredients'] = {
                'structured_list': lst,
                'continuous_text': ', '.join(lst)
            }

        if 'ì•Œë ˆë¥´ê¸°ì •ë³´' in df_dict:
            al_df = df_dict['ì•Œë ˆë¥´ê¸°ì •ë³´']
            result['allergens'] = {}
            for _, row in al_df.iterrows():
                if row['í•­ëª©'] == 'í•¨ìœ  ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ':
                    result['allergens']['contains'] = row['ë‚´ìš©'].split(', ')
                elif row['í•­ëª©'] == 'ì œì¡°ì‹œì„¤ ì•ˆë‚´':
                    result['allergens']['manufacturing_facility'] = row['ë‚´ìš©']

        if 'ì˜ì–‘ì •ë³´' in df_dict:
            ndf = df_dict['ì˜ì–‘ì •ë³´']
            per_100g = {}
            for _, row in ndf.iterrows():
                if row['ì˜ì–‘ì„±ë¶„'] == 'ì´ ì—´ëŸ‰':
                    per_100g['calories'] = row['100g ë‹¹']
                else:
                    per_100g[row['ì˜ì–‘ì„±ë¶„']] = {
                        'amount': row['100g ë‹¹'],
                        'daily_value': row['1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)']
                    }
            result['nutrition_info'] = {'per_100g': per_100g}

        if 'ì œì¡°ì›ì •ë³´' in df_dict:
            result['manufacturer'] = df_dict['ì œì¡°ì›ì •ë³´'].to_dict('records')[0]

        if 'ì£¼ì˜ì‚¬í•­' in df_dict:
            result['precautions'] = df_dict['ì£¼ì˜ì‚¬í•­']['ì£¼ì˜ì‚¬í•­'].tolist()

        if 'ì›ì¬ë£Œìƒì„¸' in df_dict:
            result['details'] = df_dict['ì›ì¬ë£Œìƒì„¸'].to_dict('records')

        return jsonify(result)
    except Exception as e:
        print(f"âŒ ì—‘ì…€ ì½ê¸° ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# 2ë‹¨ê³„: ë””ìì¸ ê²€ì¦ (AI)
@app.route('/api/verify-design', methods=['POST'])
def verify_design():
    print("ğŸ•µï¸â€â™‚ï¸ 2ë‹¨ê³„: ë””ìì¸ ê²€ì¦ ì‹œì‘...")

    design_file = request.files.get('design_file')
    standard_excel = request.files.get('standard_excel')
    standard_json = request.form.get('standard_data')

    if not design_file:
        return jsonify({"error": "ë””ìì¸ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    if standard_excel:
        try:
            df_dict = pd.read_excel(
                io.BytesIO(standard_excel.read()),
                sheet_name=None,
                engine='openpyxl',
                dtype=str,
                keep_default_na=False
            )
            first_sheet_name = list(df_dict.keys())[0]
            first_sheet_df = df_dict[first_sheet_name]
            std_data = {}

            if not first_sheet_df.empty:
                col = 'ì›ì¬ë£Œëª…' if 'ì›ì¬ë£Œëª…' in first_sheet_df.columns else first_sheet_df.columns[0]
                lst = first_sheet_df[col].astype(str).tolist()
                std_data = {'ingredients': {'structured_list': lst, 'continuous_text': ', '.join(lst)}}

            standard_json = json.dumps(std_data, ensure_ascii=False)
        except Exception as e:
            return jsonify({"error": f"ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨: {str(e)}"}), 400

    if not standard_json:
        return jsonify({"error": "ê¸°ì¤€ ë°ì´í„°(ì—‘ì…€ ë˜ëŠ” JSON)ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    design_file.seek(0)

    prompt = f"""
{PROMPT_VERIFY_DESIGN}

[ì°¸ê³  ë²•ë ¹]
{ALL_LAW_TEXT}

[ê¸°ì¤€ ë°ì´í„°(Standard)]
{standard_json}
"""

    parts = [prompt]
    parts.append(process_file_to_part(design_file))

    try:
        system_instruction = """
ë‹¹ì‹ ì€ ì •ë°€í•œ OCR ë° ë¼ë²¨ ê²€ì¦ AIì…ë‹ˆë‹¤.
- ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ë¥¼ ë³´ì •í•˜ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ì‚¬ìš©.
- Standardì™€ Designì˜ í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì ë‹¨ìœ„ë¡œ ë¹„êµ.
- ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥.
"""
        model = get_model(system_instruction=system_instruction)
        response = model.generate_content(parts)
        raw = response.text.strip()
        json_str = safe_extract_json(raw)
        result = json.loads(json_str)
        return jsonify(result)
    except Exception as e:
        print(f"âŒ ê²€ì¦ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# 2ë‹¨ê³„: Python ì—„ê²© ë¹„êµìš© (ì˜µì…˜)
@app.route('/api/verify-design-strict', methods=['POST'])
def verify_design_strict():
    """Pythonìœ¼ë¡œ ì •í™•í•œ ë¹„êµ (AI ìµœì†Œ ì‚¬ìš©)"""
    try:
        design_file = request.files.get('design_file')
        standard_json = request.form.get('standard_data')

        if not design_file or not standard_json:
            return jsonify({"error": "íŒŒì¼ê³¼ ê¸°ì¤€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400

        design_file.seek(0)
        standard_data = json.loads(standard_json)

        # 1. ìˆœìˆ˜ OCR
        parts = [PROMPT_EXTRACT_RAW_TEXT, process_file_to_part(design_file)]
        model = get_model(extra_config={"max_output_tokens": 4096})
        response = model.generate_content(parts)
        raw = response.text.strip()
        json_str = safe_extract_json(raw)
        design_ocr = json.loads(json_str)

        # 2. Python strict ë¹„êµ
        all_issues = []
        std_text = ""
        if 'ingredients' in standard_data:
            std_text = standard_data['ingredients'].get('continuous_text', '')
        des_text = design_ocr.get('raw_text', '')

        issues = compare_texts_strict(std_text, des_text)
        for issue in issues:
            all_issues.append({
                "type": "Critical" if issue['expected'] not in [' ', ',', '.'] else "Minor",
                "location": f"ì›ì¬ë£Œëª… (ìœ„ì¹˜: {issue['position']})",
                "issue": f"'{issue['expected']}' â†’ '{issue['actual']}'",
                "expected": std_text,
                "actual": des_text,
                "suggestion": f"ìœ„ì¹˜ {issue['position']}ì˜ '{issue['actual']}'ì„(ë¥¼) '{issue['expected']}'(ìœ¼)ë¡œ ìˆ˜ì •"
            })

        critical_count = sum(1 for i in all_issues if i['type'] == 'Critical')
        minor_count = sum(1 for i in all_issues if i['type'] == 'Minor')
        score = max(0, 100 - critical_count * 5 - minor_count * 2)

        return jsonify({
            "design_ocr_text": des_text,
            "score": score,
            "issues": all_issues,
            "law_compliance": {"status": "compliant", "violations": []}
        })

    except Exception as e:
        print(f"âŒ verify_design_strict ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# QA ìë£Œ ì—…ë¡œë“œ ë° ì‹í’ˆí‘œì‹œì‚¬í•­ ì‘ì„±
@app.route('/api/upload-qa', methods=['POST'])
def upload_qa():
    print("ğŸ“‹ QA ìë£Œ ì—…ë¡œë“œ ë° ì‹í’ˆí‘œì‹œì‚¬í•­ ì‘ì„± ì‹œì‘...")

    qa_files = request.files.getlist('qa_files')
    if not qa_files:
        return jsonify({"error": "QA ìë£Œ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    parts = [QA_PROMPT]
    for f in qa_files[:20]:
        part = process_file_to_part(f)
        if part:
            parts.append(part)

    try:
        model = get_model()
        response = model.generate_content(parts)
        raw = response.text.strip()
        json_str = safe_extract_json(raw)
        result = json.loads(json_str)
        return jsonify(result)
    except Exception as e:
        print(f"âŒ QA ìë£Œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# =========================
# ì„œë²„ ì‹¤í–‰
# =========================

if __name__ == '__main__':
    print("ğŸš€ ì‚¼ì§„ì–´ë¬µ ì‹í’ˆí‘œì‹œì‚¬í•­ í”Œë«í¼ (ê²°ì •ì  ëª¨ë“œ) ê°€ë™")
    from waitress import serve
    port = int(os.environ.get("PORT", 8080))
    serve(app, host="0.0.0.0", port=port)
