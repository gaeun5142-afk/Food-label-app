import os
import json
import io
import glob
import traceback
import base64
import difflib

import pandas as pd
from flask import Flask, request, jsonify
from flask_cors import CORS
from dotenv import load_dotenv
from openai import OpenAI
import PIL.Image
import re
import html

# Optional OCR fallback (if installed)
try:
    import pytesseract
    TESSERACT_AVAILABLE = True
except Exception:
    TESSERACT_AVAILABLE = False

# Optional PDF->Image (if installed)
try:
    from pdf2image import convert_from_bytes
    PDF2IMAGE_AVAILABLE = True
except Exception:
    PDF2IMAGE_AVAILABLE = False

# --- ì„¤ì • ë° ì´ˆê¸°í™” ---
load_dotenv()
app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False  # í•œê¸€ ê¹¨ì§ ë°©ì§€
CORS(app)

# âœ… OpenAI API ì„¤ì • (ë¬´ì¡°ê±´ ChatGPTë§Œ ì‚¬ìš©)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    print("ğŸš¨ ê²½ê³ : .env íŒŒì¼ì— OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤!")
    client = None
else:
    client = OpenAI(api_key=OPENAI_API_KEY)

# ChatGPT ë©€í‹°ëª¨ë‹¬ ëª¨ë¸
MODEL_NAME = "gpt-4.1-mini"   # í…ìŠ¤íŠ¸+ì´ë¯¸ì§€ ëª¨ë‘ ì§€ì›


# --- ê³µí†µ OpenAI í˜¸ì¶œ í—¬í¼ ---

def to_image_data_url(img_bytes: bytes, mime_type: str = "image/png") -> str:
    """ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ë¥¼ data URL(base64)ë¡œ ë³€í™˜"""
    b64 = base64.b64encode(img_bytes).decode("utf-8")
    return f"data:{mime_type};base64,{b64}"


def call_openai_from_parts(parts, json_mode: bool = True) -> str:
    """
    OpenAI Responses API í˜¸ì¶œ.
    - parts: ë¬¸ìì—´, PIL.Image.Image ì„ì—¬ ìˆëŠ” ë¦¬ìŠ¤íŠ¸
    - json_mode: Trueë©´ "JSONë§Œ ì¶œë ¥"ì´ë¼ê³  ì‹œìŠ¤í…œ ì§€ì‹œë¥¼ ì•ì— ë¶™ì„
    - ë°˜í™˜ê°’: ChatGPTê°€ ë°˜í™˜í•œ í…ìŠ¤íŠ¸ ì „ì²´ (string)
    """
    if client is None:
        raise RuntimeError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

    content = []

    if json_mode:
        # JSON ê°•ì œ ì§€ì‹œ
        content.append({
            "type": "input_text",
            "text": (
                "í•­ìƒ ìœ íš¨í•œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. "
                "ë§ˆí¬ë‹¤ìš´, ì½”ë“œë¸”ë¡, ì„¤ëª… ë¬¸ì¥ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
            ),
        })

    for p in parts:
        if isinstance(p, str):
            content.append({"type": "input_text", "text": p})
        elif isinstance(p, PIL.Image.Image):
            buf = io.BytesIO()
            fmt = p.format if p.format else "PNG"
            p.save(buf, format=fmt)
            buf.seek(0)
            data_url = to_image_data_url(buf.getvalue(), mime_type=f"image/{fmt.lower()}")
            content.append({
                "type": "input_image",
                "image_url": {"url": data_url},
            })
        else:
            # dict ë“± ê¸°íƒ€ íƒ€ì…ì€ í•„ìš”ì‹œ í™•ì¥
            pass

    resp = client.responses.create(
        model=MODEL_NAME,
        input=[{"role": "user", "content": content}],
        temperature=0.0,
        max_output_tokens=32768,
    )

    # text ê²°ê³¼ë§Œ ëª¨ìœ¼ê¸° (Responses API output êµ¬ì¡° ê¸°ì¤€)
    result_chunks = []
    for out in getattr(resp, "output", []):
        for c in getattr(out, "content", []):
            if getattr(c, "type", None) == "output_text" and getattr(c, "text", None):
                result_chunks.append(c.text)
    result_text = "".join(result_chunks).strip()
    return result_text


# --- ë²•ë ¹ í…ìŠ¤íŠ¸ ë¡œë“œ ---
def load_law_texts() -> str:
    print("ğŸ“š ë²•ë ¹ íŒŒì¼ë“¤ì„ ì½ì–´ì˜¤ëŠ” ì¤‘...")
    law_files = glob.glob("law_text_*.txt") + glob.glob("../law_text_*.txt")
    if not law_files:
        print("âš ï¸ ë²•ë ¹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë²•ë¥  ê²€í†  ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return ""
    all_law_text = ""
    for file_path in law_files:
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                all_law_text += f"--- ë²•ë ¹ [{file_path}] ì‹œì‘ ---\n\n"
                all_law_text += f.read()
                all_law_text += f"\n\n--- ë²•ë ¹ [{file_path}] ë ---\n\n"
            print(f"âœ… ë²•ë ¹ íŒŒì¼ '{file_path}' ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ë²•ë ¹ íŒŒì¼ '{file_path}' ì½ê¸° ì‹¤íŒ¨: {e}")
    print(f"âœ… ëª¨ë“  ë²•ë ¹ íŒŒì¼ ë¡œë“œ ì™„ë£Œ (ì´ {len(all_law_text)}ì)")
    return all_law_text


ALL_LAW_TEXT = load_law_texts()

# âœ… í•˜ì´ë¼ì´íŠ¸ ìƒì„± í•¨ìˆ˜
def highlight_matches(ocr_text: str, matches: list) -> str:
    """
    ocr_text ì•ˆì—ì„œ matches ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” í…ìŠ¤íŠ¸ë“¤ì„
    ë¹¨ê°„ í•˜ì´ë¼ì´íŠ¸ spanìœ¼ë¡œ ê°ì‹¸ì„œ ë°˜í™˜
    """
    # HTML íŠ¹ìˆ˜ ë¬¸ì ì´ìŠ¤ì¼€ì´í”„ (ì•ˆ í•˜ë©´ < > ë“±ì´ ê¹¨ì§)
    escaped_text = html.escape(ocr_text)

    for word in matches:
        if not word:
            continue
        word_escaped = html.escape(word)
        pattern = re.escape(word_escaped)
        repl = f'<span class="highlight-violation">{word_escaped}</span>'
        escaped_text = re.sub(pattern, repl, escaped_text, flags=re.IGNORECASE)

    return escaped_text


# âœ… ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸ ì˜ˆì‹œ
@app.route("/api/verify-design", methods=["POST"])
def verify_design():
    try:
        file = request.files.get("file")
        if not file:
            return jsonify({"error": "íŒŒì¼ ì—†ìŒ"}), 400

        file_bytes = file.read()
        img = PIL.Image.open(io.BytesIO(file_bytes))

        # 1ï¸âƒ£ OCR ìˆ˜í–‰ (ê°„ë‹¨íˆ)
        if TESSERACT_AVAILABLE:
            ocr_text = pytesseract.image_to_string(img, lang="kor+eng").strip()
            print("ğŸ” OCR TEXT:")
            print(ocr_text)

        else:
            ocr_text = "OCR ê²°ê³¼ ì—†ìŒ (Tesseract ë¯¸ì„¤ì¹˜)"

        # 2ï¸âƒ£ OpenAI ì‘ë‹µ (ê°„ë‹¨ ì˜ˆì‹œ)
        prompt = f"ë‹¤ìŒ ì‹í’ˆ ë¼ë²¨ ë‚´ìš©ì„ í™•ì¸í•˜ê³  ì˜¬ë°”ë¥´ê²Œ ìˆ˜ì •í•˜ê±°ë‚˜ ê·œì • ìœ„ë°˜ ì—¬ë¶€ë¥¼ ì•Œë ¤ì¤˜:\n\n{ocr_text}\n\n{ALL_LAW_TEXT}"
        gpt_response = call_openai_from_parts([prompt])
        print("ğŸ“© GPT RESPONSE:")
        print(gpt_response)

        try:
            gpt_json = json.loads(gpt_response)
            label_text = gpt_json.get("label_text", "")
        except:
            label_text = gpt_response  # ì‹¤íŒ¨ ì‹œ ì „ì²´ ì‘ë‹µ ì‚¬ìš©
         # âœ… ì—¬ê¸°ì— ë””ë²„ê¹… print ì¶”ê°€
        print("ğŸ” OCR TEXT:")
        print(ocr_text)

        print("ğŸ§¾ GPT ì‘ë‹µ ì „ì²´:")
        print(gpt_response)

        print("âœ… label_text í¬í•¨ ì—¬ë¶€:", label_text in ocr_text)
        print("ğŸ–ï¸ HIGHLIGHTED HTML:")
        print(highlight_matches(ocr_text, [label_text]))

        # 3ï¸âƒ£ ë¹¨ê°„íœ í•˜ì´ë¼ì´íŠ¸ ìƒì„±
       highlighted_html = highlight_matches(ocr_text, [label_text])

        return jsonify({
            "design_ocr_text": ocr_text,
            "design_ocr_highlighted_html": highlighted_html,
            "label_text": label_text
        })

    except Exception as e:
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8080)

# --- í”„ë¡¬í”„íŠ¸ (ì§€ì‹œì‚¬í•­) ---
PR
