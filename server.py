import os
import io
import json
import glob
import traceback
from dotenv import load_dotenv
from flask import Flask, request, jsonify, render_template, send_file
from flask_cors import CORS
import pandas as pd
import google.generativeai as genai
import PIL.Image
import re
import html
from io import BytesIO

# Optional OCR fallback libraries (install if available)
try:
    import pytesseract
    TESSERACT_AVAILABLE = True
except Exception:
    TESSERACT_AVAILABLE = False

try:
    from pdf2image import convert_from_bytes
    PDF2IMAGE_AVAILABLE = True
except Exception:
    PDF2IMAGE_AVAILABLE = False

# --- ì„¤ì • ë° ì´ˆê¸°í™” ---
load_dotenv()
app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False
CORS(app)

GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
if not GOOGLE_API_KEY:
    print("ğŸš¨ ê²½ê³ : .env íŒŒì¼ì— GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤!")
else:
    genai.configure(api_key=GOOGLE_API_KEY)

MODEL_NAME = 'gemini-1.5-flash'

def check_available_models():
    global MODEL_NAME
    try:
        models = genai.list_models()
        available_models = []
        print("\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡:")
        for m in models:
            if hasattr(m, "supported_generation_methods") and 'generateContent' in m.supported_generation_methods:
                model_name = m.name.replace('models/', '')
                available_models.append(model_name)
                print(f"   - {model_name}")
        for model in available_models:
            if 'flash' in model.lower():
                MODEL_NAME = model
                print(f"\nâœ… ì¶”ì²œ ëª¨ë¸ ì„ íƒ: {MODEL_NAME}\n")
                return MODEL_NAME
        for model in available_models:
            if 'pro' in model.lower():
                MODEL_NAME = model
                print(f"\nâœ… Pro ëª¨ë¸ ì„ íƒ: {MODEL_NAME}\n")
                return MODEL_NAME
        if available_models:
            MODEL_NAME = available_models[0]
            print(f"\nâœ… ì²« ë²ˆì§¸ ëª¨ë¸ ì„ íƒ: {MODEL_NAME}\n")
            return MODEL_NAME
        print(f"\nâš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ ì‚¬ìš©: {MODEL_NAME}\n")
        return None
    except Exception as e:
        print(f"âš ï¸ ëª¨ë¸ ëª©ë¡ í™•ì¸ ì‹¤íŒ¨: {e}")
        print(f"âš ï¸ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©: {MODEL_NAME}\n")
        return None

if GOOGLE_API_KEY:
    check_available_models()
else:
    print(f"âš ï¸ API í‚¤ê°€ ì—†ì–´ ëª¨ë¸ í™•ì¸ì„ ê±´ë„ˆëœë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©: {MODEL_NAME}\n")

# --- ë²•ë ¹ í…ìŠ¤íŠ¸ ë¡œë“œ ---
def load_law_texts() -> str:
    print("ğŸ“š ë²•ë ¹ íŒŒì¼ë“¤ì„ ì½ì–´ì˜¤ëŠ” ì¤‘...")
    law_files = glob.glob("law_text_*.txt") + glob.glob("../law_text_*.txt")
    if not law_files:
        print("âš ï¸ ë²•ë ¹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë²•ë¥  ê²€í†  ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return ""
    all_law_text = ""
    for file_path in law_files:
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                all_law_text += f"--- ë²•ë ¹ [{file_path}] ì‹œì‘ ---\n\n"
                all_law_text += f.read()
                all_law_text += f"\n\n--- ë²•ë ¹ [{file_path}] ë ---\n\n"
            print(f"âœ… ë²•ë ¹ íŒŒì¼ '{file_path}' ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ë²•ë ¹ íŒŒì¼ '{file_path}' ì½ê¸° ì‹¤íŒ¨: {e}")
    print(f"âœ… ëª¨ë“  ë²•ë ¹ íŒŒì¼ ë¡œë“œ ì™„ë£Œ (ì´ {len(all_law_text)}ì)")
    return all_law_text

ALL_LAW_TEXT = load_law_texts()

# --- PROMPTS: (ì›ë³¸ ê¸¸ì´ ê·¸ëŒ€ë¡œ ìœ ì§€) ---
PROMPT_EXTRACT_INGREDIENT_INFO = """
ì´ ì´ë¯¸ì§€ëŠ” ì›ë¶€ì¬ë£Œ í‘œì‹œì‚¬í•­ ì‚¬ì§„ì…ë‹ˆë‹¤. 
**í•„ìˆ˜ì ìœ¼ë¡œ ì¶”ì¶œí•´ì•¼ í•  ì •ë³´ë§Œ** ì¶”ì¶œí•˜ì„¸ìš”.

[ì¶”ì¶œí•´ì•¼ í•  ì •ë³´]
1. **ì›ì¬ë£Œëª…**: ì›ì¬ë£Œì˜ ì •í™•í•œ ëª…ì¹­
2. **ë³µí•©ì›ì¬ë£Œ ë‚´ì—­**: ê´„í˜¸ ì•ˆì˜ í•˜ìœ„ ì›ì¬ë£Œ ì •ë³´ (ì˜ˆ: (íƒˆì§€ëŒ€ë‘, ì†Œë§¥))
3. **ì›ì‚°ì§€ ì •ë³´**: ì›ì‚°ì§€ í‘œê¸° (ì˜ˆ: ì™¸êµ­ì‚°, êµ­ë‚´ì‚°, ì¸ë„ì‚° ë“±)
4. **ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ**: ì•Œë ˆë¥´ê¸° í‘œì‹œ ì •ë³´
5. **ì‹í’ˆì²¨ê°€ë¬¼**: ì²¨ê°€ë¬¼ëª…ê³¼ ìš©ë„ ë³‘ê¸° ì—¬ë¶€

[ì¶”ì¶œí•˜ì§€ ë§ì•„ì•¼ í•  ì •ë³´]
- ë³´ê´€ë°©ë²• (ì˜ˆ: ëƒ‰ì¥ë³´ê´€, ì‹¤ì˜¨ë³´ê´€ ë“±)
- í¬ì¥ì¬ì§ˆ ì •ë³´
- ë¶„ë¦¬ë°°ì¶œ ë§ˆí¬
- ë°”ì½”ë“œ ë²ˆí˜¸
- ì œì¡°ì¼ì/ìœ í†µê¸°í•œ
- ë‹¨ìˆœ í™ë³´ ë¬¸êµ¬
- ê¸°íƒ€ í‘œì‹œì‚¬í•­ê³¼ ë¬´ê´€í•œ ì •ë³´

[ì¶œë ¥ í˜•ì‹]
JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{
    "ingredient_name": "ì›ì¬ë£Œëª…",
    "sub_ingredients": "í•˜ìœ„ì›ì¬ë£Œ ë‚´ì—­ (ë³µí•©ì›ì¬ë£Œì¸ ê²½ìš°)",
    "origin": "ì›ì‚°ì§€ ì •ë³´",
    "allergens": ["ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ ëª©ë¡"],
    "additives": ["ì‹í’ˆì²¨ê°€ë¬¼ ëª©ë¡"]
}

ì›ì¬ë£Œëª…ì´ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ "ingredient_name"ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë‘ì„¸ìš”.
"""

PROMPT_CREATE_STANDARD = """
ë‹¹ì‹ ì€ ì‹í’ˆ ê·œì • ë° í‘œì‹œì‚¬í•­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ [ë°°í•©ë¹„ ë°ì´í„°(Excel)]ì™€ [ì›ì¬ë£Œ í‘œì‹œì‚¬í•­ ì‚¬ì§„ë“¤ì—ì„œ ì¶”ì¶œí•œ ì •ë³´]ë¥¼ ì¢…í•©í•˜ì—¬,
ë²•ì ìœ¼ë¡œ ì™„ë²½í•œ **'ì‹í’ˆí‘œì‹œì‚¬í•­ ê¸°ì¤€ ë°ì´í„°(Standard)'**ë¥¼ ì‹¤ì œ ë¼ë²¨ í˜•ì‹ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.

[ë¶„ì„ ë‹¨ê³„]
1. **Excel ë°ì´í„° ë¶„ì„**: ë°°í•©ë¹„ìœ¨(%)ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì›ì¬ë£Œ ë‚˜ì—´ ìˆœì„œë¥¼ ê²°ì •í•˜ì„¸ìš”. (ê°€ì¥ ì¤‘ìš”)
2. **ì´ë¯¸ì§€ ë°ì´í„° ë§¤í•‘**: Excelì— ì íŒ ì›ì¬ë£Œëª…(ì˜ˆ: 'ê°„ì¥')ì— í•´ë‹¹í•˜ëŠ” ì‚¬ì§„(ì›ì¬ë£Œ ë¼ë²¨)ì„ ì°¾ì•„ì„œ ìƒì„¸ ì •ë³´(ë³µí•©ì›ì¬ë£Œ ë‚´ì—­, ì•Œë ˆë¥´ê¸°, ì›ì‚°ì§€)ë¥¼ ë³´ê°•í•˜ì„¸ìš”.
    - ì˜ˆ: Excelì—” 'ê°„ì¥'ë§Œ ìˆì§€ë§Œ, ì‚¬ì§„ì— 'íƒˆì§€ëŒ€ë‘(ì¸ë„ì‚°), ì†Œë§¥(ë°€)'ì´ ìˆë‹¤ë©´ ì´ë¥¼ ë°˜ì˜í•´ì•¼ í•¨.
    - **ì¤‘ìš”**: ë³´ê´€ë°©ë²•, í¬ì¥ì¬ì§ˆ ë“±ì€ ë¬´ì‹œí•˜ê³  ì›ì¬ë£Œ ê´€ë ¨ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.
3. **ë²•ë¥  ê²€í† **: ì œê³µëœ ë²•ë ¹ì„ ì°¸ê³ í•˜ì—¬ í‘œì‹œì‚¬í•­ì´ ë²•ì ìœ¼ë¡œ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.
4. **ìµœì¢… ì¡°í•©**: í’ˆëª©ì œì¡°ë³´ê³ ì„œ ê¸°ë°˜ì˜ ë¹„ìœ¨ê³¼ ì›ì¬ë£Œ ë¼ë²¨ì˜ ìƒì„¸ ë‚´ìš©ì„ í•©ì³ ìµœì¢… í‘œì‹œ í…ìŠ¤íŠ¸ë¥¼ ë§Œë“œì„¸ìš”.

[ì¶œë ¥ ì–‘ì‹ - JSON]
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì‹¤ì œ ì‹í’ˆ ë¼ë²¨ í˜•ì‹ì²˜ëŸ¼ êµ¬ì¡°í™”í•˜ì„¸ìš”.
{
    "product_info": {
        "product_name": "ì œí’ˆëª…",
        "food_type": "ì‹í’ˆì˜ ìœ í˜• (ì˜ˆ: ì–´ë¬µ(ìœ íƒ•ì²˜ë¦¬ì œí’ˆ/ë¹„ì‚´ê· ))",
        "net_weight": "ë‚´ìš©ëŸ‰ (ì˜ˆ: 1kg)",
        "expiration_date": "ì†Œë¹„ê¸°í•œ (ì˜ˆ: ì „ë©´ ë³„ë„í‘œì‹œì¼ê¹Œì§€)",
        "storage_method": "ë³´ê´€ë°©ë²• (ì˜ˆ: 0~10â„ƒì´í•˜ ëƒ‰ì¥ë³´ê´€)",
        "packaging_material": "í¬ì¥ì¬ì§ˆ (ì˜ˆ: í´ë¦¬ì—í‹¸ë Œ(ë‚´ë©´))",
        "item_report_number": "í’ˆëª©ë³´ê³ ë²ˆí˜¸",
        "front_calories": "ì „ë©´ë¶€ ì´ì—´ëŸ‰/ë¬¸êµ¬ (ì˜ˆ: 1,291kcal / ì—°ìœ¡70.6%, ë‹¹ê·¼4.41%)"
    },
    "ingredients": {
        "structured_list": [
            "ëƒ‰ë™ì—°ìœ¡70.6%(ì™¸êµ­ì‚°/ì–´ìœ¡ì‚´, ì„¤íƒ•, D-ì†Œë¹„í†¨, ì‚°ë„ì¡°ì ˆì œ)",
            "ì „ë¶„ê°€ê³µí’ˆ1 [ì¹´ì‚¬ë°”ì „ë¶„(íƒœêµ­, ë² íŠ¸ë‚¨ì‚°), ê°ìì „ë¶„]",
            "í˜¼í•©ì œì œ[ì¸ì‚°ì´ì „ë¶„(íƒ€í”¼ì˜¤ì¹´), ë±ìŠ¤íŠ¸ë¦°]",
            "ë‹¹ê·¼(êµ­ë‚´ì‚°)",
            "..."
        ],
        "continuous_text": "ëƒ‰ë™ì—°ìœ¡70.6%(ì™¸êµ­ì‚°/ì–´ìœ¡ì‚´, ì„¤íƒ•, D-ì†Œë¹„í†¨, ì‚°ë„ì¡°ì ˆì œ), ì „ë¶„ê°€ê³µí’ˆ1 [ì¹´ì‚¬ë°”ì „ë¶„(íƒœêµ­, ë² íŠ¸ë‚¨ì‚°), ê°ìì „ë¶„], í˜¼í•©ì œì œ[ì¸ì‚°ì´ì „ë¶„(íƒ€í”¼ì˜¤ì¹´), ë±ìŠ¤íŠ¸ë¦°], ë‹¹ê·¼(êµ­ë‚´ì‚°), ..."
    },
    "allergens": {
        "contains": ["ëŒ€ë‘", "ê²Œ"],
        "manufacturing_facility": "ë³¸ ì œí’ˆì€ ë°€, ê³„ë€, ìƒˆìš°, ì˜¤ì§•ì–´, ê³ ë“±ì–´, ìš°ìœ , ì‡ ê³ ê¸°, í† ë§ˆí† , ì¡°ê°œë¥˜(êµ´â€¤ì „ë³µ,í™í•© í¬í•¨)ë¥¼ ì‚¬ìš©í•œ ì œí’ˆê³¼ ê°™ì€ ì œì¡°ì‹œì„¤ì—ì„œ ì œì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤."
    },
    "nutrition_info": {
        "total_content": "1000 g",
        "per_100g": {
            "calories": "130 Kcal",
            "sodium": {"amount": "530 mg", "daily_value": "27%"},
            "fat": {"amount": "1.5 g", "daily_value": "3%"},
            "cholesterol": {"amount": "17 mg", "daily_value": "6%"},
            "carbohydrates": {"amount": "19 g", "daily_value": "6%"},
            "sugars": {"amount": "5 g", "daily_value": "5%"},
            "trans_fat": {"amount": "0 g", "daily_value": "0%"},
            "saturated_fat": {"amount": "0.3 g", "daily_value": "2%"},
            "protein": {"amount": "10 g", "daily_value": "18%"}
        },
        "disclaimer": "1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)ì€ 2,000kcal ê¸°ì¤€ì´ë¯€ë¡œ ê°œì¸ì˜ í•„ìš” ì—´ëŸ‰ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    },
    "manufacturer": {
        "name": "ì‚¼ì§„ì‹í’ˆ(ì£¼)",
        "address": "ë¶€ì‚°ê´‘ì—­ì‹œ ì‚¬í•˜êµ¬ ë‹¤ëŒ€ë¡œ 1066ë²ˆê¸¸ 51(ì¥ë¦¼ë™)"
    },
    "precautions": [
        "ë°˜ë“œì‹œ ëƒ‰ì¥ë³´ê´€í•˜ì‹œê³  ê°œë´‰ í›„ì—ëŠ” ë¹ ë¥¸ì‹œì¼ ë‚´ ì„­ì·¨í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤.",
        "ê°„í˜¹ í‘ë§‰ì´ ë°œê²¬ë  ìˆ˜ ìˆìœ¼ë‚˜ ìƒì„  ë‚´ë¶€ë³µë§‰ì´ì˜¤ë‹ˆ ì•ˆì‹¬í•˜ê³  ë“œì‹œê¸° ë°”ëë‹ˆë‹¤.",
        "ë°˜í’ˆ ë° êµí™˜: ìœ í†µ ì¤‘ ë³€ì§ˆ íŒŒì†ëœ ì œí’ˆì€ ë³¸ì‚¬ ë° êµ¬ì…ì²˜ì—ì„œ êµí™˜í•´ë“œë¦½ë‹ˆë‹¤.",
        "ë³¸ ì œí’ˆì€ ê³µì •ê±°ë˜ìœ„ì›íšŒê³ ì‹œ ì†Œë¹„ì ë¶„ìŸí•´ê²°ê¸°ì¤€ì— ì˜ê±° êµí™˜ ë˜ëŠ” ë³´ìƒë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "ë¶€ì •, ë¶ˆëŸ‰ì‹í’ˆ ì‹ ê³ ëŠ” êµ­ë²ˆì—†ì´ 1399"
    ],
    "law_compliance": {
        "status": "compliant" | "needs_review",
        "issues": ["ë²•ë¥  ìœ„ë°˜ ì‚¬í•­ ëª©ë¡ (ìˆëŠ” ê²½ìš°)"]
    },
    "details": [
        {"name": "ì›ì¬ë£Œëª…", "ratio": "ë°°í•©ë¹„ìœ¨", "origin": "ì›ì‚°ì§€", "sub_ingredients": "í•˜ìœ„ì›ë£Œ"}
    ]
}

**ì¤‘ìš”**: 
- Excel ë°ì´í„°ì—ì„œ ì¶”ì¶œ ê°€ëŠ¥í•œ ëª¨ë“  ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”.
- ì˜ì–‘ì •ë³´ëŠ” Excelì— ìˆëŠ” ê²½ìš°ì—ë§Œ í¬í•¨í•˜ê³ , ì—†ìœ¼ë©´ ë¹ˆ ê°ì²´ë¡œ ë‘ì„¸ìš”.
- ì›ì¬ë£Œëª…ì€ ë°°í•©ë¹„ìœ¨ ìˆœì„œëŒ€ë¡œ ì •í™•íˆ ë‚˜ì—´í•˜ì„¸ìš”.
- ì‹¤ì œ ë¼ë²¨ì— í‘œì‹œë˜ëŠ” í˜•ì‹ ê·¸ëŒ€ë¡œ êµ¬ì¡°í™”í•˜ì„¸ìš”.
"""

PROMPT_VERIFY_DESIGN = """
ë‹¹ì‹ ì€ ì‹í’ˆí‘œì‹œì‚¬í•­ ê°ì‚¬ê´€ì´ì ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
[ê¸°ì¤€ ë°ì´í„°(Standard)]ì™€ [ë””ìì¸ ì‹œì•ˆ(Design)]ì„ ë¹„êµí•˜ì—¬ ì˜¤ë¥˜ë¥¼ ê²€ì¶œí•˜ì„¸ìš”.

[ì…ë ¥]
1. **Standard**: ì•ì„œ ìƒì„±ëœ ì™„ë²½í•œ í‘œì‹œì‚¬í•­ ì •ë‹µì§€
2. **Design**: ê²€ìˆ˜í•  ì‹¤ì œ í¬ì¥ì§€ ë””ìì¸ íŒŒì¼ (PDF/ì´ë¯¸ì§€)
3. **ë²•ë ¹**: ì‹í’ˆ í‘œì‹œ ê´€ë ¨ ë²•ë ¹

[ê²€ì¦ ì›ì¹™ - ë§¤ìš° ì¤‘ìš”! ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì„¸ìš”!]
1. **ì˜¤íƒˆì ê²€ì¶œ ì¤‘ì‹¬**: Standardì™€ Designì„ ë¬¸ì ë‹¨ìœ„ë¡œ ì •í™•íˆ ë¹„êµí•˜ì—¬ ì‹¤ì œ ì˜¤íƒˆìë§Œ ê²€ì¶œí•˜ì„¸ìš”.
2. **í•¨ëŸ‰ ì •ë³´(%) ì¶”ê°€ëŠ” í—ˆìš©**: Standardì— ì—†ì–´ë„ Designì— í•¨ëŸ‰ ì •ë³´(%)ê°€ ì¶”ê°€ëœ ê²ƒì€ ì ˆëŒ€ ë¬¸ì œë¡œ ë³´ì§€ ì•ŠìŠµë‹ˆë‹¤.
   âœ… í—ˆìš© ì˜ˆì‹œ: Standard "ë‹¹ê·¼(êµ­ë‚´ì‚°)" â†’ Design "ë‹¹ê·¼(êµ­ë‚´ì‚°) 4.1%" (ë¬¸ì œ ì—†ìŒ)
   âœ… í—ˆìš© ì˜ˆì‹œ: Standard "ì–‘íŒŒ" â†’ Design "ì–‘íŒŒ 2.2%" (ë¬¸ì œ ì—†ìŒ)
3. **ë¹„ì •ìƒ ê°’ë§Œ ë¬¸ì œ**: í•¨ëŸ‰ì´ 100%ë¥¼ ì´ˆê³¼í•˜ê±°ë‚˜ ë§ë„ ì•ˆë˜ëŠ” ê°’ì¸ ê²½ìš°ë§Œ ë¬¸ì œë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
   âŒ ë¬¸ì œ ì˜ˆì‹œ: "ì–‘íŒŒ221%" (ì†Œìˆ˜ì  ëˆ„ë½ìœ¼ë¡œ 221%ê°€ ë˜ì–´ ë¹„ì •ìƒ) â†’ "ì–‘íŒŒ2.21%"ë¡œ ìˆ˜ì • í•„ìš”
   âŒ ë¬¸ì œ ì˜ˆì‹œ: "ë‹¹ê·¼999%" (ë§ë„ ì•ˆë˜ëŠ” ê°’) â†’ ë¬¸ì œë¡œ í‘œì‹œ
4. **ë¼ë²¨ëª… ëˆ„ë½ì€ ë¬´ì‹œ**: ë‚´ìš©ì´ë‚˜ ìˆ˜ì¹˜ëŠ” ìˆì§€ë§Œ ë¼ë²¨ëª…(ì˜ˆ: "ì „ë©´ë¶€ ì´ì—´ëŸ‰", "ì œì¡°ì‹œì„¤ì•ˆë‚´")ë§Œ ì—†ëŠ” ê²½ìš°ëŠ” ë¬¸ì œë¡œ ë³´ì§€ ì•ŠìŠµë‹ˆë‹¤.
   âœ… í—ˆìš©: ì˜ì–‘ì •ë³´ì— 127Kcal ìˆ˜ì¹˜ê°€ ìˆìœ¼ë©´ "ì „ë©´ë¶€ ì´ì—´ëŸ‰" ë¼ë²¨ì´ ì—†ì–´ë„ ë¬¸ì œ ì—†ìŒ
   âœ… í—ˆìš©: ì œì¡°ì‹œì„¤ ë‚´ìš©ì´ ìˆìœ¼ë©´ "ì œì¡°ì‹œì„¤ì•ˆë‚´" ë¼ë²¨ì´ ì—†ì–´ë„ ë¬¸ì œ ì—†ìŒ
5. **ì‹¤ì œ ì˜¤ë¥˜ë§Œ ê²€ì¶œ**:
   âœ… ì›ì¬ë£Œëª… ì˜¤íƒˆì: "ì „ë¶„ê°€ê³µí’ˆ" â†’ "ì „ë°˜ê°€ê³µí’ˆ" (ê¸€ì ì˜¤ê¸°)
   âœ… ì›ì¬ë£Œëª… ì˜¤íƒˆì: "D-ì†Œë¹„í†¨" â†’ "D-ì†”ë¹„í†¨" (ê¸€ì ì˜¤ê¸°)
   âœ… ìˆ«ì ì˜¤íƒˆì: "130kcal" â†’ "127kcal" (ìˆ«ì ì˜¤ê¸°)
   âœ… ë‹¨ìœ„ ì˜¤íƒˆì: "10g" â†’ "10mg" (ë‹¨ìœ„ ì˜¤ê¸°)
   âœ… êµ¬ë‘ì  ì˜¤íƒˆì: "ìš°ìœ , ì‡ ê³ ê¸°, í† ë§ˆí† " â†’ "ìš°ìœ  ì‡ ê³ ê¸° í† ë§ˆí† " (ì‰¼í‘œ ëˆ„ë½)
   âœ… ì†Œìˆ˜ì  ëˆ„ë½: "2.21%" â†’ "221%" (ë¹„ì •ìƒ ê°’)
   âœ… ì›ì‚°ì§€ ì˜¤ê¸°: "êµ­ë‚´ì‚°" â†’ "ìˆ˜ì…ì‚°" (ë‚´ìš© ì˜¤ê¸°)
   âœ… ìˆœì„œ ìœ„ë°˜: ë°°í•©ë¹„ ìˆœì„œì™€ ë‹¤ë¦„
   âœ… ë²•ë¥  ìœ„ë°˜: ì²¨ê°€ë¬¼ ìœ í˜• ëˆ„ë½ (ì˜ˆ: "ì†Œë¸Œì‚°ì¹¼ë¥¨" â†’ "ì†Œë¸Œì‚°ì¹¼ë¥¨(ë³´ì¡´ë£Œ)" í•„ìˆ˜)

[ê²€ì¦í•˜ì§€ ë§ì•„ì•¼ í•  ê²ƒë“¤ - ì ˆëŒ€ ë¬¸ì œë¡œ í‘œì‹œí•˜ì§€ ë§ˆì„¸ìš”!]
âŒ Standardì— ì—†ëŠ” í•¨ëŸ‰ ì •ë³´(%)ê°€ Designì— ì¶”ê°€ëœ ê²½ìš°
âŒ ë¼ë²¨ëª…ì€ ì—†ì§€ë§Œ ë‚´ìš©ì´ë‚˜ ìˆ˜ì¹˜ê°€ ìˆëŠ” ê²½ìš°
âŒ ê³µë°±ì´ë‚˜ í¬ë§·íŒ… ì°¨ì´ë§Œ ìˆëŠ” ê²½ìš° (ì˜ˆ: "íƒœêµ­, ë² íŠ¸ë‚¨ì‚°" vs "íƒœêµ­,ë² íŠ¸ë‚¨ì‚°")
âŒ Standardì™€ Designì´ ì˜ë¯¸ìƒ ë™ì¼í•˜ì§€ë§Œ í‘œí˜„ë§Œ ë‹¤ë¥¸ ê²½ìš°

[ê²€ì¦ í•­ëª©]
1. **ì›ì¬ë£Œëª… ì˜¤íƒˆì**: Standardì˜ ì›ì¬ë£Œëª…ê³¼ Designì˜ ì›ì¬ë£Œëª…ì„ ë¬¸ì ë‹¨ìœ„ë¡œ ë¹„êµí•˜ì—¬ ì˜¤íƒˆì ê²€ì¶œ
2. **ìˆ«ì/ë‹¨ìœ„ ì˜¤íƒˆì**: ì˜ì–‘ì •ë³´, í•¨ëŸ‰ ë“±ì˜ ìˆ«ìë‚˜ ë‹¨ìœ„ ì˜¤ê¸° í™•ì¸
3. **êµ¬ë‘ì  ì˜¤íƒˆì**: ì‰¼í‘œ, ì†Œìˆ˜ì  ë“± êµ¬ë‘ì  ëˆ„ë½/ì˜¤ê¸° í™•ì¸
4. **ì›ì‚°ì§€ ì˜¤ê¸°**: ì›ì‚°ì§€ ì •ë³´ê°€ Standardì™€ ë‹¤ë¥¸ì§€ í™•ì¸
5. **ìˆœì„œ ìœ„ë°˜**: ì›ì¬ë£Œ ë‚˜ì—´ ìˆœì„œê°€ Standard(ë°°í•©ë¹„ ìˆœ)ì™€ ë‹¤ë¥¸ì§€ í™•ì¸
6. **ë²•ë¥  ìœ„ë°˜**: ë²•ë ¹ì— ëª…ì‹œëœ ì˜ë¬´ì‚¬í•­(ì˜ˆ: ì²¨ê°€ë¬¼ ìœ í˜• í‘œì‹œ)ì´ ëˆ„ë½ë˜ì—ˆëŠ”ì§€ í™•ì¸
7. **ë¹„ì •ìƒ ê°’**: í•¨ëŸ‰ì´ 100% ì´ˆê³¼ì´ê±°ë‚˜ ë§ë„ ì•ˆë˜ëŠ” ê°’ì¸ì§€ í™•ì¸

[ì¶œë ¥ ì–‘ì‹ - JSON]
{
    "design_ocr_text": "ë””ìì¸ íŒŒì¼ì—ì„œ ì¸ì‹í•œ í…ìŠ¤íŠ¸",
    "score": 90,
    "law_compliance": {
        "status": "compliant" | "violation",
        "violations": ["ë²•ë¥  ìœ„ë°˜ ì‚¬í•­ ëª©ë¡ - ë²•ë¥  ì¡°í•­ë§Œ í‘œì‹œ (ì˜ˆ: 'ì‹í’ˆ ë“±ì˜ í‘œì‹œã†ê´‘ê³ ì— ê´€í•œ ë²•ë¥  ì œ4ì¡°ì œ1í•­ì œ1í˜¸ë‹¤ëª© ìœ„ë°˜')"]
    },
    "issues": [
        {
            "type": "Critical" | "Minor" | "Law_Violation",
            "location": "ìœ„ì¹˜ (ì˜ˆ: ì›ì¬ë£Œëª… 3ë²ˆì§¸ ì¤„, í›„ë©´ë¶€ ì˜ì–‘ì •ë³´)",
            "issue": "ì˜¤ë¥˜ ë‚´ìš© (ê°„ë‹¨ëª…ë£Œí•˜ê²Œ)",
            "expected": "ì •ë‹µ ë‚´ìš© (Standard ê¸°ì¤€)",
            "actual": "ì‹¤ì œ ë‚´ìš© (Designì—ì„œ ì¸ì‹í•œ ë‚´ìš©)",
            "suggestion": "ìˆ˜ì • ì œì•ˆ",
            "law_reference": "ê´€ë ¨ ë²•ë ¹ ì¡°í•­ (ë²•ë¥  ìœ„ë°˜ì¸ ê²½ìš°ë§Œ)"
        }
    ],
    "design_ocr_highlighted_html": "<div>í•˜ì´ë¼ì´íŠ¸ëœ HTML</div>"
}
"""

# --- ìœ í‹¸ í•¨ìˆ˜ë“¤ ---
def clean_html_text(text):
    if not text:
        return ""
    text = html.unescape(str(text))
    prev_text = ""
    while prev_text != text:
        prev_text = text
        text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'style\s*=\s*["\'][^"\']*["\']', '', text, flags=re.IGNORECASE)
    text = re.sub(r'class\s*=\s*["\'][^"\']*["\']', '', text, flags=re.IGNORECASE)
    text = re.sub(r'font-weight\s*:\s*\d+', '', text, flags=re.IGNORECASE)
    text = re.sub(r'margin[^;]*;?', '', text, flags=re.IGNORECASE)
    text = re.sub(r'padding[^;]*;?', '', text, flags=re.IGNORECASE)
    text = re.sub(r'color[^;]*;?', '', text, flags=re.IGNORECASE)
    text = re.sub(r'font-size[^;]*;?', '', text, flags=re.IGNORECASE)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def clean_ai_response(data):
    if isinstance(data, dict):
        cleaned = {}
        for key, value in data.items():
            if key in ['violations', 'issues'] and isinstance(value, list):
                cleaned[key] = []
                for item in value:
                    if isinstance(item, dict):
                        cleaned_item = {}
                        for k, v in item.items():
                            if isinstance(v, str):
                                cleaned_item[k] = clean_html_text(v)
                            else:
                                cleaned_item[k] = clean_ai_response(v)
                        cleaned[key].append(cleaned_item)
                    elif isinstance(item, str):
                        cleaned[key].append(clean_html_text(item))
                    else:
                        cleaned[key].append(clean_ai_response(item))
            elif isinstance(value, str):
                cleaned[key] = clean_html_text(value)
            else:
                cleaned[key] = clean_ai_response(value)
        return cleaned
    elif isinstance(data, list):
        return [clean_ai_response(item) for item in data]
    elif isinstance(data, str):
        return clean_html_text(data)
    else:
        return data

# --- OCR í´ë°± ---
def ocr_image_bytes(image_bytes: bytes) -> str:
    if not TESSERACT_AVAILABLE:
        return ""
    try:
        img = PIL.Image.open(io.BytesIO(image_bytes)).convert("RGB")
        text = pytesseract.image_to_string(img, lang='kor+eng')
        return text
    except Exception as e:
        print("pytesseract OCR ì‹¤íŒ¨:", e)
        return ""

# --- íŒŒì¼ ì²˜ë¦¬ (ìˆ˜ì •ë¨: ì´ë¯¸ì§€ -> PIL.Image ë°˜í™˜) ---
def process_file_to_part(file_storage):
    mime_type = file_storage.mimetype or ""
    file_data = file_storage.read()
    file_storage.seek(0)

    # Excel -> CSV text
    if mime_type in ['application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'application/vnd.ms-excel']:
        try:
            df = pd.read_excel(io.BytesIO(file_data))
            csv_text = df.to_csv(index=False)
            return {"text": f"--- [Excel ë°°í•©ë¹„ ë°ì´í„°] ---\n{csv_text}"}
        except Exception as e:
            print(f"ì—‘ì…€ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None

    # Image -> PIL.Image (for model OCR)
    if mime_type.startswith('image/'):
        try:
            img = PIL.Image.open(io.BytesIO(file_data)).convert("RGB")
            max_size = 1500
            if max(img.size) > max_size:
                ratio = max_size / max(img.size)
                new_size = (int(img.width * ratio), int(img.height * ratio))
                img = img.resize(new_size, PIL.Image.Resampling.LANCZOS)
                print(f"ğŸ“‰ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§•: {new_size}")
            return img
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨, bytesë¡œ ë°˜í™˜: {e}")
            return {"mime_type": mime_type, "data": file_data}

    # PDF -> convert to image if possible
    if mime_type == 'application/pdf' and PDF2IMAGE_AVAILABLE:
        try:
            images = convert_from_bytes(file_data, dpi=200)
            if images:
                print(f"ğŸ“„ PDF->ì´ë¯¸ì§€ ë³€í™˜: {len(images)} í˜ì´ì§€ (ì²« í˜ì´ì§€ ì‚¬ìš©)")
                return images[0].convert("RGB")
        except Exception as e:
            print("PDF->ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨:", e)
            return {"mime_type": mime_type, "data": file_data}

    return {"mime_type": mime_type, "data": file_data}

# --- ì´ë¯¸ì§€ ì›ì¬ë£Œ ì •ë³´ ì¶”ì¶œ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€) ---
def extract_ingredient_info_from_image(image_file):
    try:
        image_data = image_file.read()
        image_file.seek(0)
        img_pil = PIL.Image.open(io.BytesIO(image_data)).convert("RGB")
        model = genai.GenerativeModel(MODEL_NAME)
        parts = [PROMPT_EXTRACT_INGREDIENT_INFO, img_pil]
        response = model.generate_content(parts)

        print("---- extract_ingredient_info_from_image ëª¨ë¸ ì‘ë‹µ ì‹œì‘ ----")
        try:
            print(getattr(response, "text", str(response))[:4000])
        except Exception as e:
            print("ì‘ë‹µ ì¶œë ¥ ì‹¤íŒ¨:", e)
        print("---- extract_ingredient_info_from_image ëª¨ë¸ ì‘ë‹µ ë ----")

        result_text = getattr(response, "text", "").strip()
        if not result_text and TESSERACT_AVAILABLE:
            ocr_text = ocr_image_bytes(image_data)
            if ocr_text:
                return {"ocr_fallback_text": ocr_text}
        if result_text.startswith("```json"):
            result_text = result_text[7:-3] if result_text.endswith("```") else result_text[7:]
        elif result_text.startswith("```"):
            result_text = result_text.split("```")[1].strip() if "```" in result_text else result_text
            if result_text.startswith("json"):
                result_text = result_text[4:].strip()
        try:
            return json.loads(result_text)
        except json.JSONDecodeError as e:
            print(f"ì›ì¬ë£Œ ì •ë³´ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print("ì‘ë‹µ í…ìŠ¤íŠ¸ ì¼ë¶€:", result_text[:1000])
            return None
    except Exception as e:
        print(f"ì›ì¬ë£Œ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return None

# --- ì—‘ì…€ ë§Œë“¤ê¸° ---
def create_standard_excel(data):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        if 'product_info' in data:
            product_df = pd.DataFrame([data['product_info']])
            product_df.to_excel(writer, sheet_name='ì œí’ˆì •ë³´', index=False)
        if 'ingredients' in data:
            ingredients_data = []
            if 'structured_list' in data['ingredients']:
                for idx, item in enumerate(data['ingredients']['structured_list'], 1):
                    ingredients_data.append({'ìˆœë²ˆ': idx, 'ì›ì¬ë£Œëª…': item})
            ingredients_df = pd.DataFrame(ingredients_data)
            if not ingredients_df.empty:
                ingredients_df.to_excel(writer, sheet_name='ì›ì¬ë£Œëª…', index=False)
            if 'continuous_text' in data['ingredients']:
                continuous_df = pd.DataFrame([{'ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸': data['ingredients']['continuous_text']}])
                continuous_df.to_excel(writer, sheet_name='ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸', index=False)
        if 'allergens' in data:
            allergens_data = []
            if 'contains' in data['allergens']:
                allergens_data.append({'í•­ëª©': 'í•¨ìœ  ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ', 'ë‚´ìš©': ', '.join(data['allergens']['contains'])})
            if 'manufacturing_facility' in data['allergens']:
                allergens_data.append({'í•­ëª©': 'ì œì¡°ì‹œì„¤ ì•ˆë‚´', 'ë‚´ìš©': data['allergens']['manufacturing_facility']})
            if allergens_data:
                allergens_df = pd.DataFrame(allergens_data)
                allergens_df.to_excel(writer, sheet_name='ì•Œë ˆë¥´ê¸°ì •ë³´', index=False)
        if 'nutrition_info' in data and 'per_100g' in data['nutrition_info']:
            nutrition_data = []
            nut = data['nutrition_info']['per_100g']
            if 'calories' in nut:
                nutrition_data.append({'ì˜ì–‘ì„±ë¶„': 'ì´ ì—´ëŸ‰', '100g ë‹¹': nut['calories'], '1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)': '-'})
            for key, value in nut.items():
                if key != 'calories' and isinstance(value, dict):
                    nutrition_data.append({'ì˜ì–‘ì„±ë¶„': key, '100g ë‹¹': value.get('amount', ''), '1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)': value.get('daily_value', '')})
            if nutrition_data:
                nutrition_df = pd.DataFrame(nutrition_data)
                nutrition_df.to_excel(writer, sheet_name='ì˜ì–‘ì •ë³´', index=False)
        if 'manufacturer' in data:
            manufacturer_df = pd.DataFrame([data['manufacturer']])
            manufacturer_df.to_excel(writer, sheet_name='ì œì¡°ì›ì •ë³´', index=False)
        if 'precautions' in data:
            precautions_df = pd.DataFrame([{'ì£¼ì˜ì‚¬í•­': item} for item in data['precautions']])
            precautions_df.to_excel(writer, sheet_name='ì£¼ì˜ì‚¬í•­', index=False)
        if 'details' in data and data['details']:
            details_df = pd.DataFrame(data['details'])
            details_df.to_excel(writer, sheet_name='ì›ì¬ë£Œìƒì„¸', index=False)
    output.seek(0)
    return output

# --- ë¼ìš°íŠ¸ ---
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/api/create-standard', methods=['POST'])
def create_standard():
    print("âš™ï¸ 1ë‹¨ê³„: ê¸°ì¤€ ë°ì´í„° ìƒì„± ì‹œì‘...")
    excel_file = request.files.get('excel_file')
    raw_images = request.files.getlist('raw_images')
    if not excel_file:
        return jsonify({"error": "ë°°í•©ë¹„ ì—‘ì…€ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    parts = []
    enhanced_prompt = PROMPT_CREATE_STANDARD
    if ALL_LAW_TEXT:
        enhanced_prompt += f"\n\n--- [ì°¸ê³  ë²•ë ¹] ---\n{ALL_LAW_TEXT}\n--- [ë²•ë ¹ ë] ---\n"
    parts.append(enhanced_prompt)

    excel_part = process_file_to_part(excel_file)
    if excel_part:
        if isinstance(excel_part, dict) and 'text' in excel_part:
            parts.append(excel_part['text'])
        else:
            parts.append(excel_part)

    ingredient_info_list = []
    for img in raw_images[:15]:
        print(f"ğŸ“· ì›ì¬ë£Œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘: {img.filename}")
        ingredient_info = extract_ingredient_info_from_image(img)
        if ingredient_info:
            ingredient_info_list.append(ingredient_info)

    if ingredient_info_list:
        ingredients_text = "--- [ì›ì¬ë£Œ í‘œì‹œì‚¬í•­ì—ì„œ ì¶”ì¶œí•œ ì •ë³´] ---\n"
        for idx, info in enumerate(ingredient_info_list, 1):
            ingredients_text += f"\n[ì›ì¬ë£Œ {idx}]\n"
            ingredients_text += json.dumps(info, ensure_ascii=False, indent=2)
            ingredients_text += "\n"
        ingredients_text += "--- [ì›ì¬ë£Œ ì •ë³´ ë] ---\n"
        parts.append(ingredients_text)

    print(f"ğŸ“‚ ì²˜ë¦¬ ì¤‘: ì—‘ì…€ 1ê°œ + ì›ì¬ë£Œ ì´ë¯¸ì§€ {len(raw_images)}ì¥ (ì •ë³´ ì¶”ì¶œ ì™„ë£Œ)")

    try:
        model = genai.GenerativeModel(MODEL_NAME)
        response = model.generate_content(parts)

        print("---- ëª¨ë¸ ì‘ë‹µ(ì›ë¬¸) ì‹œì‘ ----")
        try:
            print(getattr(response, "text", str(response))[:4000])
        except Exception as e:
            print("ì‘ë‹µ ì¶œë ¥ ì‹¤íŒ¨:", e)
        print("---- ëª¨ë¸ ì‘ë‹µ(ì›ë¬¸) ë ----")

        result_text = getattr(response, "text", "").strip()
        if result_text.startswith("```json"):
            result_text = result_text[7:]
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        elif result_text.startswith("```"):
            lines = result_text.split("\n")
            if lines and lines[0].startswith("```"):
                result_text = "\n".join(lines[1:])
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        result_text = result_text.strip()

        try:
            result = json.loads(result_text)
        except json.JSONDecodeError as json_err:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {json_err}")
            print(f"ì‘ë‹µ í…ìŠ¤íŠ¸ (ì²˜ìŒ 2000ì): {result_text[:2000]}")
            try:
                result_text_fixed = result_text.replace(',\n}', '\n}').replace(',\n]', '\n]')
                result = json.loads(result_text_fixed)
                print("âœ… JSON ìˆ˜ì • í›„ íŒŒì‹± ì„±ê³µ")
            except Exception as e:
                print("ìµœì¢… JSON íŒŒì‹± ì‹¤íŒ¨:", e)
                return jsonify({"error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(json_err)}. ì‘ë‹µì˜ ì¼ë¶€: {result_text[:400]}..."}), 500

        return jsonify(result)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

@app.route('/api/download-standard-excel', methods=['POST'])
def download_standard_excel():
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "ê¸°ì¤€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400
        excel_buffer = create_standard_excel(data)
        product_name = data.get('product_info', {}).get('product_name', 'ê¸°ì¤€ë°ì´í„°') or data.get('product_name', 'ê¸°ì¤€ë°ì´í„°')
        filename = f"{product_name}_ê¸°ì¤€ë°ì´í„°.xlsx"
        return send_file(
            excel_buffer,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name=filename
        )
    except Exception as e:
        print(f"âŒ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

@app.route('/api/read-standard-excel', methods=['POST'])
def read_standard_excel():
    try:
        excel_file = request.files.get('excel_file')
        if not excel_file:
            return jsonify({"error": "ì—‘ì…€ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        df_dict = pd.read_excel(io.BytesIO(excel_file.read()), sheet_name=None, engine='openpyxl')
        result = {}
        if 'ì œí’ˆì •ë³´' in df_dict:
            product_info = df_dict['ì œí’ˆì •ë³´'].to_dict('records')[0]
            result['product_info'] = product_info
        first_sheet_name = list(df_dict.keys())[0]
        first_sheet_df = df_dict[first_sheet_name]
        if 'ì›ì¬ë£Œëª…' in df_dict:
            ingredients_list = df_dict['ì›ì¬ë£Œëª…']['ì›ì¬ë£Œëª…'].dropna().tolist()
            result['ingredients'] = {'structured_list': ingredients_list, 'continuous_text': ', '.join(ingredients_list)}
        elif 'ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸' in df_dict:
            continuous_text = df_dict['ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸']['ì›ì¬ë£Œëª…_ì—°ì†í…ìŠ¤íŠ¸'].iloc[0]
            result['ingredients'] = {'structured_list': continuous_text.split(', '), 'continuous_text': continuous_text}
        elif not first_sheet_df.empty:
            first_column = first_sheet_df.columns[0]
            if 'ì›ì¬ë£Œëª…' in first_sheet_df.columns:
                ingredients_list = first_sheet_df['ì›ì¬ë£Œëª…'].dropna().tolist()
            else:
                ingredients_list = first_sheet_df[first_column].dropna().astype(str).tolist()
            if ingredients_list:
                result['ingredients'] = {'structured_list': ingredients_list, 'continuous_text': ', '.join(ingredients_list)}
        if 'ì•Œë ˆë¥´ê¸°ì •ë³´' in df_dict:
            allergens_df = df_dict['ì•Œë ˆë¥´ê¸°ì •ë³´']
            result['allergens'] = {}
            for _, row in allergens_df.iterrows():
                if row['í•­ëª©'] == 'í•¨ìœ  ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ':
                    result['allergens']['contains'] = row['ë‚´ìš©'].split(', ')
                elif row['í•­ëª©'] == 'ì œì¡°ì‹œì„¤ ì•ˆë‚´':
                    result['allergens']['manufacturing_facility'] = row['ë‚´ìš©']
        if 'ì˜ì–‘ì •ë³´' in df_dict:
            nutrition_df = df_dict['ì˜ì–‘ì •ë³´']
            per_100g = {}
            for _, row in nutrition_df.iterrows():
                if row['ì˜ì–‘ì„±ë¶„'] == 'ì´ ì—´ëŸ‰':
                    per_100g['calories'] = row['100g ë‹¹']
                else:
                    per_100g[row['ì˜ì–‘ì„±ë¶„']] = {'amount': row['100g ë‹¹'], 'daily_value': row['1ì¼ ì˜ì–‘ì„±ë¶„ ê¸°ì¤€ì¹˜ì— ëŒ€í•œ ë¹„ìœ¨(%)']}
            result['nutrition_info'] = {'per_100g': per_100g}
        if 'ì œì¡°ì›ì •ë³´' in df_dict:
            result['manufacturer'] = df_dict['ì œì¡°ì›ì •ë³´'].to_dict('records')[0]
        if 'ì£¼ì˜ì‚¬í•­' in df_dict:
            result['precautions'] = df_dict['ì£¼ì˜ì‚¬í•­']['ì£¼ì˜ì‚¬í•­'].tolist()
        if 'ì›ì¬ë£Œìƒì„¸' in df_dict:
            result['details'] = df_dict['ì›ì¬ë£Œìƒì„¸'].to_dict('records')
        return jsonify(result)
    except Exception as e:
        print(f"âŒ ì—‘ì…€ ì½ê¸° ì˜¤ë¥˜: {e}")
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

# --- verify_design ëŒ€ì²´: ëª¨ë¸ + í´ë°± OCR + í•˜ì´ë¼ì´íŠ¸ ìƒì„± ---
def simple_generate_highlight_html(ocr_text: str, standard_ingredients: list):
    if not ocr_text:
        return "<div>OCRë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.</div>"
    lines = [ln.strip() for ln in ocr_text.splitlines() if ln.strip()]
    if not lines:
        lines = [ocr_text.strip()]
    std_lower = [s.lower() for s in standard_ingredients]
    html_lines = []
    for line in lines:
        line_html = html.escape(line)
        lowered = line.lower()
        matched = False
        for idx, std in enumerate(std_lower):
            if std in lowered:
                matched = True
                line_html = line_html.replace(html.escape(standard_ingredients[idx]), f"<span style='background:#e6f4ea;padding:2px 4px;border-radius:4px;'>{html.escape(standard_ingredients[idx])}</span>")
        if not matched:
            line_html = f"<span style='color:#ad2e2e; font-weight:600;'>{line_html}</span>"
        html_lines.append(f"<div style='margin-bottom:6px; font-family:monospace; white-space:pre-wrap;'>{line_html}</div>")
    result_html = "<div style='padding:10px; background:#fff; border-radius:8px;'>" + "".join(html_lines) + "</div>"
    return result_html

def extract_text_from_design_part(design_part):
    try:
        from PIL import Image
        pil_type = Image.Image
    except Exception:
        pil_type = None
    if pil_type and isinstance(design_part, pil_type):
        bio = BytesIO()
        design_part.save(bio, format='PNG')
        bio.seek(0)
        img_bytes = bio.read()
        return ocr_image_bytes(img_bytes)
    if isinstance(design_part, dict) and 'data' in design_part:
        img_bytes = design_part['data']
        return ocr_image_bytes(img_bytes)
    return ""

@app.route('/api/verify-design', methods=['POST'])
def verify_design():
    print("ğŸ•µï¸â€â™‚ï¸ 2ë‹¨ê³„: ë””ìì¸ ê²€ì¦ ì‹œì‘ (í´ë°± OCR í¬í•¨)...")
    design_file = request.files.get('design_file')
    standard_excel = request.files.get('standard_excel')
    standard_json = request.form.get('standard_data')
    if not design_file:
        return jsonify({"error": "ë””ìì¸ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400
    if not standard_excel and not standard_json:
        return jsonify({"error": "ê¸°ì¤€ ë°ì´í„°(ì—‘ì…€ íŒŒì¼ ë˜ëŠ” JSON)ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    if standard_excel:
        try:
            df_dict = pd.read_excel(io.BytesIO(standard_excel.read()), sheet_name=None, engine='openpyxl')
            if not df_dict:
                return jsonify({"error": "ì—‘ì…€ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."}), 400
            first_sheet_name = list(df_dict.keys())[0]
            first_sheet_df = df_dict[first_sheet_name]
            if not first_sheet_df.empty:
                first_column = first_sheet_df.columns[0]
                if 'ì›ì¬ë£Œëª…' in first_sheet_df.columns:
                    ingredients_list = first_sheet_df['ì›ì¬ë£Œëª…'].dropna().astype(str).tolist()
                else:
                    ingredients_list = first_sheet_df[first_column].dropna().astype(str).tolist()
                standard_data = {'ingredients': {'structured_list': ingredients_list, 'continuous_text': ', '.join(ingredients_list)}}
                standard_json = json.dumps(standard_data, ensure_ascii=False)
            else:
                return jsonify({"error": "ì—‘ì…€ì˜ ì²« ì‹œíŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."}), 400
        except Exception as e:
            print(f"âŒ ì—‘ì…€ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            traceback.print_exc()
            return jsonify({"error": f"ì—‘ì…€ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}"}), 400

    parts = []
    enhanced_prompt = PROMPT_VERIFY_DESIGN
    if ALL_LAW_TEXT:
        enhanced_prompt += f"\n\n--- [ì°¸ê³  ë²•ë ¹] ---\n{ALL_LAW_TEXT}\n--- [ë²•ë ¹ ë] ---\n"
    parts.append(enhanced_prompt)
    parts.append(f"\n--- [ê¸°ì¤€ ë°ì´í„°(Standard)] ---\n{standard_json}")

    design_part = process_file_to_part(design_file)
    if design_part:
        parts.append(design_part)

    model = genai.GenerativeModel(MODEL_NAME)
    result_text = ""
    try:
        response = model.generate_content(parts)
        print("---- ëª¨ë¸ ì‘ë‹µ(ì›ë¬¸) ì‹œì‘ ----")
        try:
            print(getattr(response, "text", str(response))[:4000])
        except Exception as e:
            print("ì‘ë‹µ ì¶œë ¥ ì‹¤íŒ¨:", e)
        print("---- ëª¨ë¸ ì‘ë‹µ(ì›ë¬¸) ë ----")
        result_text = getattr(response, "text", "").strip()
    except Exception as e:
        print("ëª¨ë¸ í˜¸ì¶œ ì‹¤íŒ¨:", e)
        traceback.print_exc()
        result_text = ""

    result = None
    if result_text:
        if result_text.startswith("```json"):
            result_text = result_text[7:]
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        elif result_text.startswith("```"):
            lines = result_text.split("\n")
            if lines and lines[0].startswith("```"):
                result_text = "\n".join(lines[1:])
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        result_text = result_text.strip()
        try:
            result = json.loads(result_text)
        except json.JSONDecodeError as json_err:
            print("JSON íŒŒì‹± ì˜¤ë¥˜:", json_err)
            print("ì‘ë‹µ í…ìŠ¤íŠ¸(ì¼ë¶€):", result_text[:1000])
            try:
                fixed = result_text.replace(',\n}', '\n}').replace(',\n]', '\n]')
                result = json.loads(fixed)
                print("âœ… JSON ìˆ˜ì • í›„ íŒŒì‹± ì„±ê³µ")
            except Exception as e:
                print("ìµœì¢… JSON íŒŒì‹± ì‹¤íŒ¨:", e)
                result = None

    highlight_html = None
    if result and isinstance(result, dict):
        highlight_html = result.get("design_ocr_highlighted_html") or None

    if not highlight_html:
        print("ëª¨ë¸ì—ì„œ í•˜ì´ë¼ì´íŠ¸ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ -> ì„œë²„ í´ë°± OCR ì‹œë„")
        try:
            ocr_text = extract_text_from_design_part(design_part)
            if not ocr_text:
                try:
                    raw_bytes = design_file.read()
                    design_file.seek(0)
                    ocr_text = ocr_image_bytes(raw_bytes)
                except Exception:
                    ocr_text = ""
            std_ingredients = []
            try:
                std_obj = json.loads(standard_json)
                std_ingredients = std_obj.get('ingredients', {}).get('structured_list', [])
            except Exception:
                std_ingredients = []
            highlight_html = simple_generate_highlight_html(ocr_text, std_ingredients)
            if not result:
                result = {}
            result['design_ocr_highlighted_html'] = highlight_html
            result.setdefault('design_ocr_text', ocr_text)
        except Exception as e:
            print("í´ë°± OCR ì²˜ë¦¬ ì‹¤íŒ¨:", e)
            traceback.print_exc()
            if not result:
                result = {}
            result['design_ocr_highlighted_html'] = "<div>ì„œë²„ í´ë°± OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.</div>"
            result['design_ocr_text'] = ""

    if not result:
        result = {
            "design_ocr_text": "",
            "score": 0,
            "law_compliance": {"status": "needs_review", "violations": []},
            "issues": [],
            "design_ocr_highlighted_html": "<div>ëª¨ë¸ê³¼ í´ë°± ëª¨ë‘ì—ì„œ OCR ê²°ê³¼ë¥¼ ì–»ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.</div>"
        }

    result = clean_ai_response(result)
    return jsonify(result)

@app.route('/api/upload-qa', methods=['POST'])
def upload_qa():
    print("ğŸ“‹ QA ìë£Œ ì—…ë¡œë“œ ë° ì‹í’ˆí‘œì‹œì‚¬í•­ ì‘ì„± ì‹œì‘...")
    qa_files = request.files.getlist('qa_files')
    if not qa_files or len(qa_files) == 0:
        return jsonify({"error": "QA ìë£Œ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    parts = []
    qa_prompt = """
ë‹¹ì‹ ì€ ì‹í’ˆí‘œì‹œì‚¬í•­ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ QA ìë£Œë¥¼ ë¶„ì„í•˜ì—¬ ë²•ë¥ ì„ ì¤€ìˆ˜í•˜ëŠ” ì‹í’ˆí‘œì‹œì‚¬í•­ì„ ì‘ì„±í•˜ì„¸ìš”.

[ì‘ì—… ë‹¨ê³„]
1. QA ìë£Œ ë¶„ì„: ì—‘ì…€, ì´ë¯¸ì§€ ë“± ëª¨ë“  QA ìë£Œë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.
2. ë²•ë¥  ê²€í† : ì œê³µëœ ë²•ë ¹ì„ ì°¸ê³ í•˜ì—¬ í•„ìˆ˜ í‘œì‹œì‚¬í•­ì´ ëª¨ë‘ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
3. ì‹í’ˆí‘œì‹œì‚¬í•­ ì‘ì„±: ë²•ë¥ ì„ ì¤€ìˆ˜í•˜ëŠ” ì™„ì „í•œ ì‹í’ˆí‘œì‹œì‚¬í•­ì„ ì‘ì„±í•˜ì„¸ìš”.

[ì¶œë ¥ ì–‘ì‹ - JSON]
{
    "product_name": "ì œí’ˆëª…",
    "label_text": "ì‘ì„±ëœ ì‹í’ˆí‘œì‹œì‚¬í•­ ì „ì²´ í…ìŠ¤íŠ¸",
    "law_compliance": {
        "status": "compliant" | "needs_review",
        "issues": ["ë²•ë¥  ê²€í†  ì‚¬í•­ ëª©ë¡"]
    },
    "sections": {
        "ingredients": "ì›ì¬ë£Œëª…",
        "nutrition": "ì˜ì–‘ì •ë³´",
        "allergens": "ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ",
        "storage": "ë³´ê´€ë°©ë²•",
        "manufacturer": "ì œì¡°ì‚¬ ì •ë³´"
    }
}
"""
    if ALL_LAW_TEXT:
        qa_prompt += f"\n\n--- [ì°¸ê³  ë²•ë ¹] ---\n{ALL_LAW_TEXT}\n--- [ë²•ë ¹ ë] ---\n"
    parts.append(qa_prompt)

    for qa_file in qa_files[:20]:
        file_part = process_file_to_part(qa_file)
        if not file_part:
            continue
        if isinstance(file_part, dict) and 'text' in file_part:
            parts.append(file_part['text'])
        else:
            parts.append(file_part)

    print(f"ğŸ“‚ QA ìë£Œ ì²˜ë¦¬ ì¤‘: {len(qa_files)}ê°œ íŒŒì¼")
    try:
        model = genai.GenerativeModel(MODEL_NAME)
        response = model.generate_content(parts)

        print("---- ëª¨ë¸ ì‘ë‹µ(ì›ë¬¸) ì‹œì‘ ----")
        try:
            print(getattr(response, "text", str(response))[:4000])
        except Exception as e:
            print("ì‘ë‹µ ì¶œë ¥ ì‹¤íŒ¨:", e)
        print("---- ëª¨ë¸ ì‘ë‹µ(ì›ë¬¸) ë ----")

        result_text = getattr(response, "text", "").strip()
        if result_text.startswith("```json"):
            result_text = result_text[7:]
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        elif result_text.startswith("```"):
            lines = result_text.split("\n")
            if lines and lines[0].startswith("```"):
                result_text = "\n".join(lines[1:])
            if result_text.endswith("```"):
                result_text = result_text[:-3]
        result_text = result_text.strip()

        try:
            result = json.loads(result_text)
        except json.JSONDecodeError as json_err:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {json_err}")
            print(f"ì‘ë‹µ í…ìŠ¤íŠ¸ (ì²˜ìŒ 2000ì): {result_text[:2000]}")
            try:
                result_text_fixed = result_text.replace(',\n}', '\n}').replace(',\n]', '\n]')
                result = json.loads(result_text_fixed)
                print("âœ… JSON ìˆ˜ì • í›„ íŒŒì‹± ì„±ê³µ")
            except:
                return jsonify({"error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(json_err)}. ì‘ë‹µì˜ ì¼ë¶€: {result_text[:200]}..."}), 500

        return jsonify(result)

    except Exception as e:
        print(f"âŒ QA ìë£Œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    print("ğŸš€ ì‚¼ì§„ì–´ë¬µ ì‹í’ˆí‘œì‹œì‚¬í•­ ì™„ì„± í”Œë«í¼ V3.0 ê°€ë™")
    from waitress import serve
    serve(
        app,
        host='0.0.0.0',
        port=8080,
        threads=4,
        channel_timeout=600
    )

